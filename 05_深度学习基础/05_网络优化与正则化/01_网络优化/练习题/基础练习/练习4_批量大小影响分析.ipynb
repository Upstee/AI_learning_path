{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ç»ƒä¹ 4ï¼šæ‰¹é‡å¤§å°å½±å“åˆ†æ\n",
        "\n",
        "## ç»ƒä¹ ç›®æ ‡\n",
        "\n",
        "é€šè¿‡å®éªŒåˆ†ææ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰å¯¹ä¼˜åŒ–è¿‡ç¨‹çš„å½±å“ï¼Œç†è§£æ‰¹é‡æ¢¯åº¦ä¸‹é™ã€éšæœºæ¢¯åº¦ä¸‹é™å’Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™çš„åŒºåˆ«ã€‚\n",
        "\n",
        "## ä»»åŠ¡è¯´æ˜\n",
        "\n",
        "æœ¬ç»ƒä¹ è¦æ±‚ä½ ï¼š\n",
        "1. ç†è§£ä¸åŒæ‰¹é‡å¤§å°çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•\n",
        "2. å®ç°æ”¯æŒæ‰¹é‡å¤§å°çš„ä¼˜åŒ–å™¨\n",
        "3. å¯¹æ¯”ä¸åŒæ‰¹é‡å¤§å°çš„è®­ç»ƒæ•ˆæœ\n",
        "4. åˆ†ææ‰¹é‡å¤§å°å¯¹æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§çš„å½±å“\n",
        "5. ç†è§£æ‰¹é‡å¤§å°é€‰æ‹©çš„æƒè¡¡\n",
        "\n",
        "## å‰ç½®çŸ¥è¯†\n",
        "\n",
        "- å·²å®Œæˆç»ƒä¹ 2å’Œç»ƒä¹ 3\n",
        "- ç†è§£æ¢¯åº¦ä¸‹é™çš„åŸºæœ¬åŸç†\n",
        "- äº†è§£æ‰¹é‡å¤„ç†çš„æ¦‚å¿µ\n",
        "\n",
        "## å­¦ä¹ é‡ç‚¹\n",
        "\n",
        "- æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBGDï¼‰ã€éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰ã€å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch GDï¼‰çš„åŒºåˆ«\n",
        "- æ‰¹é‡å¤§å°å¯¹æ¢¯åº¦ä¼°è®¡çš„å½±å“\n",
        "- æ‰¹é‡å¤§å°ä¸è®­ç»ƒé€Ÿåº¦ã€å†…å­˜å ç”¨ã€æ”¶æ•›ç¨³å®šæ€§çš„å…³ç³»\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿å›¾è¡¨èƒ½æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n",
        "print(\"Pythonç‰ˆæœ¬è¦æ±‚ï¼š3.7+\")\n",
        "print(\"ä¸»è¦ä¾èµ–ï¼šnumpy, matplotlib\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡1ï¼šç†è§£ä¸åŒæ‰¹é‡å¤§å°çš„æ¢¯åº¦ä¸‹é™æ–¹æ³•\n",
        "\n",
        "### ä¸‰ç§æ¢¯åº¦ä¸‹é™æ–¹æ³•\n",
        "\n",
        "1. **æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆBGD - Batch Gradient Descentï¼‰**\n",
        "   - ä½¿ç”¨**å…¨éƒ¨**è®­ç»ƒæ ·æœ¬è®¡ç®—æ¢¯åº¦\n",
        "   - æ‰¹é‡å¤§å° = è®­ç»ƒé›†å¤§å°\n",
        "   - ä¼˜ç‚¹ï¼šæ¢¯åº¦ä¼°è®¡å‡†ç¡®ï¼Œæ”¶æ•›ç¨³å®š\n",
        "   - ç¼ºç‚¹ï¼šè®¡ç®—æ…¢ï¼Œå†…å­˜å ç”¨å¤§ï¼Œä¸é€‚åˆå¤§è§„æ¨¡æ•°æ®\n",
        "\n",
        "2. **éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGD - Stochastic Gradient Descentï¼‰**\n",
        "   - æ¯æ¬¡ä½¿ç”¨**ä¸€ä¸ª**æ ·æœ¬è®¡ç®—æ¢¯åº¦\n",
        "   - æ‰¹é‡å¤§å° = 1\n",
        "   - ä¼˜ç‚¹ï¼šè®¡ç®—å¿«ï¼Œå†…å­˜å ç”¨å°ï¼Œé€‚åˆåœ¨çº¿å­¦ä¹ \n",
        "   - ç¼ºç‚¹ï¼šæ¢¯åº¦ä¼°è®¡å™ªå£°å¤§ï¼Œæ”¶æ•›ä¸ç¨³å®š\n",
        "\n",
        "3. **å°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼ˆMini-batch GDï¼‰**\n",
        "   - æ¯æ¬¡ä½¿ç”¨**ä¸€å°æ‰¹**æ ·æœ¬è®¡ç®—æ¢¯åº¦\n",
        "   - æ‰¹é‡å¤§å° = 2, 4, 8, 16, 32, 64, 128, ...\n",
        "   - ä¼˜ç‚¹ï¼šå¹³è¡¡äº†è®¡ç®—æ•ˆç‡å’Œæ¢¯åº¦å‡†ç¡®æ€§\n",
        "   - ç¼ºç‚¹ï¼šéœ€è¦é€‰æ‹©åˆé€‚çš„æ‰¹é‡å¤§å°\n",
        "\n",
        "### æ¢¯åº¦ä¼°è®¡çš„å·®å¼‚\n",
        "\n",
        "- **æ‰¹é‡å¤§å°å¤§**ï¼šæ¢¯åº¦ä¼°è®¡æ›´å‡†ç¡®ï¼Œä½†è®¡ç®—æ…¢\n",
        "- **æ‰¹é‡å¤§å°å°**ï¼šæ¢¯åº¦ä¼°è®¡å™ªå£°å¤§ï¼Œä½†è®¡ç®—å¿«ï¼Œå¯èƒ½æœ‰åŠ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜\n",
        "\n",
        "### ä»»åŠ¡è¦æ±‚\n",
        "\n",
        "TODO: é˜…è¯»å¹¶ç†è§£ä¸Šè¿°å†…å®¹ï¼Œæ€è€ƒä»¥ä¸‹é—®é¢˜ï¼š\n",
        "1. ä¸ºä»€ä¹ˆæ‰¹é‡å¤§å°ä¼šå½±å“æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Ÿ\n",
        "2. æ‰¹é‡å¤§å°ä¸è®­ç»ƒé€Ÿåº¦ã€å†…å­˜å ç”¨æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ\n",
        "3. å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ‰¹é‡å¤§å°ï¼Ÿ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡2ï¼šå‡†å¤‡æµ‹è¯•æ•°æ®å’ŒæŸå¤±å‡½æ•°\n",
        "\n",
        "### ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®\n",
        "\n",
        "æˆ‘ä»¬å°†ä½¿ç”¨ç®€å•çš„çº¿æ€§å›å½’é—®é¢˜æ¥æµ‹è¯•æ‰¹é‡å¤§å°çš„å½±å“ï¼š\n",
        "- ç”Ÿæˆ1000ä¸ªæ ·æœ¬\n",
        "- ç‰¹å¾ç»´åº¦ï¼š10\n",
        "- ç›®æ ‡ï¼šå­¦ä¹ çº¿æ€§å…³ç³» y = X * w + b\n",
        "\n",
        "### ä»»åŠ¡è¦æ±‚\n",
        "\n",
        "TODO: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†å¹¶å®šä¹‰æŸå¤±å‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®é›†\n",
        "# n_samples = 1000  # æ ·æœ¬æ•°é‡\n",
        "# n_features = 10   # ç‰¹å¾ç»´åº¦\n",
        "# \n",
        "# # ç”Ÿæˆç‰¹å¾çŸ©é˜µ X (n_samples, n_features)\n",
        "# # ä½¿ç”¨éšæœºæ•°ç”Ÿæˆï¼Œç¡®ä¿æ•°æ®åˆ†å¸ƒåˆç†\n",
        "# X = np.random.randn(n_samples, n_features)\n",
        "# \n",
        "# # ç”ŸæˆçœŸå®çš„æƒé‡å’Œåç½®\n",
        "# true_w = np.random.randn(n_features)\n",
        "# true_b = 0.5\n",
        "# \n",
        "# # ç”Ÿæˆç›®æ ‡å€¼ y = X * w + b + noise\n",
        "# noise = 0.1 * np.random.randn(n_samples)\n",
        "# y = X @ true_w + true_b + noise\n",
        "# \n",
        "# print(f\"æ•°æ®é›†å½¢çŠ¶: X={X.shape}, y={y.shape}\")\n",
        "# print(f\"çœŸå®æƒé‡: w={true_w[:3]}... (å‰3ä¸ª)\")\n",
        "# print(f\"çœŸå®åç½®: b={true_b}\")\n",
        "\n",
        "# TODO: å®šä¹‰æŸå¤±å‡½æ•°ï¼ˆå‡æ–¹è¯¯å·®ï¼‰\n",
        "def mse_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    è®¡ç®—å‡æ–¹è¯¯å·®æŸå¤±\n",
        "    \n",
        "    å‚æ•°:\n",
        "        y_true: çœŸå®å€¼\n",
        "        y_pred: é¢„æµ‹å€¼\n",
        "    \n",
        "    è¿”å›:\n",
        "        float: å‡æ–¹è¯¯å·®\n",
        "    \"\"\"\n",
        "    # TODO: å®ç°MSEæŸå¤±\n",
        "    # return np.mean((y_true - y_pred) ** 2)\n",
        "    pass\n",
        "\n",
        "# TODO: å®šä¹‰æ¢¯åº¦è®¡ç®—å‡½æ•°\n",
        "def compute_gradients(X_batch, y_batch, w, b):\n",
        "    \"\"\"\n",
        "    è®¡ç®—çº¿æ€§å›å½’çš„æ¢¯åº¦\n",
        "    \n",
        "    å‚æ•°:\n",
        "        X_batch: æ‰¹é‡ç‰¹å¾ (batch_size, n_features)\n",
        "        y_batch: æ‰¹é‡ç›®æ ‡ (batch_size,)\n",
        "        w: æƒé‡ (n_features,)\n",
        "        b: åç½® (scalar)\n",
        "    \n",
        "    è¿”å›:\n",
        "        grad_w: æƒé‡æ¢¯åº¦ (n_features,)\n",
        "        grad_b: åç½®æ¢¯åº¦ (scalar)\n",
        "    \"\"\"\n",
        "    # TODO: è®¡ç®—é¢„æµ‹å€¼\n",
        "    # y_pred = X_batch @ w + b\n",
        "    # \n",
        "    # TODO: è®¡ç®—è¯¯å·®\n",
        "    # error = y_pred - y_batch\n",
        "    # \n",
        "    # TODO: è®¡ç®—æ¢¯åº¦\n",
        "    # grad_w = (2 / len(y_batch)) * (X_batch.T @ error)\n",
        "    # grad_b = (2 / len(y_batch)) * np.sum(error)\n",
        "    # \n",
        "    # return grad_w, grad_b\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡3ï¼šå®ç°æ”¯æŒæ‰¹é‡å¤§å°çš„SGDä¼˜åŒ–å™¨\n",
        "\n",
        "### å®ç°è¦æ±‚\n",
        "\n",
        "TODO: å®ç°ä¸€ä¸ªæ”¯æŒæ‰¹é‡å¤§å°çš„SGDä¼˜åŒ–å™¨ï¼Œèƒ½å¤Ÿï¼š\n",
        "1. æ¥æ”¶æ‰¹é‡æ•°æ®\n",
        "2. è®¡ç®—æ‰¹é‡æ¢¯åº¦\n",
        "3. æ›´æ–°å‚æ•°\n",
        "\n",
        "### å…³é”®ç‚¹\n",
        "\n",
        "- æ‰¹é‡æ¢¯åº¦ = æ‰¹é‡å†…æ‰€æœ‰æ ·æœ¬æ¢¯åº¦çš„å¹³å‡å€¼\n",
        "- æ‰¹é‡å¤§å°å½±å“æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§\n",
        "- éœ€è¦æ­£ç¡®å¤„ç†æ‰¹é‡æ•°æ®çš„ç»´åº¦\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: å®ç°æ”¯æŒæ‰¹é‡å¤§å°çš„SGDä¼˜åŒ–å™¨\n",
        "class BatchSGD:\n",
        "    \"\"\"\n",
        "    æ”¯æŒæ‰¹é‡å¤§å°çš„éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨\n",
        "    \n",
        "    å‚æ•°:\n",
        "        learning_rate (float): å­¦ä¹ ç‡\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–ä¼˜åŒ–å™¨\n",
        "        \n",
        "        å‚æ•°:\n",
        "            learning_rate: å­¦ä¹ ç‡ï¼Œé»˜è®¤0.01\n",
        "        \"\"\"\n",
        "        # TODO: ä¿å­˜å­¦ä¹ ç‡\n",
        "        # self.lr = learning_rate\n",
        "        pass\n",
        "    \n",
        "    def update(self, w, b, grad_w, grad_b):\n",
        "        \"\"\"\n",
        "        æ›´æ–°å‚æ•°\n",
        "        \n",
        "        å‚æ•°:\n",
        "            w: å½“å‰æƒé‡\n",
        "            b: å½“å‰åç½®\n",
        "            grad_w: æƒé‡æ¢¯åº¦\n",
        "            grad_b: åç½®æ¢¯åº¦\n",
        "        \n",
        "        è¿”å›:\n",
        "            w_new: æ›´æ–°åçš„æƒé‡\n",
        "            b_new: æ›´æ–°åçš„åç½®\n",
        "        \"\"\"\n",
        "        # TODO: å®ç°SGDæ›´æ–°å…¬å¼\n",
        "        # w_new = w - self.lr * grad_w\n",
        "        # b_new = b - self.lr * grad_b\n",
        "        # return w_new, b_new\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡4ï¼šå®ç°è®­ç»ƒå‡½æ•°ï¼ˆæ”¯æŒä¸åŒæ‰¹é‡å¤§å°ï¼‰\n",
        "\n",
        "### è®­ç»ƒæµç¨‹\n",
        "\n",
        "1. å°†æ•°æ®é›†åˆ’åˆ†ä¸ºå¤šä¸ªæ‰¹æ¬¡\n",
        "2. å¯¹æ¯ä¸ªæ‰¹æ¬¡ï¼š\n",
        "   - è®¡ç®—æ¢¯åº¦\n",
        "   - æ›´æ–°å‚æ•°\n",
        "   - è®°å½•æŸå¤±\n",
        "3. é‡å¤å¤šä¸ªepoch\n",
        "\n",
        "### ä»»åŠ¡è¦æ±‚\n",
        "\n",
        "TODO: å®ç°æ”¯æŒä¸åŒæ‰¹é‡å¤§å°çš„è®­ç»ƒå‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: å®ç°è®­ç»ƒå‡½æ•°\n",
        "def train_with_batch_size(X, y, batch_size, learning_rate=0.01, n_epochs=50):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨æŒ‡å®šæ‰¹é‡å¤§å°è®­ç»ƒæ¨¡å‹\n",
        "    \n",
        "    å‚æ•°:\n",
        "        X: ç‰¹å¾çŸ©é˜µ (n_samples, n_features)\n",
        "        y: ç›®æ ‡å‘é‡ (n_samples,)\n",
        "        batch_size: æ‰¹é‡å¤§å°\n",
        "        learning_rate: å­¦ä¹ ç‡\n",
        "        n_epochs: è®­ç»ƒè½®æ•°\n",
        "    \n",
        "    è¿”å›:\n",
        "        losses: æ¯ä¸ªepochçš„å¹³å‡æŸå¤±\n",
        "        training_time: è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰\n",
        "    \"\"\"\n",
        "    # TODO: åˆå§‹åŒ–å‚æ•°\n",
        "    # n_samples, n_features = X.shape\n",
        "    # w = np.random.randn(n_features) * 0.01\n",
        "    # b = 0.0\n",
        "    # \n",
        "    # TODO: åˆ›å»ºä¼˜åŒ–å™¨\n",
        "    # optimizer = BatchSGD(learning_rate=learning_rate)\n",
        "    # \n",
        "    # TODO: è®°å½•æŸå¤±\n",
        "    # losses = []\n",
        "    # \n",
        "    # TODO: è®°å½•è®­ç»ƒæ—¶é—´\n",
        "    # start_time = time.time()\n",
        "    # \n",
        "    # TODO: è®­ç»ƒå¾ªç¯\n",
        "    # for epoch in range(n_epochs):\n",
        "    #     epoch_losses = []\n",
        "    #     \n",
        "    #     # æ‰“ä¹±æ•°æ®ï¼ˆæ¯ä¸ªepochéƒ½æ‰“ä¹±ï¼‰\n",
        "    #     indices = np.random.permutation(n_samples)\n",
        "    #     X_shuffled = X[indices]\n",
        "    #     y_shuffled = y[indices]\n",
        "    #     \n",
        "    #     # æŒ‰æ‰¹é‡å¤§å°åˆ’åˆ†æ•°æ®\n",
        "    #     for i in range(0, n_samples, batch_size):\n",
        "    #         # è·å–å½“å‰æ‰¹æ¬¡\n",
        "    #         X_batch = X_shuffled[i:i+batch_size]\n",
        "    #         y_batch = y_shuffled[i:i+batch_size]\n",
        "    #         \n",
        "    #         # è®¡ç®—æ¢¯åº¦\n",
        "    #         grad_w, grad_b = compute_gradients(X_batch, y_batch, w, b)\n",
        "    #         \n",
        "    #         # æ›´æ–°å‚æ•°\n",
        "    #         w, b = optimizer.update(w, b, grad_w, grad_b)\n",
        "    #         \n",
        "    #         # è®¡ç®—å¹¶è®°å½•æŸå¤±\n",
        "    #         y_pred = X_batch @ w + b\n",
        "    #         loss = mse_loss(y_batch, y_pred)\n",
        "    #         epoch_losses.append(loss)\n",
        "    #     \n",
        "    #     # è®°å½•æ¯ä¸ªepochçš„å¹³å‡æŸå¤±\n",
        "    #     avg_loss = np.mean(epoch_losses)\n",
        "    #     losses.append(avg_loss)\n",
        "    #     \n",
        "    #     if (epoch + 1) % 10 == 0:\n",
        "    #         print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.6f}, Batch Size: {batch_size}\")\n",
        "    # \n",
        "    # training_time = time.time() - start_time\n",
        "    # return losses, training_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°\n",
        "# batch_sizes = [1, 8, 32, 128, n_samples]  # åŒ…å«SGDã€å°æ‰¹é‡ã€ä¸­ç­‰æ‰¹é‡ã€å¤§æ‰¹é‡ã€BGD\n",
        "# learning_rate = 0.01\n",
        "# n_epochs = 50\n",
        "# \n",
        "# results = {}  # å­˜å‚¨æ¯ä¸ªæ‰¹é‡å¤§å°çš„ç»“æœ\n",
        "# \n",
        "# print(\"=\"*60)\n",
        "# print(\"å¼€å§‹æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°\")\n",
        "# print(\"=\"*60)\n",
        "# \n",
        "# for batch_size in batch_sizes:\n",
        "#     print(f\"\\næµ‹è¯•æ‰¹é‡å¤§å°: {batch_size}\")\n",
        "#     losses, training_time = train_with_batch_size(\n",
        "#         X, y, batch_size, learning_rate, n_epochs\n",
        "#     )\n",
        "#     \n",
        "#     results[batch_size] = {\n",
        "#         'losses': losses,\n",
        "#         'training_time': training_time,\n",
        "#         'final_loss': losses[-1],\n",
        "#         'avg_time_per_epoch': training_time / n_epochs\n",
        "#     }\n",
        "#     \n",
        "#     print(f\"  æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}\")\n",
        "#     print(f\"  æ€»è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’\")\n",
        "#     print(f\"  å¹³å‡æ¯epochæ—¶é—´: {training_time/n_epochs:.4f}ç§’\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡6ï¼šå¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
        "\n",
        "### å¯è§†åŒ–å†…å®¹\n",
        "\n",
        "1. **æŸå¤±æ›²çº¿å¯¹æ¯”**ï¼šä¸åŒæ‰¹é‡å¤§å°çš„æŸå¤±å˜åŒ–\n",
        "2. **è®­ç»ƒæ—¶é—´å¯¹æ¯”**ï¼šæ‰¹é‡å¤§å°ä¸è®­ç»ƒæ—¶é—´çš„å…³ç³»\n",
        "3. **æ”¶æ•›é€Ÿåº¦å¯¹æ¯”**ï¼šè¾¾åˆ°ç›®æ ‡æŸå¤±æ‰€éœ€çš„epochæ•°\n",
        "4. **ç¨³å®šæ€§åˆ†æ**ï¼šæŸå¤±æ›²çº¿çš„å¹³æ»‘ç¨‹åº¦\n",
        "\n",
        "### ä»»åŠ¡è¦æ±‚\n",
        "\n",
        "TODO: å®ç°å®Œæ•´çš„å¯è§†åŒ–ä»£ç \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: å¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
        "# plt.figure(figsize=(16, 10))\n",
        "# \n",
        "# # 1. æŸå¤±æ›²çº¿å¯¹æ¯”\n",
        "# plt.subplot(2, 3, 1)\n",
        "# colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
        "# for i, batch_size in enumerate(batch_sizes):\n",
        "#     label = f'Batch={batch_size}' if batch_size < n_samples else 'BGD (å…¨éƒ¨)'\n",
        "#     plt.plot(results[batch_size]['losses'], \n",
        "#              label=label, color=colors[i], alpha=0.7, linewidth=2)\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('æŸå¤±å€¼')\n",
        "# plt.title('ä¸åŒæ‰¹é‡å¤§å°çš„æŸå¤±æ›²çº¿å¯¹æ¯”')\n",
        "# plt.legend()\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.yscale('log')\n",
        "# \n",
        "# # 2. æœ€ç»ˆæŸå¤±å¯¹æ¯”\n",
        "# plt.subplot(2, 3, 2)\n",
        "# final_losses = [results[bs]['final_loss'] for bs in batch_sizes]\n",
        "# labels = [f'BS={bs}' if bs < n_samples else 'BGD' for bs in batch_sizes]\n",
        "# plt.bar(range(len(batch_sizes)), final_losses, color=colors, alpha=0.7)\n",
        "# plt.xlabel('æ‰¹é‡å¤§å°')\n",
        "# plt.ylabel('æœ€ç»ˆæŸå¤±å€¼')\n",
        "# plt.title('ä¸åŒæ‰¹é‡å¤§å°çš„æœ€ç»ˆæŸå¤±å¯¹æ¯”')\n",
        "# plt.xticks(range(len(batch_sizes)), labels, rotation=45)\n",
        "# plt.grid(True, alpha=0.3, axis='y')\n",
        "# \n",
        "# # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”\n",
        "# plt.subplot(2, 3, 3)\n",
        "# training_times = [results[bs]['training_time'] for bs in batch_sizes]\n",
        "# plt.bar(range(len(batch_sizes)), training_times, color=colors, alpha=0.7)\n",
        "# plt.xlabel('æ‰¹é‡å¤§å°')\n",
        "# plt.ylabel('æ€»è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰')\n",
        "# plt.title('ä¸åŒæ‰¹é‡å¤§å°çš„è®­ç»ƒæ—¶é—´å¯¹æ¯”')\n",
        "# plt.xticks(range(len(batch_sizes)), labels, rotation=45)\n",
        "# plt.grid(True, alpha=0.3, axis='y')\n",
        "# \n",
        "# # 4. å¹³å‡æ¯epochæ—¶é—´å¯¹æ¯”\n",
        "# plt.subplot(2, 3, 4)\n",
        "# avg_times = [results[bs]['avg_time_per_epoch'] for bs in batch_sizes]\n",
        "# plt.bar(range(len(batch_sizes)), avg_times, color=colors, alpha=0.7)\n",
        "# plt.xlabel('æ‰¹é‡å¤§å°')\n",
        "# plt.ylabel('å¹³å‡æ¯epochæ—¶é—´ï¼ˆç§’ï¼‰')\n",
        "# plt.title('ä¸åŒæ‰¹é‡å¤§å°çš„å¹³å‡è®­ç»ƒæ—¶é—´å¯¹æ¯”')\n",
        "# plt.xticks(range(len(batch_sizes)), labels, rotation=45)\n",
        "# plt.grid(True, alpha=0.3, axis='y')\n",
        "# \n",
        "# # 5. æŸå¤±æ›²çº¿å¹³æ»‘åº¦åˆ†æï¼ˆè®¡ç®—æ ‡å‡†å·®ï¼‰\n",
        "# plt.subplot(2, 3, 5)\n",
        "# loss_stds = [np.std(results[bs]['losses']) for bs in batch_sizes]\n",
        "# plt.bar(range(len(batch_sizes)), loss_stds, color=colors, alpha=0.7)\n",
        "# plt.xlabel('æ‰¹é‡å¤§å°')\n",
        "# plt.ylabel('æŸå¤±æ ‡å‡†å·®ï¼ˆç¨³å®šæ€§æŒ‡æ ‡ï¼‰')\n",
        "# plt.title('ä¸åŒæ‰¹é‡å¤§å°çš„è®­ç»ƒç¨³å®šæ€§å¯¹æ¯”\\nï¼ˆæ ‡å‡†å·®è¶Šå°è¶Šç¨³å®šï¼‰')\n",
        "# plt.xticks(range(len(batch_sizes)), labels, rotation=45)\n",
        "# plt.grid(True, alpha=0.3, axis='y')\n",
        "# \n",
        "# # 6. æ‰¹é‡å¤§å°ä¸æ€§èƒ½çš„æƒè¡¡\n",
        "# plt.subplot(2, 3, 6)\n",
        "# # ç»˜åˆ¶æ‰¹é‡å¤§å° vs æœ€ç»ˆæŸå¤±çš„æ•£ç‚¹å›¾\n",
        "# plt.scatter(batch_sizes, final_losses, s=100, c=colors, alpha=0.7)\n",
        "# for i, bs in enumerate(batch_sizes):\n",
        "#     plt.annotate(f'BS={bs}', (bs, final_losses[i]), \n",
        "#                  textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
        "# plt.xlabel('æ‰¹é‡å¤§å°')\n",
        "# plt.ylabel('æœ€ç»ˆæŸå¤±å€¼')\n",
        "# plt.title('æ‰¹é‡å¤§å°ä¸æœ€ç»ˆæ€§èƒ½çš„å…³ç³»')\n",
        "# plt.grid(True, alpha=0.3)\n",
        "# plt.xscale('log')\n",
        "# \n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä»»åŠ¡7ï¼šåˆ†æç»“æœå¹¶æ€»ç»“\n",
        "\n",
        "### åˆ†æè¦ç‚¹\n",
        "\n",
        "1. **æ‰¹é‡å¤§å°ä¸æ”¶æ•›é€Ÿåº¦**ï¼š\n",
        "   - æ‰¹é‡å¤§å°å¤§ï¼šæ¯ä¸ªepochçš„æ›´æ–°æ¬¡æ•°å°‘ï¼Œä½†æ¯æ¬¡æ›´æ–°æ›´å‡†ç¡®\n",
        "   - æ‰¹é‡å¤§å°å°ï¼šæ¯ä¸ªepochçš„æ›´æ–°æ¬¡æ•°å¤šï¼Œä½†æ¯æ¬¡æ›´æ–°å™ªå£°å¤§\n",
        "\n",
        "2. **æ‰¹é‡å¤§å°ä¸è®­ç»ƒç¨³å®šæ€§**ï¼š\n",
        "   - æ‰¹é‡å¤§å°å¤§ï¼šæ¢¯åº¦ä¼°è®¡å‡†ç¡®ï¼ŒæŸå¤±æ›²çº¿å¹³æ»‘\n",
        "   - æ‰¹é‡å¤§å°å°ï¼šæ¢¯åº¦ä¼°è®¡å™ªå£°å¤§ï¼ŒæŸå¤±æ›²çº¿æ³¢åŠ¨å¤§\n",
        "\n",
        "3. **æ‰¹é‡å¤§å°ä¸è®­ç»ƒæ—¶é—´**ï¼š\n",
        "   - æ‰¹é‡å¤§å°å¤§ï¼šæ¯ä¸ªepochæ—¶é—´çŸ­ï¼ˆæ›´æ–°æ¬¡æ•°å°‘ï¼‰ï¼Œä½†å¯èƒ½æ”¶æ•›æ…¢\n",
        "   - æ‰¹é‡å¤§å°å°ï¼šæ¯ä¸ªepochæ—¶é—´é•¿ï¼ˆæ›´æ–°æ¬¡æ•°å¤šï¼‰ï¼Œä½†å¯èƒ½æ”¶æ•›å¿«\n",
        "\n",
        "4. **æ‰¹é‡å¤§å°é€‰æ‹©çš„æƒè¡¡**ï¼š\n",
        "   - éœ€è¦å¹³è¡¡ï¼šè®¡ç®—æ•ˆç‡ã€å†…å­˜å ç”¨ã€æ”¶æ•›é€Ÿåº¦ã€è®­ç»ƒç¨³å®šæ€§\n",
        "\n",
        "### ä»»åŠ¡è¦æ±‚\n",
        "\n",
        "TODO: åˆ†æå®éªŒç»“æœï¼Œæ€»ç»“æ‰¹é‡å¤§å°çš„å½±å“è§„å¾‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: åˆ†æç»“æœ\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"æ‰¹é‡å¤§å°å½±å“åˆ†ææ€»ç»“\")\n",
        "# print(\"=\"*60)\n",
        "# \n",
        "# print(f\"\\n{'æ‰¹é‡å¤§å°':<12} {'æœ€ç»ˆæŸå¤±':<15} {'è®­ç»ƒæ—¶é—´':<15} {'ç¨³å®šæ€§(æ ‡å‡†å·®)':<20}\")\n",
        "# print(\"-\" * 70)\n",
        "# for bs in batch_sizes:\n",
        "#     label = f'{bs}' if bs < n_samples else 'BGD(å…¨éƒ¨)'\n",
        "#     print(f\"{label:<12} {results[bs]['final_loss']:<15.6f} \"\n",
        "#           f\"{results[bs]['training_time']:<15.2f} \"\n",
        "#           f\"{np.std(results[bs]['losses']):<20.6f}\")\n",
        "# \n",
        "# print(\"\\nå…³é”®è§‚å¯Ÿ:\")\n",
        "# print(\"1. æ‰¹é‡å¤§å°å¯¹è®­ç»ƒç¨³å®šæ€§çš„å½±å“ï¼š\")\n",
        "# print(\"   - æ‰¹é‡å¤§å°è¶Šå¤§ï¼ŒæŸå¤±æ›²çº¿è¶Šå¹³æ»‘ï¼ˆæ ‡å‡†å·®è¶Šå°ï¼‰\")\n",
        "# print(\"   - æ‰¹é‡å¤§å°è¶Šå°ï¼ŒæŸå¤±æ›²çº¿æ³¢åŠ¨è¶Šå¤§ï¼ˆæ ‡å‡†å·®è¶Šå¤§ï¼‰\")\n",
        "# \n",
        "# print(\"\\n2. æ‰¹é‡å¤§å°å¯¹è®­ç»ƒæ—¶é—´çš„å½±å“ï¼š\")\n",
        "# print(\"   - æ‰¹é‡å¤§å°è¶Šå¤§ï¼Œæ¯ä¸ªepochçš„æ›´æ–°æ¬¡æ•°è¶Šå°‘ï¼Œä½†æ¯æ¬¡æ›´æ–°è®¡ç®—é‡å¤§\")\n",
        "# print(\"   - æ‰¹é‡å¤§å°è¶Šå°ï¼Œæ¯ä¸ªepochçš„æ›´æ–°æ¬¡æ•°è¶Šå¤šï¼Œä½†æ¯æ¬¡æ›´æ–°è®¡ç®—é‡å°\")\n",
        "# \n",
        "# print(\"\\n3. æ‰¹é‡å¤§å°é€‰æ‹©çš„å»ºè®®ï¼š\")\n",
        "# print(\"   - å°æ•°æ®é›†ï¼šå¯ä»¥ä½¿ç”¨è¾ƒå¤§çš„æ‰¹é‡å¤§å°ï¼ˆæ¥è¿‘BGDï¼‰\")\n",
        "# print(\"   - å¤§æ•°æ®é›†ï¼šé€šå¸¸ä½¿ç”¨32ã€64ã€128ç­‰ä¸­ç­‰æ‰¹é‡å¤§å°\")\n",
        "# print(\"   - å†…å­˜å—é™ï¼šä½¿ç”¨è¾ƒå°çš„æ‰¹é‡å¤§å°ï¼ˆ8ã€16ï¼‰\")\n",
        "# print(\"   - è¿½æ±‚ç¨³å®šæ€§ï¼šä½¿ç”¨è¾ƒå¤§çš„æ‰¹é‡å¤§å°\")\n",
        "# print(\"   - è¿½æ±‚é€Ÿåº¦ï¼šä½¿ç”¨è¾ƒå°çš„æ‰¹é‡å¤§å°ï¼ˆä½†éœ€è¦æ›´å¤šepochï¼‰\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ€»ç»“ä¸æ€è€ƒ\n",
        "\n",
        "### å…³é”®çŸ¥è¯†ç‚¹å›é¡¾\n",
        "\n",
        "1. **ä¸‰ç§æ¢¯åº¦ä¸‹é™æ–¹æ³•**ï¼š\n",
        "   - BGDï¼ˆæ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼‰ï¼šä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œæ¢¯åº¦å‡†ç¡®ä½†æ…¢\n",
        "   - SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰ï¼šä½¿ç”¨å•ä¸ªæ ·æœ¬ï¼Œæ¢¯åº¦å™ªå£°å¤§ä½†å¿«\n",
        "   - Mini-batch GDï¼ˆå°æ‰¹é‡æ¢¯åº¦ä¸‹é™ï¼‰ï¼šå¹³è¡¡å‡†ç¡®æ€§å’Œé€Ÿåº¦\n",
        "\n",
        "2. **æ‰¹é‡å¤§å°çš„å½±å“**ï¼š\n",
        "   - **ç¨³å®šæ€§**ï¼šæ‰¹é‡å¤§ â†’ æ¢¯åº¦å‡†ç¡® â†’ è®­ç»ƒç¨³å®š\n",
        "   - **é€Ÿåº¦**ï¼šæ‰¹é‡å° â†’ æ›´æ–°æ¬¡æ•°å¤š â†’ å¯èƒ½æ”¶æ•›å¿«\n",
        "   - **å†…å­˜**ï¼šæ‰¹é‡å¤§ â†’ å†…å­˜å ç”¨å¤§\n",
        "   - **æ³›åŒ–**ï¼šæ‰¹é‡å°å¯èƒ½æœ‰åŠ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œæå‡æ³›åŒ–\n",
        "\n",
        "3. **æ‰¹é‡å¤§å°é€‰æ‹©åŸåˆ™**ï¼š\n",
        "   - æ ¹æ®æ•°æ®é›†å¤§å°ã€å†…å­˜é™åˆ¶ã€è®­ç»ƒç›®æ ‡é€‰æ‹©\n",
        "   - å¸¸è§é€‰æ‹©ï¼š32, 64, 128, 256\n",
        "   - éœ€è¦å®éªŒæ‰¾åˆ°æœ€ä½³å€¼\n",
        "\n",
        "### æ€è€ƒé—®é¢˜\n",
        "\n",
        "1. **ä¸ºä»€ä¹ˆæ‰¹é‡å¤§å°ä¼šå½±å“æ¢¯åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Ÿ**\n",
        "   - æç¤ºï¼šæ€è€ƒå¤§æ•°å®šå¾‹å’Œä¸­å¿ƒæé™å®šç†\n",
        "\n",
        "2. **æ‰¹é‡å¤§å°ä¸å­¦ä¹ ç‡æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ**\n",
        "   - æ‰¹é‡å¤§æ—¶ï¼Œæ˜¯å¦åº”è¯¥è°ƒæ•´å­¦ä¹ ç‡ï¼Ÿ\n",
        "\n",
        "3. **åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¦‚ä½•é€‰æ‹©æ‰¹é‡å¤§å°ï¼Ÿ**\n",
        "   - è€ƒè™‘å“ªäº›å› ç´ ï¼Ÿ\n",
        "\n",
        "4. **æ‰¹é‡å¤§å°å¯¹æ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ**\n",
        "   - ä¸ºä»€ä¹ˆå°æ‰¹é‡å¯èƒ½æœ‰åŠ©äºæ³›åŒ–ï¼Ÿ\n",
        "\n",
        "### æ‰©å±•ä»»åŠ¡\n",
        "\n",
        "- ç ”ç©¶æ‰¹é‡å½’ä¸€åŒ–ï¼ˆBatchNormï¼‰ä¸æ‰¹é‡å¤§å°çš„å…³ç³»\n",
        "- å®ç°è‡ªé€‚åº”æ‰¹é‡å¤§å°ç­–ç•¥\n",
        "- å¯¹æ¯”ä¸åŒæ‰¹é‡å¤§å°åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸Šçš„æ•ˆæœ\n",
        "- ç ”ç©¶æ‰¹é‡å¤§å°ä¸å­¦ä¹ ç‡è°ƒåº¦çš„å…³ç³»\n",
        "\n",
        "---\n",
        "\n",
        "**å®Œæˆæœ¬ç»ƒä¹ åï¼Œä½ å°†æ·±å…¥ç†è§£æ‰¹é‡å¤§å°å¯¹ä¼˜åŒ–è¿‡ç¨‹çš„å½±å“ï¼** ğŸ‰\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
