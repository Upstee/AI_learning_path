# CNNå¿«é€Ÿä¸Šæ‰‹

> **ç›®æ ‡**ï¼š30åˆ†é’Ÿå†…å¿«é€Ÿä½“éªŒCNNï¼Œå»ºç«‹å­¦ä¹ ä¿¡å¿ƒï¼Œæ˜ç¡®å­¦ä¹ ç›®æ ‡

---

## ğŸš€ 30åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

### æ­¥éª¤1ï¼šå®‰è£…ä¾èµ–ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
pip install torch torchvision matplotlib
```

### æ­¥éª¤2ï¼šè¿è¡Œç¬¬ä¸€ä¸ªCNNï¼ˆ10åˆ†é’Ÿï¼‰

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# åŠ è½½æ•°æ®ï¼ˆMNISTæ‰‹å†™æ•°å­—ï¼‰
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# å®šä¹‰CNNï¼ˆåªéœ€è¦å‡ è¡Œä»£ç ï¼ï¼‰
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 32 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒä¸€ä¸ªepoch
model.train()
for images, labels in train_loader:
    optimizer.zero_grad()
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
    break  # åªè®­ç»ƒä¸€ä¸ªbatch

print("âœ… æˆåŠŸï¼ä½ å·²ç»ç”¨CNNè®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼")

# å¯è§†åŒ–å·ç§¯å±‚
model.eval()
with torch.no_grad():
    sample_image, _ = next(iter(train_loader))
    sample_image = sample_image[0:1]
    
    # è·å–ç¬¬ä¸€å±‚å·ç§¯çš„è¾“å‡º
    conv1_output = model.conv1(sample_image)
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(1, 9, figsize=(15, 2))
    axes[0].imshow(sample_image[0, 0].numpy(), cmap='gray')
    axes[0].set_title('è¾“å…¥å›¾åƒ')
    axes[0].axis('off')
    
    for i in range(8):
        axes[i+1].imshow(conv1_output[0, i].numpy(), cmap='viridis')
        axes[i+1].set_title(f'ç‰¹å¾å›¾{i+1}')
        axes[i+1].axis('off')
    
    plt.tight_layout()
    plt.show()
```

**è¿è¡Œç»“æœ**ï¼šä½ ä¼šçœ‹åˆ°CNNæˆåŠŸæå–äº†å›¾åƒç‰¹å¾ï¼

### æ­¥éª¤3ï¼šç†è§£å·ç§¯æ“ä½œï¼ˆ10åˆ†é’Ÿï¼‰

```python
# å¯è§†åŒ–å·ç§¯æ“ä½œ
import torch.nn.functional as F

# åˆ›å»ºä¸€ä¸ªç®€å•çš„å›¾åƒ
image = torch.zeros(1, 1, 5, 5)
image[0, 0, 2, 2] = 1  # ä¸­å¿ƒç‚¹

# åˆ›å»ºä¸€ä¸ªç®€å•çš„å·ç§¯æ ¸ï¼ˆè¾¹ç¼˜æ£€æµ‹ï¼‰
kernel = torch.tensor([[-1, -1, -1],
                       [-1,  8, -1],
                       [-1, -1, -1]]).float().unsqueeze(0).unsqueeze(0)

# å·ç§¯æ“ä½œ
output = F.conv2d(image, kernel, padding=1)

# å¯è§†åŒ–
fig, axes = plt.subplots(1, 3, figsize=(12, 4))
axes[0].imshow(image[0, 0].numpy(), cmap='gray')
axes[0].set_title('è¾“å…¥å›¾åƒ')
axes[1].imshow(kernel[0, 0].numpy(), cmap='gray')
axes[1].set_title('å·ç§¯æ ¸')
axes[2].imshow(output[0, 0].numpy(), cmap='viridis')
axes[2].set_title('å·ç§¯è¾“å‡º')
plt.show()
```

**è§‚å¯Ÿ**ï¼š
- å·ç§¯æ ¸åœ¨å›¾åƒä¸Šæ»‘åŠ¨
- æ¯ä¸ªä½ç½®è®¡ç®—ç‚¹ç§¯
- è¾“å‡ºæ˜¯ç‰¹å¾å›¾

---

## ğŸ¯ ç†è§£CNNåœ¨åšä»€ä¹ˆ

### ç›´è§‚ç†è§£

**CNNå°±åƒ"ç‰¹å¾æå–å™¨"**ï¼š
1. **å·ç§¯å±‚**ï¼šæå–å±€éƒ¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ç­‰ï¼‰
2. **æ± åŒ–å±‚**ï¼šé™ä½ç»´åº¦ï¼Œä¿ç•™é‡è¦ä¿¡æ¯
3. **å…¨è¿æ¥å±‚**ï¼šç»„åˆç‰¹å¾ï¼Œè¿›è¡Œåˆ†ç±»

**ç±»æ¯”**ï¼š
- å°±åƒäººçœ‹å›¾åƒï¼šå…ˆçœ‹å±€éƒ¨ï¼ˆè¾¹ç¼˜ã€è§’ç‚¹ï¼‰ï¼Œå†çœ‹æ•´ä½“ï¼ˆå½¢çŠ¶ã€ç‰©ä½“ï¼‰

---

## ğŸ“‹ å»ºç«‹å­¦ä¹ ç›®æ ‡

å®Œæˆå¿«é€Ÿä¸Šæ‰‹åï¼Œä½ åº”è¯¥ï¼š

### âœ… å·²ç»èƒ½åšåˆ°
- [x] ä½¿ç”¨PyTorchå®šä¹‰CNN
- [x] ç†è§£CNNçš„åŸºæœ¬ç»“æ„
- [x] çŸ¥é“CNNå¯ä»¥æå–å›¾åƒç‰¹å¾

### ğŸ¯ æ¥ä¸‹æ¥è¦å­¦
- [ ] **ç†è§£åŸç†**ï¼šå·ç§¯ã€æ± åŒ–çš„æ•°å­¦åŸç†
- [ ] **ç»å…¸æ¶æ„**ï¼šLeNetã€AlexNetã€VGGã€ResNet
- [ ] **å®é™…åº”ç”¨**ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ç­‰

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **å…ˆä½“éªŒå†å­¦ä¹ **ï¼šä½ å·²ç»è¿è¡Œäº†ä»£ç ï¼Œçœ‹åˆ°äº†æ•ˆæœ
2. **ç†è§£å·ç§¯**ï¼šç†è§£å·ç§¯æ“ä½œçš„æ•°å­¦åŸç†
3. **å¯è§†åŒ–ç‰¹å¾**ï¼šè§‚å¯ŸCNNæå–çš„ç‰¹å¾å›¾
4. **å®è·µåº”ç”¨**ï¼šåœ¨çœŸå®å›¾åƒæ•°æ®ä¸Šè®­ç»ƒ

---

## âš ï¸ å¸¸è§é—®é¢˜

**Q: å·ç§¯å’Œå…¨è¿æ¥æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**
A: å·ç§¯æ˜¯å±€éƒ¨è¿æ¥ã€å‚æ•°å…±äº«ï¼›å…¨è¿æ¥æ˜¯å…¨å±€è¿æ¥ã€å‚æ•°ç‹¬ç«‹ã€‚

**Q: ä¸ºä»€ä¹ˆCNNé€‚åˆå›¾åƒï¼Ÿ**
A: CNNåˆ©ç”¨äº†å›¾åƒçš„å±€éƒ¨æ€§å’Œå¹³ç§»ä¸å˜æ€§ã€‚

**Q: å¦‚ä½•é€‰æ‹©CNNæ¶æ„ï¼Ÿ**
A: æ ¹æ®ä»»åŠ¡å’Œæ•°æ®é€‰æ‹©ï¼Œå¯ä»¥ä»ç®€å•æ¶æ„å¼€å§‹ã€‚

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿç°åœ¨å¼€å§‹æ­£å¼å­¦ä¹ CNNçš„åŸç†å’Œå®ç°ï¼** ğŸš€
