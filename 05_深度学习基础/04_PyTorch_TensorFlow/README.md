# PyTorch与TensorFlow深度学习框架

> **🎯 快速开始**：如果你是第一次学习深度学习框架，建议先完成[快速上手](./00_快速上手.md)（30分钟），快速体验效果，建立学习信心！

---

## 📚 学习资源导航

- **[快速上手](./00_快速上手.md)** - 30分钟快速体验，建立学习信心
- **[学习检查点](./学习检查点.md)** - 自我评估，确保真正掌握
- **[常见问题FAQ](./常见问题FAQ.md)** - 快速解决学习中的问题
- **[神经网络可视化工具](../01_神经网络基础/神经网络可视化工具.md)** - 可视化网络结构
- **[训练过程监控指南](../01_神经网络基础/训练过程监控指南.md)** - 监控训练过程
- **[调试技巧和常见错误](../01_神经网络基础/调试技巧和常见错误.md)** - 调试技巧

---

## ⚠️ 模块说明

本模块是优化后的结构，**框架学习提前到第2位**（原第4位），对应优化后的学习路径：
- 先理解原理（从零实现）→ 掌握工具（框架）→ 应用工具（CNN/RNN）

**优化理由**：学习CNN和RNN时需要框架支持，框架应该提前学习，提高学习效率和实践能力。

---

## 1. 课程概述

### 课程目标

1. **掌握PyTorch基础**
   - 理解张量（Tensor）的概念和操作
   - 掌握自动梯度系统（autograd）
   - 能够使用PyTorch构建和训练神经网络
   - 理解PyTorch的动态计算图

2. **掌握TensorFlow基础**
   - 理解TensorFlow的计算图模型
   - 掌握TensorFlow 2.x的Eager Execution
   - 能够使用TensorFlow构建和训练模型
   - 理解Keras高级API

3. **框架对比与选择**
   - 理解PyTorch和TensorFlow的优缺点
   - 能够根据项目需求选择合适的框架
   - 理解两个框架的适用场景

### 预计学习时间

- **理论学习**：10-12小时（PyTorch 4-5小时 + TensorFlow 4-5小时 + 对比 2小时）
- **代码实践**：15-20小时
- **练习巩固**：10-12小时
- **总计**：35-44小时（约1-2周）

### 难度等级

- **中等** - 需要理解框架的设计理念和使用方法

### 课程定位

- **前置课程**：01_神经网络基础（理解原理，从零实现）
- **后续课程**：02_CNN、03_RNN_LSTM（使用框架实现）
- **在体系中的位置**：从手动实现到框架使用的桥梁，为后续学习提供工具支持

### 学完能做什么

- ✅ 能够使用PyTorch构建和训练神经网络
- ✅ 能够使用TensorFlow构建和训练模型
- ✅ 理解两个框架的设计理念和差异
- ✅ 能够根据项目需求选择合适的框架
- ✅ 能够使用框架实现CNN、RNN等架构
- ✅ 为后续专业方向学习打下坚实基础

---

## 2. 前置知识检查

### 必备前置概念清单

- **神经网络基础**：前向传播、反向传播、自动梯度
- **Python基础**：类、装饰器、上下文管理器
- **NumPy**：数组操作、矩阵运算

### 回顾链接/跳转

- 如果不熟悉神经网络基础：[01_神经网络基础](../01_神经网络基础/)
- 如果不熟悉NumPy：[03_数据处理基础/01_NumPy](../../03_数据处理基础/01_NumPy/)

### 2.5 知识关联

#### 前置知识依赖链

**直接前置**：
- [神经网络基础](../01_神经网络基础/) - 理解原理，从零实现
  - [感知器与神经元](../01_神经网络基础/01_感知器与神经元/) - 理解基本单元
  - [前馈神经网络](../01_神经网络基础/02_前馈神经网络/) - 理解网络结构
  - [自动梯度与优化](../01_神经网络基础/03_自动梯度与优化/) - 理解自动梯度原理

**间接前置**：
- [NumPy](../../03_数据处理基础/01_NumPy/) - 数组操作基础
- [Python基础](../../01_Python进阶/) - 面向对象编程

#### 相关概念交叉引用

**本模块核心概念**：
- **张量（Tensor）**：本模块首次详细讲解，是框架的核心数据结构
- **自动梯度（Autograd）**：基于[自动梯度与优化](../01_神经网络基础/03_自动梯度与优化/)的原理
- **计算图**：基于[自动梯度与优化/计算图](../01_神经网络基础/03_自动梯度与优化/#计算图)的概念

**相关概念**：
- **前向传播**：[前馈神经网络/前向传播](../01_神经网络基础/02_前馈神经网络/#前向传播算法) - 框架自动实现
- **反向传播**：[前馈神经网络/反向传播](../01_神经网络基础/02_前馈神经网络/#反向传播算法) - 框架自动实现
- **优化算法**：[网络优化](../../05_网络优化与正则化/01_网络优化/) - 框架提供的优化器

#### 后续应用场景

**直接后续**（所有使用框架的模块）：
- [CNN](../02_CNN/) - 使用框架实现CNN
- [RNN](../03_RNN_LSTM/) - 使用框架实现RNN
- [Transformer](../06_注意力机制与外部记忆/02_Transformer架构/) - 使用框架实现Transformer

**专业方向应用**：
- [计算机视觉](../../06_计算机视觉/) - 使用框架构建CV模型
- [自然语言处理](../../07_自然语言处理/) - 使用框架构建NLP模型
- [强化学习](../../08_强化学习/) - 使用框架构建RL模型

**优化应用**：
- [网络优化](../05_网络优化与正则化/01_网络优化/) - 使用框架的优化器
- [超参数优化](../05_网络优化与正则化/05_超参数优化/) - 调优框架模型

### 入门小测

**选择题**（每题2分，共10分）

1. PyTorch的主要特点是？
   A. 静态计算图  B. 动态计算图  C. 只有CPU支持  D. 不支持GPU
   **答案**：B
   **解释**：PyTorch使用动态计算图，更灵活，适合研究和实验。

2. TensorFlow 2.x的主要改进是？
   A. 移除Eager Execution  B. 引入Eager Execution  C. 移除Keras  D. 只支持静态图
   **答案**：B
   **解释**：TensorFlow 2.x引入Eager Execution，使开发更简单，类似PyTorch。

3. 张量（Tensor）是？
   A. 标量  B. 多维数组  C. 矩阵  D. 向量
   **答案**：B
   **解释**：张量是多维数组的泛化，可以是标量（0维）、向量（1维）、矩阵（2维）等。

**评分标准**：≥8分（80%）为通过

---

## 3. 核心知识点详解

### 3.1 PyTorch基础

#### 3.1.1 PyTorch简介

**PyTorch**是Facebook开发的深度学习框架，特点：
- **动态计算图**：更灵活，适合研究和实验
- **Pythonic**：代码简洁，易于理解
- **研究友好**：学术界广泛使用

#### 3.1.2 张量（Tensor）

**张量**是PyTorch的核心数据结构，类似于NumPy数组，但支持GPU加速。

**创建张量**：
```python
import torch

# 从列表创建
x = torch.tensor([1, 2, 3])

# 从NumPy创建
import numpy as np
x = torch.from_numpy(np.array([1, 2, 3]))

# 随机初始化
x = torch.randn(3, 4)  # 3x4的正态分布随机数
```

#### 3.1.3 自动梯度（Autograd）

**核心概念**：`requires_grad=True` 启用自动梯度计算。

```python
x = torch.tensor([1.0, 2.0], requires_grad=True)
y = x.sum()
y.backward()  # 自动计算梯度
print(x.grad)  # 梯度：[1.0, 1.0]
```

#### 3.1.4 构建神经网络

**使用nn.Module**：
```python
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

### 3.2 TensorFlow基础

#### 3.2.1 TensorFlow简介

**TensorFlow**是Google开发的深度学习框架，特点：
- **静态计算图**（TF 1.x）→ **动态计算图**（TF 2.x）
- **生产就绪**：工业界广泛使用
- **Keras集成**：高级API，易于使用

#### 3.2.2 TensorFlow 2.x

**主要改进**：
- Eager Execution（默认启用）
- Keras作为高级API
- 简化API，更Pythonic

#### 3.2.3 构建神经网络

**使用Keras**：
```python
import tensorflow as tf
from tensorflow import keras

model = keras.Sequential([
    keras.layers.Dense(128, activation='relu', input_shape=(784,)),
    keras.layers.Dense(10, activation='softmax')
])
```

### 3.3 框架对比

| 特性 | PyTorch | TensorFlow |
|------|---------|-----------|
| **计算图** | 动态 | 动态（TF 2.x） |
| **易用性** | 简单直观 | 简单（TF 2.x） |
| **研究** | 更适合 | 适合 |
| **生产** | 适合 | 更适合 |
| **社区** | 研究社区 | 工业界 |
| **学习曲线** | 平缓 | 中等 |

---

## 4. Python代码实践

详细代码请参考各子模块的 `代码示例/` 文件夹：
- `01_PyTorch基础/代码示例/`
- `02_TensorFlow基础/代码示例/`

---

## 5. 动手练习（分层次）

### 基础练习（3-5题）

#### 练习1：PyTorch张量操作
**目标**：熟悉PyTorch的基本操作

**难度**：⭐⭐

#### 练习2：TensorFlow张量操作
**目标**：熟悉TensorFlow的基本操作

**难度**：⭐⭐

#### 练习3：使用PyTorch构建简单网络
**难度**：⭐⭐⭐

#### 练习4：使用TensorFlow构建简单网络
**难度**：⭐⭐⭐

### 进阶练习（2-3题）

#### 练习1：对比PyTorch和TensorFlow实现
**目标**：用两个框架实现相同的网络，对比差异

**难度**：⭐⭐⭐⭐

### 挑战练习（1-2题）

#### 练习1：实现自定义层和损失函数
**难度**：⭐⭐⭐⭐⭐

---

## 6. 实际案例

详细内容请参考各子模块的 `实战案例/` 文件夹

---

## 7. 自我评估

详细评估题目请参考各子模块的 `自我评估/` 文件夹

---

## 8. 拓展学习

### 论文推荐

1. **PyTorch相关论文和文档**
2. **TensorFlow相关论文和文档**

### 书籍推荐

1. **《深度学习框架PyTorch：入门与实践》**
2. **《TensorFlow实战》**

### 官方资源

1. **PyTorch官方文档**：https://pytorch.org/docs/
2. **TensorFlow官方文档**：https://www.tensorflow.org/

### 下节课预告

**下节课**：`02_CNN`

**内容预告**：
- 使用PyTorch/TensorFlow实现CNN
- 卷积层、池化层
- 经典CNN架构

**学习建议**：
1. 选择一个框架深入学习（建议PyTorch，更简单）
2. 另一个框架了解即可
3. 多动手实践，熟悉框架API
4. 为后续CNN/RNN学习做好准备

---

**继续学习，成为深度学习专家！** 🚀

