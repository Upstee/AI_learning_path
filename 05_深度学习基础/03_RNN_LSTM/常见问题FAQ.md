# RNN/LSTM常见问题FAQ

> **目的**：快速解决学习过程中的常见问题

---

## 概念理解问题

### Q1: RNN和LSTM有什么区别？

**A**: 

| 特性 | RNN | LSTM |
|------|-----|------|
| **梯度问题** | 梯度消失 | 解决梯度消失 |
| **长序列** | 难以处理 | 可以处理 |
| **复杂度** | 简单 | 复杂 |
| **应用** | 短序列 | 长序列 |

**建议**：现在通常直接使用LSTM

---

### Q2: LSTM的门控机制是什么？

**A**: 

**三个门**：
1. **遗忘门**：决定丢弃什么信息
2. **输入门**：决定存储什么新信息
3. **输出门**：决定输出什么信息

**作用**：选择性记忆，解决梯度消失

---

### Q3: 如何选择RNN、LSTM、GRU？

**A**: 

**选择建议**：
- **RNN**：简单任务，短序列
- **LSTM**：复杂任务，长序列（推荐）
- **GRU**：LSTM的简化版，效果相近

---

## 代码实现问题

### Q4: 如何处理变长序列？

**A**: 

```python
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence

# 填充序列
padded = pad_sequence(sequences, batch_first=True)

# 打包（用于RNN）
packed = pack_padded_sequence(padded, lengths, batch_first=True)
output, hidden = rnn(packed)
```

---

### Q5: 如何选择hidden_size？

**A**: 

**建议**：
- 小任务：32-64
- 中等任务：128-256
- 大任务：512+

**实验**：从小的开始，逐步增加

---

## 实际应用问题

### Q6: RNN/LSTM在哪些场景中应用？

**A**: 

**常见应用**：
1. **文本分类**：情感分析、垃圾邮件检测
2. **机器翻译**：序列到序列翻译
3. **时间序列预测**：股票、 weather
4. **语音识别**：识别语音内容

---

## 错误排查

### Q7: 梯度消失问题

**A**: 

**症状**：训练很慢，损失不下降

**解决**：
1. 使用LSTM或GRU
2. 梯度裁剪
3. 使用残差连接

---

## 📖 更多资源

- **快速上手**：[00_快速上手.md](./00_快速上手.md)
- **学习检查点**：[学习检查点.md](./学习检查点.md)
- **训练监控**：[../01_神经网络基础/训练过程监控指南.md](../01_神经网络基础/训练过程监控指南.md)

---

**如果这里没有你遇到的问题，请查看其他资源！** 💪
