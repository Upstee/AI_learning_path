# RNN/LSTMå¿«é€Ÿä¸Šæ‰‹

> **ç›®æ ‡**ï¼š30åˆ†é’Ÿå†…å¿«é€Ÿä½“éªŒRNN/LSTMï¼Œå»ºç«‹å­¦ä¹ ä¿¡å¿ƒï¼Œæ˜ç¡®å­¦ä¹ ç›®æ ‡

---

## ğŸš€ 30åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

### æ­¥éª¤1ï¼šå®‰è£…ä¾èµ–ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
pip install torch torchvision matplotlib
```

### æ­¥éª¤2ï¼šè¿è¡Œç¬¬ä¸€ä¸ªRNNï¼ˆ10åˆ†é’Ÿï¼‰

```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt

# ç”Ÿæˆåºåˆ—æ•°æ®ï¼ˆæ­£å¼¦æ³¢ï¼‰
time_steps = 100
x = np.linspace(0, 4*np.pi, time_steps)
y = np.sin(x) + np.random.normal(0, 0.1, time_steps)

# å‡†å¤‡æ•°æ®
def create_sequences(data, seq_length=10):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

X, y = create_sequences(y, seq_length=10)
X = torch.FloatTensor(X).unsqueeze(-1)  # (batch, seq, features)
y = torch.FloatTensor(y)

# å®šä¹‰RNNï¼ˆåªéœ€è¦å‡ è¡Œä»£ç ï¼ï¼‰
class SimpleRNN(nn.Module):
    def __init__(self, input_size=1, hidden_size=32, num_layers=1):
        super(SimpleRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])  # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        return out

model = SimpleRNN()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# è®­ç»ƒ
model.train()
for epoch in range(100):
    optimizer.zero_grad()
    outputs = model(X)
    loss = criterion(outputs.squeeze(), y)
    loss.backward()
    optimizer.step()
    
    if epoch % 20 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')

# é¢„æµ‹
model.eval()
with torch.no_grad():
    predictions = model(X)

# å¯è§†åŒ–
plt.figure(figsize=(12, 5))
plt.plot(y.numpy(), label='çœŸå®å€¼', alpha=0.7)
plt.plot(predictions.squeeze().numpy(), label='é¢„æµ‹å€¼', alpha=0.7)
plt.legend()
plt.title('RNNåºåˆ—é¢„æµ‹')
plt.xlabel('æ—¶é—´æ­¥')
plt.ylabel('å€¼')
plt.grid(True, alpha=0.3)
plt.show()

print("âœ… æˆåŠŸï¼ä½ å·²ç»ç”¨RNNé¢„æµ‹äº†åºåˆ—æ•°æ®ï¼")
```

### æ­¥éª¤3ï¼šä½¿ç”¨LSTMï¼ˆ10åˆ†é’Ÿï¼‰

```python
# ä½¿ç”¨LSTMï¼ˆåªéœ€è¦æ”¹ä¸€è¡Œä»£ç ï¼ï¼‰
class SimpleLSTM(nn.Module):
    def __init__(self, input_size=1, hidden_size=32, num_layers=1):
        super(SimpleLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return out

model_lstm = SimpleLSTM()
optimizer = optim.Adam(model_lstm.parameters(), lr=0.01)

# è®­ç»ƒLSTM
for epoch in range(100):
    optimizer.zero_grad()
    outputs = model_lstm(X)
    loss = criterion(outputs.squeeze(), y)
    loss.backward()
    optimizer.step()

# å¯¹æ¯”RNNå’ŒLSTM
with torch.no_grad():
    rnn_pred = model(X)
    lstm_pred = model_lstm(X)

plt.figure(figsize=(12, 5))
plt.plot(y.numpy(), label='çœŸå®å€¼', alpha=0.7)
plt.plot(rnn_pred.squeeze().numpy(), label='RNNé¢„æµ‹', alpha=0.7)
plt.plot(lstm_pred.squeeze().numpy(), label='LSTMé¢„æµ‹', alpha=0.7)
plt.legend()
plt.title('RNN vs LSTM')
plt.show()

print("âœ… LSTMé€šå¸¸æ¯”RNNæ•ˆæœæ›´å¥½ï¼Œç‰¹åˆ«æ˜¯é•¿åºåˆ—ï¼")
```

---

## ğŸ¯ ç†è§£RNN/LSTMåœ¨åšä»€ä¹ˆ

### ç›´è§‚ç†è§£

**RNNå°±åƒ"æœ‰è®°å¿†çš„ç¥ç»ç½‘ç»œ"**ï¼š
1. **å¤„ç†åºåˆ—**ï¼šé€ä¸ªå¤„ç†åºåˆ—ä¸­çš„æ¯ä¸ªå…ƒç´ 
2. **ä¿æŒçŠ¶æ€**ï¼šè®°ä½ä¹‹å‰çœ‹åˆ°çš„ä¿¡æ¯
3. **é¢„æµ‹æœªæ¥**ï¼šåŸºäºå†å²ä¿¡æ¯é¢„æµ‹ä¸‹ä¸€ä¸ª

**ç±»æ¯”**ï¼š
- å°±åƒè¯»å¥å­ï¼šç†è§£æ¯ä¸ªè¯ï¼ŒåŒæ—¶è®°ä½å‰é¢çš„è¯
- æˆ–è€…åƒå¬éŸ³ä¹ï¼šç†è§£å½“å‰éŸ³ç¬¦ï¼ŒåŒæ—¶è®°ä½æ—‹å¾‹

---

## ğŸ“‹ å»ºç«‹å­¦ä¹ ç›®æ ‡

å®Œæˆå¿«é€Ÿä¸Šæ‰‹åï¼Œä½ åº”è¯¥ï¼š

### âœ… å·²ç»èƒ½åšåˆ°
- [x] ä½¿ç”¨PyTorchå®šä¹‰RNN/LSTM
- [x] ç†è§£RNN/LSTMçš„åŸºæœ¬ç»“æ„
- [x] çŸ¥é“RNN/LSTMå¯ä»¥å¤„ç†åºåˆ—æ•°æ®

### ğŸ¯ æ¥ä¸‹æ¥è¦å­¦
- [ ] **ç†è§£åŸç†**ï¼šRNNã€LSTMçš„å†…éƒ¨å·¥ä½œåŸç†
- [ ] **æ¢¯åº¦é—®é¢˜**ï¼šæ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸
- [ ] **å®é™…åº”ç”¨**ï¼šæ–‡æœ¬åˆ†ç±»ã€æœºå™¨ç¿»è¯‘ç­‰

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **å…ˆä½“éªŒå†å­¦ä¹ **ï¼šä½ å·²ç»è¿è¡Œäº†ä»£ç ï¼Œçœ‹åˆ°äº†æ•ˆæœ
2. **ç†è§£åºåˆ—**ï¼šç†è§£åºåˆ—æ•°æ®çš„ç‰¹æ€§
3. **å¯¹æ¯”RNNå’ŒLSTM**ï¼šç†è§£LSTMå¦‚ä½•è§£å†³RNNçš„é—®é¢˜
4. **å®è·µåº”ç”¨**ï¼šåœ¨çœŸå®åºåˆ—æ•°æ®ä¸Šè®­ç»ƒ

---

## âš ï¸ å¸¸è§é—®é¢˜

**Q: RNNå’ŒLSTMæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ**
A: LSTMé€šè¿‡é—¨æ§æœºåˆ¶è§£å†³äº†RNNçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œèƒ½å¤„ç†æ›´é•¿çš„åºåˆ—ã€‚

**Q: ä»€ä¹ˆæ—¶å€™ç”¨RNNï¼Œä»€ä¹ˆæ—¶å€™ç”¨LSTMï¼Ÿ**
A: çŸ­åºåˆ—å¯ä»¥ç”¨RNNï¼Œé•¿åºåˆ—å»ºè®®ç”¨LSTMã€‚ç°åœ¨é€šå¸¸ç›´æ¥ç”¨LSTMã€‚

**Q: RNN/LSTMå¯ä»¥å¤„ç†ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Ÿ**
A: åºåˆ—æ•°æ®ï¼šæ–‡æœ¬ã€æ—¶é—´åºåˆ—ã€è¯­éŸ³ã€è§†é¢‘ç­‰ã€‚

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿç°åœ¨å¼€å§‹æ­£å¼å­¦ä¹ RNN/LSTMçš„åŸç†å’Œå®ç°ï¼** ğŸš€
