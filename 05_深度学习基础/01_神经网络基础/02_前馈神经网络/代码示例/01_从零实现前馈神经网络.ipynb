{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ä»é›¶å®ç°å‰é¦ˆç¥ç»ç½‘ç»œ\n",
        "\n",
        "## ğŸ“š ä»£ç ç¤ºä¾‹å…³è”\n",
        "\n",
        "**æœ¬ç¤ºä¾‹ä½ç½®**ï¼šè¿™æ˜¯ç¥ç»ç½‘ç»œåŸºç¡€çš„ç¬¬ä¸‰ä¸ªä»£ç ç¤ºä¾‹\n",
        "\n",
        "**åŸºäº**ï¼š\n",
        "- [ä»é›¶å®ç°ç¥ç»å…ƒ](../../01_æ„ŸçŸ¥å™¨ä¸ç¥ç»å…ƒ/ä»£ç ç¤ºä¾‹/01_ä»é›¶å®ç°ç¥ç»å…ƒ.ipynb) - å‰é¦ˆç¥ç»ç½‘ç»œç”±å¤šä¸ªç¥ç»å…ƒç»„æˆ\n",
        "- [ä»é›¶å®ç°æ„ŸçŸ¥å™¨](../../01_æ„ŸçŸ¥å™¨ä¸ç¥ç»å…ƒ/ä»£ç ç¤ºä¾‹/01_ä»é›¶å®ç°æ„ŸçŸ¥å™¨.ipynb) - å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„åŸºç¡€\n",
        "\n",
        "**æ‰©å±•ä¸º**ï¼š\n",
        "- [å®ç°ç®€å•çš„è‡ªåŠ¨æ¢¯åº¦ç³»ç»Ÿ](../03_è‡ªåŠ¨æ¢¯åº¦ä¸ä¼˜åŒ–/ä»£ç ç¤ºä¾‹/01_å®ç°ç®€å•çš„è‡ªåŠ¨æ¢¯åº¦ç³»ç»Ÿ.ipynb) - è‡ªåŠ¨å®ç°åå‘ä¼ æ’­\n",
        "- [PyTorchåŸºç¡€å…¥é—¨](../../04_PyTorch_TensorFlow/01_PyTorchåŸºç¡€/ä»£ç ç¤ºä¾‹/01_PyTorchåŸºç¡€å…¥é—¨.ipynb) - ä½¿ç”¨æ¡†æ¶å®ç°å‰é¦ˆç½‘ç»œ\n",
        "- [ä»é›¶å®ç°ä¼˜åŒ–ç®—æ³•](../../05_ç½‘ç»œä¼˜åŒ–ä¸æ­£åˆ™åŒ–/01_ç½‘ç»œä¼˜åŒ–/ä»£ç ç¤ºä¾‹/01_ä»é›¶å®ç°ä¼˜åŒ–ç®—æ³•.ipynb) - ä½¿ç”¨ä¼˜åŒ–ç®—æ³•è®­ç»ƒç½‘ç»œ\n",
        "\n",
        "**ç›¸å…³ç¤ºä¾‹**ï¼š\n",
        "- [å®Œæ•´å‰é¦ˆç¥ç»ç½‘ç»œè®­ç»ƒæµç¨‹](../Jupyterç»ƒä¹ /01_å®Œæ•´å‰é¦ˆç¥ç»ç½‘ç»œè®­ç»ƒæµç¨‹.ipynb) - å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "- [CNNå®ç°](../../02_CNN/ä»£ç ç¤ºä¾‹/) - CNNæ˜¯å‰é¦ˆç½‘ç»œçš„æ‰©å±•\n",
        "- [RNNå®ç°](../../03_RNN_LSTM/ä»£ç ç¤ºä¾‹/) - RNNæ˜¯å‰é¦ˆç½‘ç»œçš„å¾ªç¯æ‰©å±•\n",
        "\n",
        "---\n",
        "\n",
        "## å­¦ä¹ ç›®æ ‡\n",
        "\n",
        "æœ¬notebookå°†å¸¦ä½ ä»é›¶å¼€å§‹å®ç°ä¸€ä¸ªå®Œæ•´çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼ŒåŒ…æ‹¬ï¼š\n",
        "\n",
        "1. **ç†è§£å‰é¦ˆç¥ç»ç½‘ç»œçš„å®Œæ•´ç»“æ„**\n",
        "   - å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰çš„æ¶æ„\n",
        "   - å…¨è¿æ¥å±‚çš„å·¥ä½œåŸç†\n",
        "   - ç½‘ç»œæ·±åº¦ä¸å®½åº¦çš„æ¦‚å¿µ\n",
        "\n",
        "2. **æŒæ¡å‰å‘ä¼ æ’­çš„å®ç°**\n",
        "   - çº¿æ€§å˜æ¢ï¼ˆçŸ©é˜µä¹˜æ³•ï¼‰\n",
        "   - æ¿€æ´»å‡½æ•°çš„åº”ç”¨\n",
        "   - æ‰¹é‡å¤„ç†\n",
        "\n",
        "3. **æŒæ¡åå‘ä¼ æ’­çš„å®ç°**\n",
        "   - é“¾å¼æ³•åˆ™çš„åº”ç”¨\n",
        "   - è¯¯å·®åå‘ä¼ æ’­\n",
        "   - æ¢¯åº¦è®¡ç®—\n",
        "\n",
        "4. **èƒ½å¤Ÿè®­ç»ƒå¤šå±‚ç¥ç»ç½‘ç»œ**\n",
        "   - å®Œæ•´çš„è®­ç»ƒå¾ªç¯\n",
        "   - æŸå¤±å‡½æ•°è®¡ç®—\n",
        "   - å‚æ•°æ›´æ–°\n",
        "\n",
        "## è¯¾ç¨‹æ¦‚è¿°\n",
        "\n",
        "æœ¬ç¤ºä¾‹å°†å®ç°ä¸€ä¸ª3å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆè¾“å…¥å±‚â†’éšè—å±‚â†’è¾“å‡ºå±‚ï¼‰ï¼Œç”¨äºè§£å†³äºŒåˆ†ç±»é—®é¢˜ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons, make_circles\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾\n",
        "plt.rcParams['axes.unicode_minus'] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·\n",
        "\n",
        "# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. æ¿€æ´»å‡½æ•°å®ç°\n",
        "\n",
        "æˆ‘ä»¬å°†å®ç°å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°åŠå…¶å¯¼æ•°ï¼Œè¿™äº›å°†åœ¨å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä¸­ä½¿ç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ActivationFunctions:\n",
        "    \"\"\"\n",
        "    æ¿€æ´»å‡½æ•°é›†åˆ\n",
        "    åŒ…å«å¸¸ç”¨æ¿€æ´»å‡½æ•°åŠå…¶å¯¼æ•°\n",
        "    \"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "        \"\"\"\n",
        "        Sigmoidæ¿€æ´»å‡½æ•°\n",
        "        å…¬å¼: Ïƒ(z) = 1 / (1 + e^(-z))\n",
        "        è¾“å‡ºèŒƒå›´: [0, 1]\n",
        "        \"\"\"\n",
        "        z = np.clip(z, -500, 500)  # é˜²æ­¢æº¢å‡º\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid_derivative(z):\n",
        "        \"\"\"Sigmoidå‡½æ•°çš„å¯¼æ•°: Ïƒ'(z) = Ïƒ(z) * (1 - Ïƒ(z))\"\"\"\n",
        "        s = ActivationFunctions.sigmoid(z)\n",
        "        return s * (1 - s)\n",
        "    \n",
        "    @staticmethod\n",
        "    def tanh(z):\n",
        "        \"\"\"Tanhæ¿€æ´»å‡½æ•°ï¼Œè¾“å‡ºèŒƒå›´: [-1, 1]\"\"\"\n",
        "        return np.tanh(z)\n",
        "    \n",
        "    @staticmethod\n",
        "    def tanh_derivative(z):\n",
        "        \"\"\"Tanhå‡½æ•°çš„å¯¼æ•°: tanh'(z) = 1 - tanh^2(z)\"\"\"\n",
        "        return 1 - np.tanh(z) ** 2\n",
        "    \n",
        "    @staticmethod\n",
        "    def relu(z):\n",
        "        \"\"\"ReLUæ¿€æ´»å‡½æ•°: ReLU(z) = max(0, z)\"\"\"\n",
        "        return np.maximum(0, z)\n",
        "    \n",
        "    @staticmethod\n",
        "    def relu_derivative(z):\n",
        "        \"\"\"ReLUå‡½æ•°çš„å¯¼æ•°: ReLU'(z) = 1 if z > 0 else 0\"\"\"\n",
        "        return (z > 0).astype(float)\n",
        "    \n",
        "    @staticmethod\n",
        "    def linear(z):\n",
        "        \"\"\"çº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆç”¨äºå›å½’ï¼‰: f(z) = z\"\"\"\n",
        "        return z\n",
        "    \n",
        "    @staticmethod\n",
        "    def linear_derivative(z):\n",
        "        \"\"\"çº¿æ€§å‡½æ•°çš„å¯¼æ•°: f'(z) = 1\"\"\"\n",
        "        return np.ones_like(z)\n",
        "\n",
        "print(\"æ¿€æ´»å‡½æ•°ç±»å®šä¹‰å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å‰é¦ˆç¥ç»ç½‘ç»œç±»å®ç°\n",
        "\n",
        "æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªå®Œæ•´çš„å‰é¦ˆç¥ç»ç½‘ç»œç±»ï¼ŒåŒ…æ‹¬ï¼š\n",
        "- ç½‘ç»œåˆå§‹åŒ–ï¼ˆæƒé‡å’Œåç½®ï¼‰\n",
        "- å‰å‘ä¼ æ’­\n",
        "- åå‘ä¼ æ’­\n",
        "- å‚æ•°æ›´æ–°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeedforwardNeuralNetwork:\n",
        "    \"\"\"\n",
        "    å‰é¦ˆç¥ç»ç½‘ç»œç±»\n",
        "    æ”¯æŒå¤šå±‚å…¨è¿æ¥ç½‘ç»œï¼Œå¯è‡ªå®šä¹‰æ¯å±‚çš„æ¿€æ´»å‡½æ•°\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, layer_sizes, activations, learning_rate=0.01):\n",
        "        \"\"\"\n",
        "        åˆå§‹åŒ–å‰é¦ˆç¥ç»ç½‘ç»œ\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - layer_sizes: åˆ—è¡¨ï¼Œæ¯å±‚çš„ç¥ç»å…ƒæ•°é‡ï¼Œä¾‹å¦‚ [2, 4, 1] è¡¨ç¤ºè¾“å…¥2ç»´ï¼Œéšè—å±‚4ç»´ï¼Œè¾“å‡º1ç»´\n",
        "        - activations: åˆ—è¡¨ï¼Œæ¯å±‚çš„æ¿€æ´»å‡½æ•°åç§°ï¼Œä¾‹å¦‚ ['relu', 'sigmoid']\n",
        "        - learning_rate: å­¦ä¹ ç‡\n",
        "        \"\"\"\n",
        "        self.layer_sizes = layer_sizes\n",
        "        self.num_layers = len(layer_sizes) - 1  # ä¸åŒ…æ‹¬è¾“å…¥å±‚\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        # åˆå§‹åŒ–æƒé‡å’Œåç½®\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            # Xavieråˆå§‹åŒ–ï¼ˆé€‚ç”¨äºSigmoid/Tanhï¼‰\n",
        "            # Heåˆå§‹åŒ–ï¼ˆé€‚ç”¨äºReLUï¼‰\n",
        "            if activations[i] == 'relu':\n",
        "                # Heåˆå§‹åŒ–\n",
        "                w = np.random.randn(layer_sizes[i+1], layer_sizes[i]) * np.sqrt(2.0 / layer_sizes[i])\n",
        "            else:\n",
        "                # Xavieråˆå§‹åŒ–\n",
        "                w = np.random.randn(layer_sizes[i+1], layer_sizes[i]) * np.sqrt(1.0 / layer_sizes[i])\n",
        "            \n",
        "            b = np.zeros((layer_sizes[i+1], 1))\n",
        "            \n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "        \n",
        "        # è®¾ç½®æ¿€æ´»å‡½æ•°\n",
        "        self.activations = []\n",
        "        self.activation_derivatives = []\n",
        "        \n",
        "        for act_name in activations:\n",
        "            if act_name == 'sigmoid':\n",
        "                self.activations.append(ActivationFunctions.sigmoid)\n",
        "                self.activation_derivatives.append(ActivationFunctions.sigmoid_derivative)\n",
        "            elif act_name == 'tanh':\n",
        "                self.activations.append(ActivationFunctions.tanh)\n",
        "                self.activation_derivatives.append(ActivationFunctions.tanh_derivative)\n",
        "            elif act_name == 'relu':\n",
        "                self.activations.append(ActivationFunctions.relu)\n",
        "                self.activation_derivatives.append(ActivationFunctions.relu_derivative)\n",
        "            elif act_name == 'linear':\n",
        "                self.activations.append(ActivationFunctions.linear)\n",
        "                self.activation_derivatives.append(ActivationFunctions.linear_derivative)\n",
        "            else:\n",
        "                raise ValueError(f\"ä¸æ”¯æŒçš„æ¿€æ´»å‡½æ•°: {act_name}\")\n",
        "    \n",
        "    def forward_propagation(self, X):\n",
        "        \"\"\"\n",
        "        å‰å‘ä¼ æ’­\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - X: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_samples, n_features)\n",
        "        \n",
        "        è¿”å›:\n",
        "        - activations: æ‰€æœ‰å±‚çš„æ¿€æ´»å€¼\n",
        "        - zs: æ‰€æœ‰å±‚çš„å‡€è¾“å…¥ï¼ˆæ¿€æ´»å‰ï¼‰\n",
        "        \"\"\"\n",
        "        activations = [X.T]  # è½¬ç½®ä»¥ä¾¿è¿›è¡ŒçŸ©é˜µä¹˜æ³•\n",
        "        zs = []\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            # çº¿æ€§å˜æ¢: z = W @ a + b\n",
        "            z = self.weights[i] @ activations[-1] + self.biases[i]\n",
        "            zs.append(z)\n",
        "            \n",
        "            # æ¿€æ´»å‡½æ•°: a = f(z)\n",
        "            a = self.activations[i](z)\n",
        "            activations.append(a)\n",
        "        \n",
        "        return activations, zs\n",
        "    \n",
        "    def backward_propagation(self, X, y, activations, zs):\n",
        "        \"\"\"\n",
        "        åå‘ä¼ æ’­\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - X: è¾“å…¥æ•°æ®\n",
        "        - y: çœŸå®æ ‡ç­¾\n",
        "        - activations: å‰å‘ä¼ æ’­å¾—åˆ°çš„æ¿€æ´»å€¼\n",
        "        - zs: å‰å‘ä¼ æ’­å¾—åˆ°çš„å‡€è¾“å…¥\n",
        "        \n",
        "        è¿”å›:\n",
        "        - dW: æƒé‡æ¢¯åº¦åˆ—è¡¨\n",
        "        - db: åç½®æ¢¯åº¦åˆ—è¡¨\n",
        "        \"\"\"\n",
        "        m = X.shape[0]  # æ ·æœ¬æ•°é‡\n",
        "        \n",
        "        # åˆå§‹åŒ–æ¢¯åº¦\n",
        "        dW = [np.zeros_like(w) for w in self.weights]\n",
        "        db = [np.zeros_like(b) for b in self.biases]\n",
        "        \n",
        "        # è¾“å‡ºå±‚è¯¯å·®\n",
        "        # å¯¹äºäºŒåˆ†ç±»ï¼Œä½¿ç”¨Sigmoid + äºŒå…ƒäº¤å‰ç†µ\n",
        "        # è¯¯å·® = (é¢„æµ‹å€¼ - çœŸå®å€¼)\n",
        "        y_pred = activations[-1]  # å½¢çŠ¶: (1, m)\n",
        "        y_true = y.reshape(1, -1)  # å½¢çŠ¶: (1, m)\n",
        "        \n",
        "        # è¾“å‡ºå±‚è¯¯å·®: Î´^(L) = (a^(L) - y) * f'(z^(L))\n",
        "        delta = (y_pred - y_true) * self.activation_derivatives[-1](zs[-1])\n",
        "        \n",
        "        # åå‘ä¼ æ’­è¯¯å·®\n",
        "        for l in range(self.num_layers - 1, -1, -1):\n",
        "            # è®¡ç®—æ¢¯åº¦\n",
        "            dW[l] = (1 / m) * delta @ activations[l].T\n",
        "            db[l] = (1 / m) * np.sum(delta, axis=1, keepdims=True)\n",
        "            \n",
        "            # å¦‚æœä¸æ˜¯ç¬¬ä¸€å±‚ï¼Œè®¡ç®—å‰ä¸€å±‚çš„è¯¯å·®\n",
        "            if l > 0:\n",
        "                # è¯¯å·®åå‘ä¼ æ’­: Î´^(l) = (W^(l+1))^T @ Î´^(l+1) * f'(z^(l))\n",
        "                delta = (self.weights[l].T @ delta) * self.activation_derivatives[l-1](zs[l-1])\n",
        "        \n",
        "        return dW, db\n",
        "    \n",
        "    def update_parameters(self, dW, db):\n",
        "        \"\"\"\n",
        "        æ›´æ–°å‚æ•°ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - dW: æƒé‡æ¢¯åº¦åˆ—è¡¨\n",
        "        - db: åç½®æ¢¯åº¦åˆ—è¡¨\n",
        "        \"\"\"\n",
        "        for i in range(self.num_layers):\n",
        "            self.weights[i] -= self.learning_rate * dW[i]\n",
        "            self.biases[i] -= self.learning_rate * db[i]\n",
        "    \n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        è®¡ç®—æŸå¤±å‡½æ•°ï¼ˆäºŒå…ƒäº¤å‰ç†µï¼‰\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - y_pred: é¢„æµ‹å€¼ï¼Œå½¢çŠ¶ä¸º (1, m)\n",
        "        - y_true: çœŸå®å€¼ï¼Œå½¢çŠ¶ä¸º (1, m)\n",
        "        \n",
        "        è¿”å›:\n",
        "        - loss: æŸå¤±å€¼\n",
        "        \"\"\"\n",
        "        m = y_true.shape[1]\n",
        "        # é˜²æ­¢log(0)\n",
        "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
        "        loss = -(1 / m) * np.sum(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "        return loss\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        é¢„æµ‹\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - X: è¾“å…¥æ•°æ®\n",
        "        \n",
        "        è¿”å›:\n",
        "        - predictions: é¢„æµ‹å€¼ï¼ˆ0æˆ–1ï¼‰\n",
        "        \"\"\"\n",
        "        activations, _ = self.forward_propagation(X)\n",
        "        y_pred = activations[-1].T  # è½¬ç½®å› (m, 1)\n",
        "        return (y_pred > 0.5).astype(int)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        é¢„æµ‹æ¦‚ç‡\n",
        "        \n",
        "        å‚æ•°:\n",
        "        - X: è¾“å…¥æ•°æ®\n",
        "        \n",
        "        è¿”å›:\n",
        "        - probabilities: é¢„æµ‹æ¦‚ç‡\n",
        "        \"\"\"\n",
        "        activations, _ = self.forward_propagation(X)\n",
        "        return activations[-1].T  # è½¬ç½®å› (m, 1)\n",
        "\n",
        "print(\"å‰é¦ˆç¥ç»ç½‘ç»œç±»å®šä¹‰å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(network, X_train, y_train, X_val, y_val, epochs=1000, verbose=True):\n",
        "    \"\"\"\n",
        "    è®­ç»ƒç¥ç»ç½‘ç»œ\n",
        "    \n",
        "    å‚æ•°:\n",
        "    - network: ç¥ç»ç½‘ç»œå®ä¾‹\n",
        "    - X_train: è®­ç»ƒé›†è¾“å…¥\n",
        "    - y_train: è®­ç»ƒé›†æ ‡ç­¾\n",
        "    - X_val: éªŒè¯é›†è¾“å…¥\n",
        "    - y_val: éªŒè¯é›†æ ‡ç­¾\n",
        "    - epochs: è®­ç»ƒè½®æ•°\n",
        "    - verbose: æ˜¯å¦æ‰“å°è®­ç»ƒè¿‡ç¨‹\n",
        "    \n",
        "    è¿”å›:\n",
        "    - history: è®­ç»ƒå†å²ï¼ˆæŸå¤±å’Œå‡†ç¡®ç‡ï¼‰\n",
        "    \"\"\"\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # å‰å‘ä¼ æ’­\n",
        "        activations, zs = network.forward_propagation(X_train)\n",
        "        \n",
        "        # è®¡ç®—è®­ç»ƒæŸå¤±\n",
        "        train_loss = network.compute_loss(activations[-1], y_train.reshape(1, -1))\n",
        "        \n",
        "        # åå‘ä¼ æ’­\n",
        "        dW, db = network.backward_propagation(X_train, y_train, activations, zs)\n",
        "        \n",
        "        # æ›´æ–°å‚æ•°\n",
        "        network.update_parameters(dW, db)\n",
        "        \n",
        "        # è®¡ç®—è®­ç»ƒå‡†ç¡®ç‡\n",
        "        train_pred = network.predict(X_train)\n",
        "        train_acc = np.mean(train_pred.flatten() == y_train)\n",
        "        \n",
        "        # è®¡ç®—éªŒè¯æŸå¤±å’Œå‡†ç¡®ç‡\n",
        "        val_activations, _ = network.forward_propagation(X_val)\n",
        "        val_loss = network.compute_loss(val_activations[-1], y_val.reshape(1, -1))\n",
        "        val_pred = network.predict(X_val)\n",
        "        val_acc = np.mean(val_pred.flatten() == y_val)\n",
        "        \n",
        "        # è®°å½•å†å²\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        \n",
        "        # æ‰“å°è®­ç»ƒè¿‡ç¨‹\n",
        "        if verbose and (epoch + 1) % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"  è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f}\")\n",
        "            print(f\"  éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}\")\n",
        "            print()\n",
        "    \n",
        "    return history\n",
        "\n",
        "print(\"è®­ç»ƒå‡½æ•°å®šä¹‰å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æ•°æ®å‡†å¤‡\n",
        "\n",
        "æˆ‘ä»¬ä½¿ç”¨sklearnç”Ÿæˆä¸€ä¸ªéçº¿æ€§åˆ†ç±»æ•°æ®é›†ï¼ˆæœˆç‰™å½¢æ•°æ®é›†ï¼‰æ¥æµ‹è¯•æˆ‘ä»¬çš„ç½‘ç»œã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”Ÿæˆæœˆç‰™å½¢æ•°æ®é›†\n",
        "X, y = make_moons(n_samples=1000, noise=0.1, random_state=42)\n",
        "\n",
        "# åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}\")\n",
        "print(f\"éªŒè¯é›†å¤§å°: {X_val.shape[0]}\")\n",
        "print(f\"ç‰¹å¾ç»´åº¦: {X_train.shape[1]}\")\n",
        "\n",
        "# å¯è§†åŒ–æ•°æ®é›†\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c='blue', label='ç±»åˆ«0', alpha=0.6)\n",
        "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c='red', label='ç±»åˆ«1', alpha=0.6)\n",
        "plt.xlabel('ç‰¹å¾1')\n",
        "plt.ylabel('ç‰¹å¾2')\n",
        "plt.title('è®­ç»ƒé›†åˆ†å¸ƒ')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(X_val[y_val == 0, 0], X_val[y_val == 0, 1], c='blue', label='ç±»åˆ«0', alpha=0.6)\n",
        "plt.scatter(X_val[y_val == 1, 0], X_val[y_val == 1, 1], c='red', label='ç±»åˆ«1', alpha=0.6)\n",
        "plt.xlabel('ç‰¹å¾1')\n",
        "plt.ylabel('ç‰¹å¾2')\n",
        "plt.title('éªŒè¯é›†åˆ†å¸ƒ')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. åˆ›å»ºå’Œè®­ç»ƒç½‘ç»œ\n",
        "\n",
        "åˆ›å»ºä¸€ä¸ª3å±‚ç½‘ç»œï¼ˆè¾“å…¥2ç»´ â†’ éšè—å±‚8ç»´ â†’ è¾“å‡º1ç»´ï¼‰ï¼Œä½¿ç”¨ReLUä½œä¸ºéšè—å±‚æ¿€æ´»å‡½æ•°ï¼ŒSigmoidä½œä¸ºè¾“å‡ºå±‚æ¿€æ´»å‡½æ•°ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºç½‘ç»œ\n",
        "# ç½‘ç»œç»“æ„: è¾“å…¥2ç»´ â†’ éšè—å±‚8ç»´ â†’ è¾“å‡º1ç»´\n",
        "layer_sizes = [2, 8, 1]\n",
        "activations = ['relu', 'sigmoid']  # éšè—å±‚ç”¨ReLUï¼Œè¾“å‡ºå±‚ç”¨Sigmoid\n",
        "\n",
        "network = FeedforwardNeuralNetwork(\n",
        "    layer_sizes=layer_sizes,\n",
        "    activations=activations,\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "print(\"ç½‘ç»œç»“æ„:\")\n",
        "print(f\"  è¾“å…¥å±‚: {layer_sizes[0]} ä¸ªç¥ç»å…ƒ\")\n",
        "for i in range(1, len(layer_sizes)):\n",
        "    print(f\"  ç¬¬{i}å±‚: {layer_sizes[i]} ä¸ªç¥ç»å…ƒ, æ¿€æ´»å‡½æ•°: {activations[i-1]}\")\n",
        "print(f\"  æ€»å‚æ•°æ•°: {sum(w.size + b.size for w, b in zip(network.weights, network.biases))}\")\n",
        "\n",
        "# è®­ç»ƒç½‘ç»œ\n",
        "print(\"\\nå¼€å§‹è®­ç»ƒ...\")\n",
        "history = train(network, X_train, y_train, X_val, y_val, epochs=1000, verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
        "\n",
        "ç»˜åˆ¶æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿ï¼Œè§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç»˜åˆ¶è®­ç»ƒæ›²çº¿\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# æŸå¤±æ›²çº¿\n",
        "axes[0].plot(history['train_loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)\n",
        "axes[0].plot(history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# å‡†ç¡®ç‡æ›²çº¿\n",
        "axes[1].plot(history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)\n",
        "axes[1].plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\næœ€ç»ˆç»“æœ:\")\n",
        "print(f\"  è®­ç»ƒå‡†ç¡®ç‡: {history['train_acc'][-1]:.4f}\")\n",
        "print(f\"  éªŒè¯å‡†ç¡®ç‡: {history['val_acc'][-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. å¯è§†åŒ–å†³ç­–è¾¹ç•Œ\n",
        "\n",
        "ç»˜åˆ¶ç½‘ç»œçš„å†³ç­–è¾¹ç•Œï¼Œè§‚å¯Ÿåˆ†ç±»æ•ˆæœã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºç½‘æ ¼ç‚¹ç”¨äºç»˜åˆ¶å†³ç­–è¾¹ç•Œ\n",
        "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "# é¢„æµ‹ç½‘æ ¼ç‚¹çš„ç±»åˆ«\n",
        "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "Z = network.predict_proba(grid_points)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# ç»˜åˆ¶å†³ç­–è¾¹ç•Œ\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')\n",
        "plt.colorbar(label='é¢„æµ‹æ¦‚ç‡')\n",
        "\n",
        "# ç»˜åˆ¶æ•°æ®ç‚¹\n",
        "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \n",
        "           c='blue', label='ç±»åˆ«0 (è®­ç»ƒ)', marker='o', s=50, edgecolors='black', linewidths=1)\n",
        "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \n",
        "           c='red', label='ç±»åˆ«1 (è®­ç»ƒ)', marker='o', s=50, edgecolors='black', linewidths=1)\n",
        "plt.scatter(X_val[y_val == 0, 0], X_val[y_val == 0, 1], \n",
        "           c='cyan', label='ç±»åˆ«0 (éªŒè¯)', marker='s', s=50, edgecolors='black', linewidths=1)\n",
        "plt.scatter(X_val[y_val == 1, 0], X_val[y_val == 1, 1], \n",
        "           c='orange', label='ç±»åˆ«1 (éªŒè¯)', marker='s', s=50, edgecolors='black', linewidths=1)\n",
        "\n",
        "plt.xlabel('ç‰¹å¾1')\n",
        "plt.ylabel('ç‰¹å¾2')\n",
        "plt.title('å‰é¦ˆç¥ç»ç½‘ç»œå†³ç­–è¾¹ç•Œ')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. æ€»ç»“\n",
        "\n",
        "### 8.1 å…³é”®è¦ç‚¹\n",
        "\n",
        "1. **å‰å‘ä¼ æ’­**ï¼š\n",
        "   - ä»è¾“å…¥å±‚åˆ°è¾“å‡ºå±‚ï¼Œé€å±‚è®¡ç®—æ¿€æ´»å€¼\n",
        "   - æ¯å±‚åŒ…æ‹¬çº¿æ€§å˜æ¢å’Œæ¿€æ´»å‡½æ•°\n",
        "\n",
        "2. **åå‘ä¼ æ’­**ï¼š\n",
        "   - ä»è¾“å‡ºå±‚åˆ°è¾“å…¥å±‚ï¼Œé€å±‚è®¡ç®—æ¢¯åº¦\n",
        "   - ä½¿ç”¨é“¾å¼æ³•åˆ™è®¡ç®—å‚æ•°æ¢¯åº¦\n",
        "\n",
        "3. **è®­ç»ƒè¿‡ç¨‹**ï¼š\n",
        "   - å‰å‘ä¼ æ’­è®¡ç®—é¢„æµ‹å€¼\n",
        "   - åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
        "   - ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°\n",
        "\n",
        "### 8.2 è¿›ä¸€æ­¥å­¦ä¹ \n",
        "\n",
        "- [è‡ªåŠ¨æ¢¯åº¦ä¸ä¼˜åŒ–](../03_è‡ªåŠ¨æ¢¯åº¦ä¸ä¼˜åŒ–/) - å­¦ä¹ å¦‚ä½•è‡ªåŠ¨å®ç°åå‘ä¼ æ’­\n",
        "- [PyTorchåŸºç¡€](../../04_PyTorch_TensorFlow/01_PyTorchåŸºç¡€/) - ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¡†æ¶å®ç°ç½‘ç»œ\n",
        "- [ç½‘ç»œä¼˜åŒ–](../../05_ç½‘ç»œä¼˜åŒ–ä¸æ­£åˆ™åŒ–/01_ç½‘ç»œä¼˜åŒ–/) - å­¦ä¹ æ›´é«˜çº§çš„ä¼˜åŒ–ç®—æ³•\n",
        "\n",
        "### 8.3 ç»ƒä¹ å»ºè®®\n",
        "\n",
        "1. å°è¯•ä¸åŒçš„ç½‘ç»œç»“æ„ï¼ˆæ·±åº¦ã€å®½åº¦ï¼‰\n",
        "2. å°è¯•ä¸åŒçš„æ¿€æ´»å‡½æ•°\n",
        "3. å°è¯•ä¸åŒçš„å­¦ä¹ ç‡\n",
        "4. åœ¨æ›´å¤æ‚çš„æ•°æ®é›†ä¸Šæµ‹è¯•\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
