# 自我评估：编程实践题

## 题目1：实现Sigmoid激活函数（20分）

### 要求

实现Sigmoid激活函数及其导数，并验证正确性。

### 任务

1. 实现Sigmoid函数：$\sigma(z) = \frac{1}{1 + e^{-z}}$
2. 实现Sigmoid的导数：$\sigma'(z) = \sigma(z)(1 - \sigma(z))$
3. 测试函数：计算$\sigma(0)$、$\sigma(1)$、$\sigma(-1)$
4. 验证导数：使用数值方法验证导数的正确性

### 评分标准

- 正确实现Sigmoid函数（5分）
- 正确实现导数（5分）
- 测试用例通过（5分）
- 代码注释清晰（5分）

---

## 题目2：实现神经元类（30分）

### 要求

实现一个通用的神经元类，支持不同的激活函数。

### 任务

1. 实现`Neuron`类，包含：
   - `__init__`：初始化权重和偏置
   - `forward`：前向传播
   - `backward`：反向传播（计算梯度）
   - `update`：更新参数

2. 支持至少3种激活函数：Sigmoid、Tanh、ReLU

3. 在简单数据集上测试训练过程

### 评分标准

- 正确实现Neuron类（10分）
- 支持多种激活函数（10分）
- 训练过程正确（5分）
- 代码结构清晰，注释完整（5分）

---

## 题目3：激活函数对比分析（30分）

### 要求

对比不同激活函数在相同训练条件下的表现。

### 任务

1. 实现Sigmoid、Tanh、ReLU、Leaky ReLU四种激活函数

2. 在相同数据集上训练使用不同激活函数的神经元

3. 记录并可视化：
   - 训练损失曲线
   - 最终准确率
   - 收敛速度

4. 生成对比分析报告

### 评分标准

- 正确实现所有激活函数（10分）
- 训练框架完整（5分）
- 可视化清晰（5分）
- 分析报告详细（10分）

---

## 题目4：解决梯度消失问题（20分）

### 要求

分析并解决深层网络中的梯度消失问题。

### 任务

1. 创建一个简单的多层网络（至少3层）

2. 使用Sigmoid激活函数，观察梯度消失现象

3. 尝试以下方法解决：
   - 使用ReLU激活函数
   - 使用合适的权重初始化（Xavier或He初始化）
   - 添加批量归一化（可选）

4. 对比不同方法的效果

### 评分标准

- 正确实现多层网络（5分）
- 观察到梯度消失现象（5分）
- 尝试至少2种解决方法（5分）
- 效果对比分析（5分）

---

## 总分：100分

## 通过标准：≥80分（80%）

---

## 提交要求

1. 所有代码必须可以运行
2. 代码必须有详细注释
3. 提交时包含：
   - 源代码文件（.py或.ipynb）
   - 运行结果截图
   - 简要说明文档

---

**完成编程实践题，检验你的编程能力！** 💻

