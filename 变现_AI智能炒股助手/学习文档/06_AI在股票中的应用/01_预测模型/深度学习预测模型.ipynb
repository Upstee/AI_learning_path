{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹\n",
        "\n",
        "## ğŸ“‹ æ¦‚è¿°\n",
        "\n",
        "æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹æ˜¯è‚¡ç¥¨åˆ†æä¸­åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›çš„æ–¹æ³•ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¤æ‚çš„å¸‚åœºæ¨¡å¼ã€‚æœ¬ç« èŠ‚å°†è¯¦ç»†ä»‹ç»æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹åœ¨è‚¡ç¥¨åˆ†æä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬LSTMã€GRUã€Transformerç­‰æ¨¡å‹ã€‚\n",
        "\n",
        "**å­¦ä¹ æ–¹å¼**ï¼šæœ¬æ–‡ä»¶æ˜¯Jupyter Notebookæ ¼å¼ï¼Œä½ å¯ä»¥è¾¹çœ‹è¾¹è¿è¡Œä»£ç ï¼Œé€šè¿‡å®é™…ä»£ç ç¤ºä¾‹ç†è§£æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹ã€‚\n",
        "\n",
        "**æ³¨æ„**ï¼šæœ¬ç¤ºä¾‹ä½¿ç”¨ç®€åŒ–çš„æ¨¡å‹ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„ç½‘ç»œç»“æ„ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£…å¿…è¦çš„åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å®‰è£…ï¼‰\n",
        "# !pip install pandas numpy matplotlib tensorflow\n",
        "\n",
        "# å¯¼å…¥åº“\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# å°è¯•å¯¼å…¥TensorFlow\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Attention\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(\"TensorFlowå¯ç”¨ï¼Œå°†ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹\")\n",
        "except ImportError:\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "    print(\"TensorFlowä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€åŒ–çš„æ¨¡æ‹Ÿæ¨¡å‹\")\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“– æ ¸å¿ƒå†…å®¹\n",
        "\n",
        "### 1. æ·±åº¦å­¦ä¹ é¢„æµ‹æ¨¡å‹æ¦‚è¿°\n",
        "\n",
        "#### 1.1 å¸¸ç”¨æ¨¡å‹\n",
        "\n",
        "**å¾ªç¯ç¥ç»ç½‘ç»œ**ï¼š\n",
        "- LSTMï¼ˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼‰\n",
        "- GRUï¼ˆé—¨æ§å¾ªç¯å•å…ƒï¼‰\n",
        "\n",
        "**æ³¨æ„åŠ›æœºåˆ¶**ï¼š\n",
        "- Transformer\n",
        "- Attentionæœºåˆ¶\n",
        "\n",
        "**å·ç§¯ç¥ç»ç½‘ç»œ**ï¼š\n",
        "- 1D CNNç”¨äºæ—¶é—´åºåˆ—\n",
        "\n",
        "è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªLSTMæ¨¡å‹æ¥é¢„æµ‹è‚¡ç¥¨ä»·æ ¼ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”Ÿæˆç¤ºä¾‹æ•°æ®\n",
        "np.random.seed(42)\n",
        "n_days = 1000\n",
        "dates = pd.date_range(start='2021-01-01', periods=n_days, freq='D')\n",
        "dates = dates[dates.weekday < 5]\n",
        "\n",
        "trend = np.linspace(10, 15, len(dates))\n",
        "noise = np.cumsum(np.random.randn(len(dates)) * 0.1)\n",
        "prices = trend + noise\n",
        "\n",
        "price_data = pd.Series(prices, index=dates, name='Close')\n",
        "\n",
        "# å‡†å¤‡LSTMæ•°æ®\n",
        "def create_sequences(data, seq_length=60):\n",
        "    \"\"\"åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®\"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# æ ‡å‡†åŒ–\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_prices = scaler.fit_transform(price_data.values.reshape(-1, 1))\n",
        "\n",
        "# åˆ›å»ºåºåˆ—\n",
        "seq_length = 60\n",
        "X, y = create_sequences(scaled_prices.flatten(), seq_length)\n",
        "\n",
        "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# è°ƒæ•´ç»´åº¦\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "print(f\"æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
        "print(f\"è®­ç»ƒé›†ï¼š{len(X_train)} ä¸ªæ ·æœ¬\")\n",
        "print(f\"æµ‹è¯•é›†ï¼š{len(X_test)} ä¸ªæ ·æœ¬\")\n",
        "\n",
        "if TENSORFLOW_AVAILABLE:\n",
        "    # æ„å»ºLSTMæ¨¡å‹\n",
        "    lstm_model = Sequential([\n",
        "        LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
        "        Dropout(0.2),\n",
        "        LSTM(50, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    \n",
        "    lstm_model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    \n",
        "    print(\"\\nLSTMæ¨¡å‹ç»“æ„ï¼š\")\n",
        "    lstm_model.summary()\n",
        "    \n",
        "    # è®­ç»ƒæ¨¡å‹\n",
        "    print(\"\\nå¼€å§‹è®­ç»ƒLSTMæ¨¡å‹...\")\n",
        "    history = lstm_model.fit(\n",
        "        X_train, y_train,\n",
        "        batch_size=32,\n",
        "        epochs=10,  # å®é™…åº”ç”¨éœ€è¦æ›´å¤šepochs\n",
        "        validation_split=0.2,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # é¢„æµ‹\n",
        "    train_pred = lstm_model.predict(X_train)\n",
        "    test_pred = lstm_model.predict(X_test)\n",
        "    \n",
        "    # åæ ‡å‡†åŒ–\n",
        "    train_pred = scaler.inverse_transform(train_pred)\n",
        "    y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
        "    test_pred = scaler.inverse_transform(test_pred)\n",
        "    y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "    \n",
        "    # è¯„ä¼°\n",
        "    train_mse = mean_squared_error(y_train_actual, train_pred)\n",
        "    test_mse = mean_squared_error(y_test_actual, test_pred)\n",
        "    test_mae = mean_absolute_error(y_test_actual, test_pred)\n",
        "    \n",
        "    print(f\"\\næ¨¡å‹è¯„ä¼°ï¼š\")\n",
        "    print(f\"è®­ç»ƒé›†MSE: {train_mse:.4f}\")\n",
        "    print(f\"æµ‹è¯•é›†MSE: {test_mse:.4f}\")\n",
        "    print(f\"æµ‹è¯•é›†MAE: {test_mae:.4f}\")\n",
        "    \n",
        "    # å¯è§†åŒ–\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "    \n",
        "    # è®­ç»ƒè¿‡ç¨‹\n",
        "    axes[0].plot(history.history['loss'], label='è®­ç»ƒæŸå¤±', linewidth=2)\n",
        "    axes[0].plot(history.history['val_loss'], label='éªŒè¯æŸå¤±', linewidth=2)\n",
        "    axes[0].set_title('LSTMæ¨¡å‹è®­ç»ƒè¿‡ç¨‹', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # é¢„æµ‹ç»“æœ\n",
        "    test_dates = price_data.index[train_size + seq_length:train_size + seq_length + len(y_test)]\n",
        "    axes[1].plot(test_dates, y_test_actual.flatten(), label='å®é™…ä»·æ ¼', \n",
        "                linewidth=2, color='black', alpha=0.7)\n",
        "    axes[1].plot(test_dates, test_pred.flatten(), label='LSTMé¢„æµ‹', \n",
        "                linewidth=2, color='green', alpha=0.7)\n",
        "    axes[1].set_title('LSTMä»·æ ¼é¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('æ—¥æœŸ')\n",
        "    axes[1].set_ylabel('ä»·æ ¼')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"\\næ³¨æ„ï¼šTensorFlowä¸å¯ç”¨\")\n",
        "    print(\"å®‰è£…TensorFlowåå¯ä»¥è¿è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼špip install tensorflow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
