{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹\n",
        "\n",
        "## ğŸ“‹ æ¦‚è¿°\n",
        "\n",
        "æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹æ˜¯è‚¡ç¥¨åˆ†æä¸­åº”ç”¨å¹¿æ³›çš„æ–¹æ³•ï¼Œé€šè¿‡ä½¿ç”¨å„ç§æœºå™¨å­¦ä¹ ç®—æ³•æ¥é¢„æµ‹è‚¡ç¥¨ä»·æ ¼å’Œæ”¶ç›Šã€‚æœ¬ç« èŠ‚å°†è¯¦ç»†ä»‹ç»æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹åœ¨è‚¡ç¥¨åˆ†æä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬éšæœºæ£®æ—ã€XGBoostã€æ”¯æŒå‘é‡æœºç­‰ç®—æ³•ã€‚\n",
        "\n",
        "**å­¦ä¹ æ–¹å¼**ï¼šæœ¬æ–‡ä»¶æ˜¯Jupyter Notebookæ ¼å¼ï¼Œä½ å¯ä»¥è¾¹çœ‹è¾¹è¿è¡Œä»£ç ï¼Œé€šè¿‡å®é™…ä»£ç ç¤ºä¾‹ç†è§£æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£…å¿…è¦çš„åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å®‰è£…ï¼‰\n",
        "# !pip install pandas numpy matplotlib scikit-learn xgboost\n",
        "\n",
        "# å¯¼å…¥åº“\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# å°è¯•å¯¼å…¥XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"XGBoostä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å…¶ä»–æ¨¡å‹\")\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“– æ ¸å¿ƒå†…å®¹\n",
        "\n",
        "### 1. æœºå™¨å­¦ä¹ é¢„æµ‹æ¨¡å‹æ¦‚è¿°\n",
        "\n",
        "#### 1.1 å¸¸ç”¨ç®—æ³•\n",
        "\n",
        "**æ ‘æ¨¡å‹**ï¼š\n",
        "- éšæœºæ£®æ—ï¼ˆRandom Forestï¼‰\n",
        "- æ¢¯åº¦æå‡ï¼ˆGradient Boostingï¼‰\n",
        "- XGBoostã€LightGBM\n",
        "\n",
        "**çº¿æ€§æ¨¡å‹**ï¼š\n",
        "- çº¿æ€§å›å½’\n",
        "- å²­å›å½’\n",
        "- Lassoå›å½’\n",
        "\n",
        "**æ”¯æŒå‘é‡æœº**ï¼š\n",
        "- SVRï¼ˆæ”¯æŒå‘é‡å›å½’ï¼‰\n",
        "\n",
        "è®©æˆ‘ä»¬å‡†å¤‡æ•°æ®å¹¶è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç”Ÿæˆç¤ºä¾‹æ•°æ®\n",
        "np.random.seed(42)\n",
        "n_days = 500\n",
        "dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')\n",
        "dates = dates[dates.weekday < 5]\n",
        "\n",
        "prices = 10 + np.cumsum(np.random.randn(len(dates)) * 0.1)\n",
        "volumes = np.random.randint(1000000, 10000000, len(dates))\n",
        "\n",
        "price_data = pd.DataFrame({\n",
        "    'Close': prices,\n",
        "    'Volume': volumes\n",
        "}, index=dates)\n",
        "\n",
        "# è®¡ç®—ç‰¹å¾\n",
        "price_data['Returns'] = price_data['Close'].pct_change()\n",
        "price_data['MA5'] = price_data['Close'].rolling(window=5).mean()\n",
        "price_data['MA20'] = price_data['Close'].rolling(window=20).mean()\n",
        "price_data['Volatility'] = price_data['Returns'].rolling(window=20).std()\n",
        "price_data['Momentum'] = price_data['Close'] / price_data['Close'].shift(5) - 1\n",
        "price_data['Volume_Ratio'] = price_data['Volume'] / price_data['Volume'].rolling(window=20).mean()\n",
        "\n",
        "# ç›®æ ‡å˜é‡ï¼šæœªæ¥1æœŸæ”¶ç›Šç‡\n",
        "price_data['Future_Return'] = price_data['Returns'].shift(-1)\n",
        "\n",
        "price_data = price_data.dropna()\n",
        "\n",
        "# å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡\n",
        "feature_cols = ['Returns', 'MA5', 'MA20', 'Volatility', 'Momentum', 'Volume_Ratio']\n",
        "X = price_data[feature_cols].values\n",
        "y = price_data['Future_Return'].values\n",
        "\n",
        "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
        "\n",
        "# æ ‡å‡†åŒ–\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"æ•°æ®å‡†å¤‡å®Œæˆï¼\")\n",
        "print(f\"è®­ç»ƒé›†ï¼š{len(X_train)} ä¸ªæ ·æœ¬\")\n",
        "print(f\"æµ‹è¯•é›†ï¼š{len(X_test)} ä¸ªæ ·æœ¬\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è®­ç»ƒå¤šä¸ªæ¨¡å‹\n",
        "models = {}\n",
        "\n",
        "# 1. éšæœºæ£®æ—\n",
        "rf_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "models['éšæœºæ£®æ—'] = rf_model\n",
        "\n",
        "# 2. æ¢¯åº¦æå‡\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "models['æ¢¯åº¦æå‡'] = gb_model\n",
        "\n",
        "# 3. XGBoost\n",
        "if XGBOOST_AVAILABLE:\n",
        "    xgb_model = xgb.XGBRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "    xgb_model.fit(X_train_scaled, y_train)\n",
        "    models['XGBoost'] = xgb_model\n",
        "\n",
        "# 4. æ”¯æŒå‘é‡å›å½’\n",
        "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "models['SVR'] = svr_model\n",
        "\n",
        "# é¢„æµ‹å’Œè¯„ä¼°\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    train_pred = model.predict(X_train_scaled)\n",
        "    test_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_mae = mean_absolute_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    \n",
        "    results[name] = {\n",
        "        'train_mse': train_mse,\n",
        "        'test_mse': test_mse,\n",
        "        'test_mae': test_mae,\n",
        "        'test_r2': test_r2,\n",
        "        'predictions': test_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n{name}æ¨¡å‹ï¼š\")\n",
        "    print(f\"  è®­ç»ƒé›†MSE: {train_mse:.6f}\")\n",
        "    print(f\"  æµ‹è¯•é›†MSE: {test_mse:.6f}\")\n",
        "    print(f\"  æµ‹è¯•é›†MAE: {test_mae:.6f}\")\n",
        "    print(f\"  æµ‹è¯•é›†RÂ²: {test_r2:.4f}\")\n",
        "\n",
        "# å¯è§†åŒ–é¢„æµ‹ç»“æœ\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
        "\n",
        "test_dates = price_data.index[-len(y_test):]\n",
        "\n",
        "# å®é™…å€¼\n",
        "axes[0].plot(test_dates, y_test * 100, 'o-', label='å®é™…æ”¶ç›Šç‡', \n",
        "            linewidth=2, markersize=4, color='black', alpha=0.7)\n",
        "\n",
        "# å„æ¨¡å‹é¢„æµ‹\n",
        "colors = {'éšæœºæ£®æ—': 'green', 'æ¢¯åº¦æå‡': 'blue', 'XGBoost': 'orange', 'SVR': 'red'}\n",
        "for name, result in results.items():\n",
        "    if name in colors:\n",
        "        axes[0].plot(test_dates, result['predictions'] * 100, \n",
        "                    label=f'{name}é¢„æµ‹', linewidth=1.5, color=colors[name], alpha=0.7)\n",
        "\n",
        "axes[0].axhline(y=0, color='gray', linestyle='--', linewidth=0.5)\n",
        "axes[0].set_title('æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹ç»“æœå¯¹æ¯”', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('æ”¶ç›Šç‡ (%)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n",
        "model_names = list(results.keys())\n",
        "mse_values = [results[name]['test_mse'] for name in model_names]\n",
        "mae_values = [results[name]['test_mae'] for name in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "width = 0.35\n",
        "\n",
        "axes[1].bar(x - width/2, mse_values, width, label='MSE', alpha=0.7, color='skyblue')\n",
        "axes[1].bar(x + width/2, mae_values, width, label='MAE', alpha=0.7, color='lightgreen')\n",
        "axes[1].set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('æ¨¡å‹')\n",
        "axes[1].set_ylabel('è¯¯å·®')\n",
        "axes[1].set_xticks(x)\n",
        "axes[1].set_xticklabels(model_names, rotation=45, ha='right')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
        "\n",
        "è®©æˆ‘ä»¬åˆ†æå“ªäº›ç‰¹å¾æœ€é‡è¦ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç‰¹å¾é‡è¦æ€§åˆ†æ\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§\n",
        "if 'éšæœºæ£®æ—' in models:\n",
        "    rf_importance = models['éšæœºæ£®æ—'].feature_importances_\n",
        "    indices = np.argsort(rf_importance)[::-1]\n",
        "    \n",
        "    axes[0].barh(range(len(feature_cols)), rf_importance[indices], \n",
        "                color='skyblue', alpha=0.7, edgecolor='black')\n",
        "    axes[0].set_yticks(range(len(feature_cols)))\n",
        "    axes[0].set_yticklabels([feature_cols[i] for i in indices])\n",
        "    axes[0].set_xlabel('é‡è¦æ€§')\n",
        "    axes[0].set_title('éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§', fontsize=12, fontweight='bold')\n",
        "    axes[0].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# æ¢¯åº¦æå‡ç‰¹å¾é‡è¦æ€§\n",
        "if 'æ¢¯åº¦æå‡' in models:\n",
        "    gb_importance = models['æ¢¯åº¦æå‡'].feature_importances_\n",
        "    indices = np.argsort(gb_importance)[::-1]\n",
        "    \n",
        "    axes[1].barh(range(len(feature_cols)), gb_importance[indices], \n",
        "                color='lightgreen', alpha=0.7, edgecolor='black')\n",
        "    axes[1].set_yticks(range(len(feature_cols)))\n",
        "    axes[1].set_yticklabels([feature_cols[i] for i in indices])\n",
        "    axes[1].set_xlabel('é‡è¦æ€§')\n",
        "    axes[1].set_title('æ¢¯åº¦æå‡ç‰¹å¾é‡è¦æ€§', fontsize=12, fontweight='bold')\n",
        "    axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nç‰¹å¾é‡è¦æ€§æ’åï¼ˆéšæœºæ£®æ—ï¼‰ï¼š\")\n",
        "if 'éšæœºæ£®æ—' in models:\n",
        "    rf_importance = models['éšæœºæ£®æ—'].feature_importances_\n",
        "    indices = np.argsort(rf_importance)[::-1]\n",
        "    for i, idx in enumerate(indices, 1):\n",
        "        print(f\"{i}. {feature_cols[idx]}: {rf_importance[idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
