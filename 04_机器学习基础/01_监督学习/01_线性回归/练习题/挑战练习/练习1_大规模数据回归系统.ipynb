{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 挑战练习1：大规模数据回归系统\n",
        "\n",
        "## 练习目标\n",
        "\n",
        "实现一个能够处理大规模数据的回归系统，包括性能优化和工程化考虑。\n",
        "\n",
        "## 练习要求\n",
        "\n",
        "### 1. 大规模数据处理\n",
        "- 处理10万+样本的数据集\n",
        "- 使用内存高效的方法\n",
        "- 实现数据流式处理（可选）\n",
        "\n",
        "### 2. 模型优化\n",
        "- 实现批量梯度下降、随机梯度下降、小批量梯度下降\n",
        "- 对比不同优化方法的性能\n",
        "- 实现早停（early stopping）\n",
        "- 实现学习率衰减\n",
        "\n",
        "### 3. 分布式训练（可选）\n",
        "- 使用多进程/多线程加速训练\n",
        "- 实现模型并行或数据并行\n",
        "\n",
        "### 4. 模型部署准备\n",
        "- 实现模型保存和加载\n",
        "- 实现预测接口\n",
        "- 性能测试和优化\n",
        "\n",
        "### 5. 完整的工程化系统\n",
        "- 模块化设计\n",
        "- 单元测试\n",
        "- 日志记录\n",
        "- 配置文件管理\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置随机种子\n",
        "np.random.seed(42)\n",
        "\n",
        "# 设置matplotlib在notebook中内联显示\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 第一步：生成大规模数据\n",
        "\n",
        "**你的任务**：生成10万+样本的数据集。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: 生成大规模数据\n",
        "# 提示：\n",
        "# 1. 使用 make_regression 生成10万+样本\n",
        "# 2. 注意内存使用\n",
        "# 3. 可以考虑分批生成\n",
        "\n",
        "# 你的代码：\n",
        "# X, y = make_regression(n_samples=100000, n_features=10, noise=10, random_state=42)\n",
        "# print(f\"数据形状: {X.shape}\")\n",
        "# print(f\"内存使用: {X.nbytes / 1024 / 1024:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 第二步：实现不同的优化方法\n",
        "\n",
        "**你的任务**：实现批量梯度下降、随机梯度下降、小批量梯度下降，并对比性能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: 实现不同的优化方法\n",
        "# 提示：\n",
        "# 1. 批量梯度下降：每次使用全部数据\n",
        "# 2. 随机梯度下降：每次使用1个样本\n",
        "# 3. 小批量梯度下降：每次使用batch_size个样本\n",
        "# 4. 对比训练时间和性能\n",
        "\n",
        "# 你的代码：\n",
        "# ... 实现批量梯度下降\n",
        "# ... 实现随机梯度下降\n",
        "# ... 实现小批量梯度下降\n",
        "# ... 对比性能\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 第三步：使用SGDRegressor\n",
        "\n",
        "**你的任务**：使用scikit-learn的SGDRegressor处理大规模数据。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: 使用SGDRegressor\n",
        "# 提示：\n",
        "# 1. 使用 SGDRegressor 创建模型\n",
        "# 2. 设置不同的学习率策略\n",
        "# 3. 实现早停和学习率衰减\n",
        "# 4. 对比性能\n",
        "\n",
        "# 你的代码：\n",
        "# model_sgd = SGDRegressor(max_iter=1000, learning_rate='adaptive', early_stopping=True)\n",
        "# model_sgd.fit(...)\n",
        "# ... 评估和对比\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 第四步：模型保存和加载\n",
        "\n",
        "**你的任务**：实现模型保存和加载功能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: 模型保存和加载\n",
        "# 提示：\n",
        "# 1. 使用 pickle 保存模型\n",
        "# 2. 加载模型\n",
        "# 3. 测试加载的模型\n",
        "\n",
        "# 你的代码：\n",
        "# with open('model.pkl', 'wb') as f:\n",
        "#     pickle.dump(model, f)\n",
        "# \n",
        "# with open('model.pkl', 'rb') as f:\n",
        "#     loaded_model = pickle.load(f)\n",
        "# ... 测试加载的模型\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结\n",
        "\n",
        "### 完成情况检查\n",
        "\n",
        "- [ ] 成功处理大规模数据\n",
        "- [ ] 实现不同的优化方法\n",
        "- [ ] 使用SGDRegressor\n",
        "- [ ] 实现模型保存和加载\n",
        "- [ ] 性能优化\n",
        "\n",
        "### 思考问题\n",
        "\n",
        "1. **大规模数据处理的关键是什么？**\n",
        "   - 内存管理\n",
        "   - 计算效率\n",
        "   - 算法选择\n",
        "\n",
        "2. **如何优化训练速度？**\n",
        "   - 使用SGD\n",
        "   - 并行计算\n",
        "   - 早停机制\n",
        "\n",
        "---\n",
        "\n",
        "**完成后，请查看答案文件进行对比！**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
