# 逻辑回归 - 概念题

## 一、选择题（每题2分，共20分）

### 1. 逻辑回归主要用于解决什么问题？
A. 回归问题  
B. 分类问题  
C. 聚类问题  
D. 降维问题  

**答案**：B

---

### 2. Sigmoid函数的值域是？
A. [0, 1]  
B. (0, 1)  
C. [-1, 1]  
D. (-∞, +∞)  

**答案**：B

---

### 3. 逻辑回归的损失函数是？
A. 均方误差  
B. 交叉熵  
C. 绝对值误差  
D. 对数损失  

**答案**：B（交叉熵和对数损失是等价的）

---

### 4. 逻辑回归使用什么方法优化参数？
A. 最小二乘法  
B. 梯度下降  
C. 牛顿法  
D. B和C都可以  

**答案**：D

---

### 5. L1正则化的作用是？
A. 防止过拟合  
B. 特征选择（产生稀疏解）  
C. 平滑参数  
D. A和B  

**答案**：D

---

### 6. 逻辑回归的决策边界是？
A. 线性的  
B. 非线性的  
C. 取决于数据  
D. 不确定  

**答案**：A

---

### 7. 多分类逻辑回归使用什么函数？
A. Sigmoid  
B. Softmax  
C. ReLU  
D. Tanh  

**答案**：B

---

### 8. 逻辑回归输出的是什么？
A. 类别  
B. 概率  
C. 连续值  
D. B和A都可以  

**答案**：D（可以输出概率，也可以输出类别）

---

### 9. 逻辑回归假设数据服从什么分布？
A. 正态分布  
B. 伯努利分布  
C. 均匀分布  
D. 指数分布  

**答案**：B

---

### 10. 逻辑回归相比线性回归的主要区别是？
A. 损失函数不同  
B. 输出不同  
C. 优化方法不同  
D. 以上都是  

**答案**：D

---

## 二、简答题（每题10分，共40分）

### 1. 解释逻辑回归的基本原理。

**参考答案**：
逻辑回归使用线性函数 $\theta^T x$ 计算得分，然后通过Sigmoid函数 $\sigma(\theta^T x) = \frac{1}{1+e^{-\theta^T x}}$ 将得分映射到[0,1]区间，得到概率 $P(y=1|x)$。通过最大化似然函数（或最小化交叉熵损失）来优化参数。

---

### 2. 为什么逻辑回归使用交叉熵损失而不是均方误差？

**参考答案**：
1. **统计意义**：从最大似然估计自然导出，假设标签服从伯努利分布
2. **优化性质**：交叉熵损失是凸函数，保证全局最优；均方误差在逻辑回归中不是凸函数
3. **梯度性质**：交叉熵损失的梯度形式简单，便于优化

---

### 3. 说明L1和L2正则化的区别。

**参考答案**：
- **L1正则化（Lasso）**：
  - 惩罚项：$\lambda \sum |\theta_j|$
  - 产生稀疏解（某些参数为0）
  - 可以用于特征选择
  - 对异常值敏感

- **L2正则化（Ridge）**：
  - 惩罚项：$\lambda \sum \theta_j^2$
  - 产生平滑解（参数接近0但不为0）
  - 不能用于特征选择
  - 对异常值不敏感

---

### 4. 如何将逻辑回归用于多分类问题？

**参考答案**：
1. **One-vs-Rest（OvR）**：训练K个二分类器，每个对应一个类别
2. **One-vs-One（OvO）**：训练K(K-1)/2个二分类器，每对类别一个
3. **Softmax回归**：直接使用Softmax函数进行多分类，输出每个类别的概率

---

## 三、计算题（每题10分，共20分）

### 1. 给定Sigmoid函数 $\sigma(z) = \frac{1}{1+e^{-z}}$，计算 $\sigma(0)$ 和 $\sigma'(0)$。

**参考答案**：

$\sigma(0) = \frac{1}{1+e^{0}} = \frac{1}{2} = 0.5$

$\sigma'(z) = \sigma(z)(1-\sigma(z))$

$\sigma'(0) = \sigma(0)(1-\sigma(0)) = 0.5 \times 0.5 = 0.25$

---

### 2. 给定逻辑回归模型 $h_\theta(x) = \sigma(2x_1 + 3x_2 - 1)$，计算当 $x_1=1, x_2=2$ 时的预测概率。

**参考答案**：

$z = 2 \times 1 + 3 \times 2 - 1 = 2 + 6 - 1 = 7$

$h_\theta(x) = \sigma(7) = \frac{1}{1+e^{-7}} \approx 0.9991$

所以预测概率约为 0.9991（接近1，预测为类别1）

---

## 评分标准

- **选择题**：每题2分，共20分
- **简答题**：每题10分，共40分
- **计算题**：每题10分，共20分
- **总分**：80分
- **及格线**：64分（80%）

---

**完成后请对照答案检查，理解每道题的原理！**

