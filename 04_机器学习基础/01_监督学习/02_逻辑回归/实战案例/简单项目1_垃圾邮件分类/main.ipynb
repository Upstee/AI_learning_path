{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 简单项目1：垃圾邮件分类\n",
        "\n",
        "## 项目描述\n",
        "\n",
        "使用逻辑回归构建垃圾邮件分类器。这是一个典型的文本分类问题，展示如何将逻辑回归应用于实际场景。\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "通过本项目，你将学会：\n",
        "1. 如何处理文本数据（TF-IDF向量化）\n",
        "2. 如何使用逻辑回归进行文本分类\n",
        "3. 如何评估分类模型性能\n",
        "4. 如何分析特征重要性\n",
        "\n",
        "## 项目流程\n",
        "\n",
        "1. 数据加载：加载文本数据\n",
        "2. 特征提取：使用TF-IDF向量化文本\n",
        "3. 模型训练：训练逻辑回归模型\n",
        "4. 模型评估：评估模型性能\n",
        "5. 特征分析：分析重要特征\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "import seaborn as sns\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "np.random.seed(42)\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 数据加载\n",
        "\n",
        "使用20newsgroups数据集的部分类别作为示例。在实际应用中，应该使用真实的垃圾邮件数据集。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载数据\n",
        "# 使用20newsgroups数据集的两个类别作为示例\n",
        "categories = ['alt.atheism', 'soc.religion.christian']\n",
        "\n",
        "print(\"加载数据...\")\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, \n",
        "                                      shuffle=True, random_state=42)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, \n",
        "                                     shuffle=True, random_state=42)\n",
        "\n",
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target\n",
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "print(f\"训练集大小: {len(X_train)}\")\n",
        "print(f\"测试集大小: {len(X_test)}\")\n",
        "print(f\"\\n类别: {categories}\")\n",
        "print(f\"训练集类别分布:\")\n",
        "for i, cat in enumerate(categories):\n",
        "    print(f\"  {cat}: {np.sum(y_train == i)} 个样本\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 特征提取\n",
        "\n",
        "使用TF-IDF（Term Frequency-Inverse Document Frequency）将文本转换为数值特征。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF向量化\n",
        "# max_features: 最大特征数量（词汇表大小）\n",
        "# stop_words: 停用词（如'the', 'a'等常见词）\n",
        "# lowercase: 转换为小写\n",
        "# strip_accents: 去除重音符号\n",
        "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', \n",
        "                            lowercase=True, strip_accents='unicode')\n",
        "\n",
        "print(\"特征提取...\")\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"特征维度: {X_train_tfidf.shape[1]}\")\n",
        "print(f\"训练集特征矩阵形状: {X_train_tfidf.shape}\")\n",
        "print(f\"测试集特征矩阵形状: {X_test_tfidf.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 模型训练\n",
        "\n",
        "使用逻辑回归训练分类模型。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建和训练模型\n",
        "print(\"训练模型...\")\n",
        "model = LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs')\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "print(\"模型训练完成！\")\n",
        "\n",
        "# 查看模型参数\n",
        "print(f\"\\n模型参数:\")\n",
        "print(f\"偏置项: {model.intercept_[0]:.4f}\")\n",
        "print(f\"权重数量: {len(model.coef_[0])}\")\n",
        "print(f\"权重范围: [{model.coef_[0].min():.4f}, {model.coef_[0].max():.4f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 模型评估\n",
        "\n",
        "评估模型在测试集上的性能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 预测\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "y_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
        "\n",
        "# 评估指标\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"准确率: {accuracy:.4f}\")\n",
        "\n",
        "# 分类报告\n",
        "print(\"\\n分类报告:\")\n",
        "print(classification_report(y_test, y_pred, target_names=categories))\n",
        "\n",
        "# 混淆矩阵\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\n混淆矩阵:\")\n",
        "print(cm)\n",
        "\n",
        "# ROC曲线\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(f\"\\nROC AUC: {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 结果可视化\n",
        "\n",
        "可视化混淆矩阵和ROC曲线。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化结果\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 1. 混淆矩阵\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=categories,\n",
        "            yticklabels=categories, ax=axes[0])\n",
        "axes[0].set_title('混淆矩阵')\n",
        "axes[0].set_ylabel('真实标签')\n",
        "axes[0].set_xlabel('预测标签')\n",
        "\n",
        "# 2. ROC曲线\n",
        "axes[1].plot(fpr, tpr, label=f'ROC曲线 (AUC = {roc_auc:.2f})', linewidth=2)\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', label='随机分类器')\n",
        "axes[1].set_xlabel('假正例率 (FPR)')\n",
        "axes[1].set_ylabel('真正例率 (TPR)')\n",
        "axes[1].set_title('ROC曲线')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 特征重要性分析\n",
        "\n",
        "分析哪些词对分类最重要。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 分析重要特征\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "coefficients = model.coef_[0]\n",
        "\n",
        "# 获取最重要的特征\n",
        "top_n = 20\n",
        "top_positive = np.argsort(coefficients)[-top_n:][::-1]  # 正系数最大的\n",
        "top_negative = np.argsort(coefficients)[:top_n]  # 负系数最小的（绝对值最大）\n",
        "\n",
        "print(f\"最重要的 {top_n} 个正特征（倾向于类别1）:\")\n",
        "for idx in top_positive:\n",
        "    print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "print(f\"\\n最重要的 {top_n} 个负特征（倾向于类别0）:\")\n",
        "for idx in top_negative:\n",
        "    print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
        "\n",
        "# 可视化特征重要性\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# 正特征\n",
        "top_pos_words = [feature_names[idx] for idx in top_positive]\n",
        "top_pos_coefs = [coefficients[idx] for idx in top_positive]\n",
        "axes[0].barh(range(len(top_pos_words)), top_pos_coefs)\n",
        "axes[0].set_yticks(range(len(top_pos_words)))\n",
        "axes[0].set_yticklabels(top_pos_words)\n",
        "axes[0].set_xlabel('系数值')\n",
        "axes[0].set_title(f'最重要的 {top_n} 个正特征')\n",
        "axes[0].invert_yaxis()\n",
        "\n",
        "# 负特征\n",
        "top_neg_words = [feature_names[idx] for idx in top_negative]\n",
        "top_neg_coefs = [coefficients[idx] for idx in top_negative]\n",
        "axes[1].barh(range(len(top_neg_words)), top_neg_coefs, color='salmon')\n",
        "axes[1].set_yticks(range(len(top_neg_words)))\n",
        "axes[1].set_yticklabels(top_neg_words)\n",
        "axes[1].set_xlabel('系数值')\n",
        "axes[1].set_title(f'最重要的 {top_n} 个负特征')\n",
        "axes[1].invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 总结\n",
        "\n",
        "### 项目总结\n",
        "\n",
        "通过本项目，我们：\n",
        "1. ✅ 学会了如何处理文本数据（TF-IDF向量化）\n",
        "2. ✅ 使用逻辑回归进行文本分类\n",
        "3. ✅ 评估了模型性能（准确率、ROC曲线、混淆矩阵）\n",
        "4. ✅ 分析了特征重要性（哪些词对分类最重要）\n",
        "\n",
        "### 改进方向\n",
        "\n",
        "1. **数据质量**：使用真实的垃圾邮件数据集\n",
        "2. **特征工程**：尝试不同的特征提取方法（如n-gram）\n",
        "3. **模型优化**：调整正则化参数，尝试不同的C值\n",
        "4. **特征选择**：使用L1正则化进行特征选择\n",
        "5. **交叉验证**：使用交叉验证评估模型\n",
        "\n",
        "### 思考问题\n",
        "\n",
        "1. 为什么TF-IDF比简单的词频（TF）更好？\n",
        "2. 如何解释逻辑回归的系数？\n",
        "3. 如何处理类别不平衡问题？\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
