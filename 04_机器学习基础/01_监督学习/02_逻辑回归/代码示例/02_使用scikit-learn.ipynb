{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 使用scikit-learn实现逻辑回归\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "通过本notebook，你将学会：\n",
        "- 使用scikit-learn实现逻辑回归\n",
        "- 处理二分类和多分类问题\n",
        "- 使用正则化（L1和L2）\n",
        "- 评估分类模型性能（准确率、ROC曲线、混淆矩阵）\n",
        "- 理解多分类逻辑回归（Softmax）\n",
        "\n",
        "## 课程概述\n",
        "\n",
        "本notebook将展示如何使用scikit-learn库实现逻辑回归，包括：\n",
        "1. **二分类问题**：基本的二分类任务\n",
        "2. **多分类问题**：使用Softmax的多分类任务\n",
        "3. **正则化**：L1和L2正则化的对比\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_classification, load_breast_cancer, load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
        "                            roc_curve, auc)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置随机种子\n",
        "np.random.seed(42)\n",
        "\n",
        "# 设置matplotlib在notebook中内联显示\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 示例1：二分类问题\n",
        "\n",
        "使用逻辑回归解决二分类问题，包括数据准备、模型训练、评估和可视化。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 生成二分类数据\n",
        "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, \n",
        "                           n_informative=2, n_clusters_per_class=1, \n",
        "                           random_state=42)\n",
        "\n",
        "# 划分数据\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 标准化（逻辑回归通常需要标准化，特别是使用正则化时）\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"训练集大小: {X_train.shape[0]}\")\n",
        "print(f\"测试集大小: {X_test.shape[0]}\")\n",
        "print(f\"特征维度: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建模型\n",
        "# random_state: 随机种子，确保结果可复现\n",
        "# max_iter: 最大迭代次数\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# 训练模型\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 预测\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_proba = model.predict_proba(X_test_scaled)[:, 1]  # 正类的概率\n",
        "\n",
        "# 评估\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"准确率: {accuracy:.4f}\")\n",
        "print(\"\\n分类报告:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 计算ROC曲线\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print(f\"\\nROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# 显示模型参数\n",
        "print(f\"\\n模型参数:\")\n",
        "print(f\"偏置项: {model.intercept_[0]:.4f}\")\n",
        "print(f\"权重: {model.coef_[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化结果\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 1. ROC曲线\n",
        "axes[0].plot(fpr, tpr, label=f'ROC曲线 (AUC = {roc_auc:.2f})', linewidth=2)\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', label='随机分类器')\n",
        "axes[0].set_xlabel('假正例率 (FPR)')\n",
        "axes[0].set_ylabel('真正例率 (TPR)')\n",
        "axes[0].set_title('ROC曲线')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. 决策边界\n",
        "x_min, x_max = X_test_scaled[:, 0].min() - 1, X_test_scaled[:, 0].max() + 1\n",
        "y_min, y_max = X_test_scaled[:, 1].min() - 1, X_test_scaled[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "axes[1].contourf(xx, yy, Z, levels=50, alpha=0.5, cmap='RdYlBu')\n",
        "axes[1].contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n",
        "axes[1].scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], c=y_test, \n",
        "               cmap='RdYlBu', edgecolors='black', s=30)\n",
        "axes[1].set_xlabel('特征1')\n",
        "axes[1].set_ylabel('特征2')\n",
        "axes[1].set_title('决策边界')\n",
        "plt.colorbar(axes[1].contourf(xx, yy, Z, levels=50, alpha=0.5, cmap='RdYlBu'), \n",
        "             ax=axes[1], label='预测概率')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 示例2：多分类问题\n",
        "\n",
        "使用逻辑回归解决多分类问题（Iris数据集），展示Softmax回归。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载Iris数据集\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 划分数据\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 标准化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"数据集信息:\")\n",
        "print(f\"  类别数量: {len(iris.target_names)}\")\n",
        "print(f\"  类别名称: {iris.target_names}\")\n",
        "print(f\"  特征数量: {X.shape[1]}\")\n",
        "print(f\"  样本数量: {X.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建多分类模型\n",
        "# multi_class='multinomial': 使用Softmax（多项逻辑回归）\n",
        "# solver='lbfgs': 优化算法，适合多分类问题\n",
        "model_multi = LogisticRegression(multi_class='multinomial', solver='lbfgs', \n",
        "                                  random_state=42, max_iter=1000)\n",
        "\n",
        "# 训练\n",
        "model_multi.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 预测\n",
        "y_pred = model_multi.predict(X_test_scaled)\n",
        "y_proba = model_multi.predict_proba(X_test_scaled)  # 每个类别的概率\n",
        "\n",
        "# 评估\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"准确率: {accuracy:.4f}\")\n",
        "print(\"\\n分类报告:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "# 混淆矩阵\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(f\"\\n混淆矩阵:\")\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化混淆矩阵\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=iris.target_names,\n",
        "            yticklabels=iris.target_names)\n",
        "plt.title('混淆矩阵')\n",
        "plt.ylabel('真实标签')\n",
        "plt.xlabel('预测标签')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 显示前5个样本的概率预测\n",
        "print(\"\\n前5个样本的概率预测:\")\n",
        "print(\"样本 | 真实类别 | 预测类别 | 各类别概率\")\n",
        "print(\"-\" * 50)\n",
        "for i in range(min(5, len(y_test))):\n",
        "    print(f\"  {i+1}  |    {iris.target_names[y_test[i]]:<8} | \"\n",
        "          f\"  {iris.target_names[y_pred[i]]:<8} | {y_proba[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 示例3：正则化对比\n",
        "\n",
        "对比L1和L2正则化对模型性能的影响，使用乳腺癌数据集。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载乳腺癌数据集\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "# 划分数据\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 标准化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"数据集信息:\")\n",
        "print(f\"  样本数量: {X.shape[0]}\")\n",
        "print(f\"  特征数量: {X.shape[1]}\")\n",
        "print(f\"  类别: {cancer.target_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试不同的正则化方法\n",
        "# C是正则化强度的倒数，C越小，正则化越强\n",
        "regularizations = [\n",
        "    ('L2 (C=1.0)', LogisticRegression(penalty='l2', C=1.0, random_state=42, max_iter=1000)),\n",
        "    ('L2 (C=0.1)', LogisticRegression(penalty='l2', C=0.1, random_state=42, max_iter=1000)),\n",
        "    ('L1 (C=1.0)', LogisticRegression(penalty='l1', C=1.0, solver='liblinear', \n",
        "                                      random_state=42, max_iter=1000)),\n",
        "    ('L1 (C=0.1)', LogisticRegression(penalty='l1', C=0.1, solver='liblinear', \n",
        "                                      random_state=42, max_iter=1000)),\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in regularizations:\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    # 统计非零参数数量（L1正则化会产生稀疏性）\n",
        "    n_nonzero = np.sum(model.coef_[0] != 0)\n",
        "    \n",
        "    results.append({\n",
        "        'name': name,\n",
        "        'accuracy': accuracy,\n",
        "        'n_nonzero': n_nonzero,\n",
        "        'n_features': len(model.coef_[0])\n",
        "    })\n",
        "    \n",
        "    print(f\"{name:<15}: 准确率={accuracy:.4f}, \"\n",
        "          f\"非零参数={n_nonzero}/{len(model.coef_[0])}\")\n",
        "\n",
        "# 可视化结果\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# 准确率对比\n",
        "names = [r['name'] for r in results]\n",
        "accuracies = [r['accuracy'] for r in results]\n",
        "axes[0].bar(names, accuracies, color=['skyblue', 'lightblue', 'lightcoral', 'salmon'])\n",
        "axes[0].set_ylabel('准确率')\n",
        "axes[0].set_title('不同正则化方法的准确率')\n",
        "axes[0].set_xticklabels(names, rotation=45, ha='right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# 非零参数数量（稀疏性）\n",
        "n_nonzeros = [r['n_nonzero'] for r in results]\n",
        "axes[1].bar(names, n_nonzeros, color=['skyblue', 'lightblue', 'lightcoral', 'salmon'])\n",
        "axes[1].set_ylabel('非零参数数量')\n",
        "axes[1].set_title('不同正则化方法的稀疏性（L1会产生稀疏性）')\n",
        "axes[1].set_xticklabels(names, rotation=45, ha='right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n观察:\")\n",
        "print(\"- L1正则化会产生稀疏性（部分参数变为0），适合特征选择\")\n",
        "print(\"- L2正则化会缩小所有参数，但不为0\")\n",
        "print(\"- 正则化强度（C值）越小，正则化效果越强\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 总结与思考\n",
        "\n",
        "### 关键知识点总结\n",
        "\n",
        "1. **scikit-learn的LogisticRegression**：\n",
        "   - 支持二分类和多分类\n",
        "   - 默认使用L2正则化\n",
        "   - 需要标准化特征\n",
        "\n",
        "2. **多分类逻辑回归**：\n",
        "   - 使用`multi_class='multinomial'`启用Softmax\n",
        "   - 适合多类别分类问题\n",
        "\n",
        "3. **正则化**：\n",
        "   - L1正则化：产生稀疏性，适合特征选择\n",
        "   - L2正则化：缩小所有参数，防止过拟合\n",
        "   - C参数：正则化强度的倒数，C越小正则化越强\n",
        "\n",
        "### 思考问题\n",
        "\n",
        "1. **为什么逻辑回归需要标准化？**\n",
        "   - 提示：考虑正则化和梯度下降的影响\n",
        "\n",
        "2. **L1和L2正则化有什么区别？**\n",
        "   - 提示：观察参数的变化和稀疏性\n",
        "\n",
        "3. **什么时候使用多分类逻辑回归？**\n",
        "   - 提示：考虑类别数量和问题类型\n",
        "\n",
        "### 下一步学习\n",
        "\n",
        "- 学习处理类别不平衡问题\n",
        "- 学习特征工程和特征选择\n",
        "- 学习模型调优和超参数搜索\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
