# 挑战练习1：大规模数据与在线学习

## 练习目标

处理大规模数据，实现增量学习和在线学习。

## 练习要求

### 1. 大规模数据处理

1. **数据生成/加载**
   - 生成或加载大规模数据集（10万+样本）
   - 分析内存使用情况

2. **批量处理**
   - 实现批量梯度下降
   - 实现小批量梯度下降（Mini-batch）
   - 实现随机梯度下降（SGD）
   - 比较不同方法的性能

3. **内存优化**
   - 使用生成器处理数据
   - 使用HDF5或Parquet格式存储
   - 优化内存使用

### 2. 增量学习

1. **实现增量逻辑回归**
   - 支持增量更新参数
   - 处理新数据到来时的模型更新
   - 不需要重新训练整个模型

2. **增量学习流程**
   - 初始模型训练
   - 新数据到来时增量更新
   - 评估增量学习的效果
   - 对比全量重训练

3. **性能评估**
   - 比较增量学习和全量重训练的时间
   - 比较两种方法的准确率
   - 分析增量学习的适用场景

### 3. 在线学习

1. **实现在线逻辑回归**
   - 使用随机梯度下降（SGD）
   - 支持在线更新
   - 处理数据流

2. **在线学习流程**
   - 模拟数据流
   - 逐个样本更新模型
   - 定期评估模型性能
   - 监控模型性能变化

3. **自适应学习率**
   - 实现学习率衰减
   - 实现自适应学习率（AdaGrad、Adam等）
   - 比较不同学习率策略

### 4. 分布式训练（可选）

1. **数据并行**
   - 将数据分片
   - 在不同进程/机器上训练
   - 聚合参数更新

2. **模型并行**
   - 将模型分片
   - 分布式计算梯度
   - 同步参数

### 5. 性能优化

1. **计算优化**
   - 使用NumPy向量化
   - 使用Numba加速
   - 使用多线程/多进程

2. **内存优化**
   - 减少内存占用
   - 使用稀疏矩阵
   - 流式处理数据

3. **性能分析**
   - 使用cProfile分析性能瓶颈
   - 优化关键代码
   - 对比优化前后性能

## 代码要求

- 实现完整的增量学习和在线学习
- 处理大规模数据（10万+样本）
- 性能优化
- 详细的性能分析报告

## 评估标准

- **正确性**（30分）：正确实现增量/在线学习
- **性能**（30分）：能够处理大规模数据
- **优化**（20分）：性能优化有效
- **分析**（20分）：性能分析深入

## 预期结果

- 能够处理10万+样本的数据
- 增量学习速度明显快于全量重训练
- 在线学习能够适应数据流
- 性能优化有明显效果

## 提示

1. **批量处理**：
   ```python
   def batch_generator(X, y, batch_size):
       n_samples = X.shape[0]
       for i in range(0, n_samples, batch_size):
           yield X[i:i+batch_size], y[i:i+batch_size]
   ```

2. **增量更新**：
   ```python
   def incremental_update(self, X_new, y_new, learning_rate):
       # 只使用新数据更新参数
       gradient = self.compute_gradient(X_new, y_new)
       self.theta -= learning_rate * gradient
   ```

3. **学习率衰减**：
   ```python
   learning_rate = initial_lr / (1 + decay_rate * epoch)
   ```

4. **性能分析**：
   ```python
   import cProfile
   cProfile.run('your_function()')
   ```

---

**完成后，请将代码保存为 `练习1_答案.py`，并放在 `答案/` 文件夹中。**

