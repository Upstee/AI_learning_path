# 基础练习3：正则化与特征选择

## 练习目标

学习如何使用正则化进行特征选择，理解L1和L2正则化的区别。

## 练习要求

### 1. 数据准备

使用高维数据集（如`load_breast_cancer`，30个特征），完成：

1. **加载数据**
   - 加载乳腺癌数据集
   - 划分训练集和测试集（80/20）
   - 标准化数据

2. **特征分析**
   - 计算每个特征与目标的相关性
   - 可视化特征重要性

### 2. L1正则化特征选择

1. **训练模型**
   - 使用L1正则化，测试不同的C值（0.001, 0.01, 0.1, 1, 10）
   - 记录每个C值选择的特征数量

2. **特征选择分析**
   - 绘制C值与特征数量的关系图
   - 找出最优C值（使用交叉验证）
   - 可视化选择的特征

3. **模型性能**
   - 比较使用所有特征和选择特征后的性能
   - 分析特征选择对模型的影响

### 3. L2正则化对比

1. **训练模型**
   - 使用L2正则化，测试相同的C值
   - 记录模型性能

2. **对比分析**
   - 比较L1和L2的准确率
   - 比较L1和L2的参数分布
   - 分析两种正则化的适用场景

### 4. 特征重要性可视化

1. **绘制特征权重**
   - L1正则化：绘制非零特征的权重
   - L2正则化：绘制所有特征的权重
   - 对比两种方法的特征选择效果

2. **特征选择效果评估**
   - 使用选择的特征重新训练模型
   - 评估模型性能
   - 分析特征选择的价值

## 代码要求

- 实现完整的特征选择流程
- 使用交叉验证选择最优参数
- 可视化特征选择结果
- 包含详细的分析和解释

## 评估标准

- **正确性**（30分）：正确实现特征选择
- **分析深度**（30分）：深入分析正则化效果
- **可视化**（20分）：图表清晰美观
- **代码质量**（20分）：代码结构清晰

## 预期结果

- 能够通过L1正则化选择重要特征
- 理解L1产生稀疏解，L2产生平滑解
- 特征选择后模型性能可能略有下降，但更简洁
- 可视化结果清晰展示特征选择过程

## 提示

1. **交叉验证选择C值**：
   ```python
   from sklearn.model_selection import GridSearchCV
   param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}
   grid_search = GridSearchCV(LogisticRegression(penalty='l1', solver='liblinear'), 
                              param_grid, cv=5)
   ```

2. **统计非零特征**：
   ```python
   n_nonzero = np.sum(model.coef_[0] != 0)
   ```

3. **可视化特征权重**：
   ```python
   plt.barh(range(len(selected_features)), model.coef_[0][selected_features])
   ```

---

**完成后，请将代码保存为 `练习3_答案.py`，并放在 `答案/` 文件夹中。**

