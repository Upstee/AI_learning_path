{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 中等项目2：超参数调优系统\n",
        "\n",
        "## 学习目标\n",
        "- 理解不同超参数搜索方法的原理\n",
        "- 使用网格搜索进行超参数调优\n",
        "- 使用随机搜索进行超参数调优\n",
        "- 使用贝叶斯优化进行超参数调优\n",
        "- 分析超参数对模型性能的影响\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.datasets import load_iris\n",
        "from scipy.stats import randint, uniform\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"警告: optuna未安装，贝叶斯优化功能将不可用。安装命令: pip install optuna\")\n",
        "\n",
        "# 设置中文字体和样式\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 数据准备\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载Iris数据集\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"数据信息\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"训练集样本数: {len(X_train)}\")\n",
        "print(f\"测试集样本数: {len(X_test)}\")\n",
        "print(f\"特征数: {X.shape[1]}\")\n",
        "print(f\"类别数: {len(np.unique(y))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 网格搜索（Grid Search）\n",
        "\n",
        "网格搜索会遍历所有参数组合，找到最佳参数。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义参数网格\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# 创建基础模型\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 网格搜索\n",
        "print(\"=\" * 60)\n",
        "print(\"开始网格搜索...\")\n",
        "print(\"=\" * 60)\n",
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', \n",
        "                           n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n最佳参数: {grid_search.best_params_}\")\n",
        "print(f\"最佳交叉验证得分: {grid_search.best_score_:.4f}\")\n",
        "print(f\"总参数组合数: {len(grid_search.cv_results_['params'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 随机搜索（Random Search）\n",
        "\n",
        "随机搜索从参数分布中随机采样，通常比网格搜索更高效。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义参数分布\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [3, 5, 7, None],\n",
        "    'min_samples_split': randint(2, 10)\n",
        "}\n",
        "\n",
        "# 随机搜索\n",
        "print(\"=\" * 60)\n",
        "print(\"开始随机搜索...\")\n",
        "print(\"=\" * 60)\n",
        "random_search = RandomizedSearchCV(rf, param_dist, n_iter=20, cv=5, \n",
        "                                   scoring='accuracy', random_state=42, \n",
        "                                   n_jobs=-1, verbose=1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\n最佳参数: {random_search.best_params_}\")\n",
        "print(f\"最佳交叉验证得分: {random_search.best_score_:.4f}\")\n",
        "print(f\"尝试的参数组合数: {len(random_search.cv_results_['params'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 贝叶斯优化（Optuna）\n",
        "\n",
        "贝叶斯优化使用历史实验结果来指导下一步的参数选择，通常比随机搜索更高效。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if OPTUNA_AVAILABLE:\n",
        "    # 定义目标函数\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "            'random_state': 42\n",
        "        }\n",
        "        \n",
        "        model = RandomForestClassifier(**params)\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "        return scores.mean()\n",
        "    \n",
        "    # 运行优化\n",
        "    print(\"=\" * 60)\n",
        "    print(\"开始贝叶斯优化...\")\n",
        "    print(\"=\" * 60)\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
        "    \n",
        "    print(f\"\\n最佳参数: {study.best_params}\")\n",
        "    print(f\"最佳得分: {study.best_value:.4f}\")\n",
        "    print(f\"尝试的参数组合数: {len(study.trials)}\")\n",
        "else:\n",
        "    print(\"跳过贝叶斯优化（optuna未安装）\")\n",
        "    study = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 结果对比和可视化\n",
        "\n",
        "比较不同搜索方法找到的最佳模型在测试集上的性能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 准备最佳模型\n",
        "best_models = {\n",
        "    '网格搜索': grid_search.best_estimator_,\n",
        "    '随机搜索': random_search.best_estimator_\n",
        "}\n",
        "\n",
        "if OPTUNA_AVAILABLE and study:\n",
        "    best_models['贝叶斯优化'] = RandomForestClassifier(**study.best_params, random_state=42)\n",
        "\n",
        "# 在测试集上评估\n",
        "results = {}\n",
        "print(\"=\" * 60)\n",
        "print(\"测试集评估结果\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'cv_score': grid_search.best_score_ if name == '网格搜索' else \n",
        "                   (random_search.best_score_ if name == '随机搜索' else study.best_value)\n",
        "    }\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  交叉验证得分: {results[name]['cv_score']:.4f}\")\n",
        "    print(f\"  测试集准确率: {accuracy:.4f}\")\n",
        "\n",
        "# 可视化对比\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# 左图：交叉验证得分对比\n",
        "ax1 = axes[0]\n",
        "names = list(results.keys())\n",
        "cv_scores = [results[name]['cv_score'] for name in names]\n",
        "ax1.bar(names, cv_scores, alpha=0.7, color=['skyblue', 'lightgreen', 'lightcoral'][:len(names)])\n",
        "ax1.set_ylabel('交叉验证得分', fontsize=12)\n",
        "ax1.set_title('交叉验证得分对比', fontsize=14)\n",
        "ax1.grid(True, axis='y', alpha=0.3)\n",
        "for i, (name, score) in enumerate(zip(names, cv_scores)):\n",
        "    ax1.text(i, score + 0.01, f'{score:.4f}', ha='center', va='bottom')\n",
        "\n",
        "# 右图：测试集准确率对比\n",
        "ax2 = axes[1]\n",
        "test_accuracies = [results[name]['accuracy'] for name in names]\n",
        "ax2.bar(names, test_accuracies, alpha=0.7, color=['skyblue', 'lightgreen', 'lightcoral'][:len(names)])\n",
        "ax2.set_ylabel('测试集准确率', fontsize=12)\n",
        "ax2.set_title('测试集准确率对比', fontsize=14)\n",
        "ax2.grid(True, axis='y', alpha=0.3)\n",
        "for i, (name, acc) in enumerate(zip(names, test_accuracies)):\n",
        "    ax2.text(i, acc + 0.01, f'{acc:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('hyperparameter_tuning_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"总结\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 网格搜索：遍历所有参数组合，最全面但最耗时\")\n",
        "print(\"2. 随机搜索：随机采样参数，通常比网格搜索更高效\")\n",
        "print(\"3. 贝叶斯优化：使用历史结果指导搜索，通常最高效\")\n",
        "print(\"\\n根据数据规模和计算资源选择合适的搜索方法！\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
