{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 交叉验证\n",
        "\n",
        "## 学习目标\n",
        "\n",
        "- 理解交叉验证的原理和重要性\n",
        "- 掌握K折交叉验证、分层交叉验证、留一法\n",
        "- 学会使用交叉验证进行模型比较\n",
        "- 理解不同K值对评估结果的影响\n",
        "\n",
        "## 课程概述\n",
        "\n",
        "本Notebook将带你全面学习交叉验证方法。交叉验证是评估模型性能的重要技术，可以充分利用数据，避免过拟合，并帮助我们选择最佳模型。\n",
        "\n",
        "**学习路径**：\n",
        "1. K折交叉验证基础\n",
        "2. 分层K折交叉验证\n",
        "3. 留一法（LOOCV）\n",
        "4. 多指标交叉验证\n",
        "5. 模型比较\n",
        "6. 不同K值的影响分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import (cross_val_score, KFold, StratifiedKFold,\n",
        "                                    LeaveOneOut, cross_validate)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置随机种子\n",
        "np.random.seed(42)\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 理论回顾\n",
        "\n",
        "### 为什么需要交叉验证？\n",
        "\n",
        "**问题**：如果只用一次训练-测试划分，评估结果可能不够稳定，因为：\n",
        "- 数据划分的随机性会影响结果\n",
        "- 可能过拟合测试集\n",
        "- 无法充分利用数据\n",
        "\n",
        "**解决方案**：交叉验证（Cross-Validation）\n",
        "\n",
        "### K折交叉验证（K-Fold Cross-Validation）\n",
        "\n",
        "**原理**：\n",
        "1. 将数据分成K份（通常K=5或10）\n",
        "2. 每次用K-1份训练，1份验证\n",
        "3. 重复K次，得到K个评估结果\n",
        "4. 计算平均值和标准差\n",
        "\n",
        "**优点**：\n",
        "- 充分利用所有数据\n",
        "- 评估结果更稳定\n",
        "- 可以发现过拟合问题\n",
        "\n",
        "### 分层K折交叉验证（Stratified K-Fold）\n",
        "\n",
        "**特点**：\n",
        "- 保持每折中各类别的比例与原始数据相同\n",
        "- 特别适合类别不平衡的数据\n",
        "\n",
        "### 留一法（Leave-One-Out Cross-Validation, LOOCV）\n",
        "\n",
        "**特点**：\n",
        "- K等于样本数\n",
        "- 每次只用1个样本验证\n",
        "- 计算量大，但评估结果无偏\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 数据准备\n",
        "\n",
        "首先生成分类数据，用于后续的交叉验证演示。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 生成分类数据\n",
        "# n_samples: 样本数量（200个样本，适合演示）\n",
        "# n_features: 特征数量\n",
        "# n_informative: 有信息的特征数量\n",
        "# n_redundant: 冗余特征数量\n",
        "# n_classes: 类别数量（二分类）\n",
        "X, y = make_classification(n_samples=200, n_features=10, n_informative=5,\n",
        "                          n_redundant=2, n_classes=2, random_state=42)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"数据信息\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"样本数: {X.shape[0]}\")\n",
        "print(f\"特征数: {X.shape[1]}\")\n",
        "print(f\"类别数: {len(np.unique(y))}\")\n",
        "print(f\"类别分布: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. K折交叉验证\n",
        "\n",
        "K折交叉验证是最常用的交叉验证方法。让我们看看如何使用它。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建模型\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# 使用5折交叉验证\n",
        "# n_splits: 折数（K值）\n",
        "# shuffle: 是否打乱数据\n",
        "# random_state: 随机种子\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 进行交叉验证\n",
        "# scoring: 评估指标（'accuracy'表示准确率）\n",
        "scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"K折交叉验证\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n5折交叉验证结果:\")\n",
        "for i, score in enumerate(scores, 1):\n",
        "    print(f\"  折 {i}: {score:.4f} ({score*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n统计结果:\")\n",
        "print(f\"  平均准确率: {scores.mean():.4f} ({scores.mean()*100:.2f}%)\")\n",
        "print(f\"  标准差: {scores.std():.4f}\")\n",
        "print(f\"  最小值: {scores.min():.4f}\")\n",
        "print(f\"  最大值: {scores.max():.4f}\")\n",
        "\n",
        "print(\"\\n说明:\")\n",
        "print(\"- 将200个样本分成5折，每折40个样本\")\n",
        "print(\"- 每次用4折（160个样本）训练，1折（40个样本）验证\")\n",
        "print(\"- 重复5次，得到5个评估结果\")\n",
        "print(\"- 计算平均值和标准差，得到更稳定的评估\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 分层K折交叉验证\n",
        "\n",
        "对于类别不平衡的数据，分层交叉验证可以保持每折中各类别的比例。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用分层5折交叉验证\n",
        "# StratifiedKFold会保持每折中各类别的比例与原始数据相同\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores_stratified = cross_val_score(model, X, y, cv=skfold, scoring='accuracy')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"分层K折交叉验证\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n分层5折交叉验证结果:\")\n",
        "for i, score in enumerate(scores_stratified, 1):\n",
        "    print(f\"  折 {i}: {score:.4f} ({score*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n统计结果:\")\n",
        "print(f\"  平均准确率: {scores_stratified.mean():.4f} ({scores_stratified.mean()*100:.2f}%)\")\n",
        "print(f\"  标准差: {scores_stratified.std():.4f}\")\n",
        "\n",
        "print(\"\\n说明:\")\n",
        "print(\"- 分层交叉验证保持每折中各类别的比例\")\n",
        "print(\"- 对于类别不平衡的数据，分层交叉验证更准确\")\n",
        "print(\"- 通常推荐使用分层交叉验证（StratifiedKFold）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 留一法（LOOCV）\n",
        "\n",
        "留一法是K折交叉验证的特殊情况，K等于样本数。虽然计算量大，但评估结果无偏。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 注意：留一法计算量大，这里只用前50个样本演示\n",
        "# 对于200个样本，留一法需要训练200次模型，计算时间较长\n",
        "X_small = X[:50]\n",
        "y_small = y[:50]\n",
        "\n",
        "# 创建留一法交叉验证器\n",
        "loocv = LeaveOneOut()\n",
        "\n",
        "# 进行留一法交叉验证\n",
        "scores_loocv = cross_val_score(model, X_small, y_small, cv=loocv, scoring='accuracy')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"留一法（LOOCV）\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n留一法交叉验证结果（前50个样本）:\")\n",
        "print(f\"  平均准确率: {scores_loocv.mean():.4f} ({scores_loocv.mean()*100:.2f}%)\")\n",
        "print(f\"  标准差: {scores_loocv.std():.4f}\")\n",
        "print(f\"  评估次数: {len(scores_loocv)} (等于样本数)\")\n",
        "\n",
        "print(\"\\n说明:\")\n",
        "print(\"- 留一法：每次只用1个样本验证，其余49个样本训练\")\n",
        "print(\"- 重复50次，得到50个评估结果\")\n",
        "print(\"- 计算量大，但评估结果无偏\")\n",
        "print(\"- 通常用于小数据集（<100个样本）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 多指标交叉验证\n",
        "\n",
        "使用`cross_validate`可以同时计算多个评估指标，更全面地评估模型性能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 定义多个评估指标\n",
        "# make_scorer: 将评估函数转换为scorer对象\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'precision': make_scorer(precision_score),\n",
        "    'recall': make_scorer(recall_score),\n",
        "    'f1': make_scorer(f1_score)\n",
        "}\n",
        "\n",
        "# 使用cross_validate计算多个指标\n",
        "# cross_validate返回一个字典，包含所有指标的测试分数\n",
        "cv_results = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"多指标交叉验证\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n多指标交叉验证结果（5折）:\")\n",
        "for metric in scoring.keys():\n",
        "    scores = cv_results[f'test_{metric}']  # 注意：键名是 'test_指标名'\n",
        "    print(f\"\\n{metric.upper()}:\")\n",
        "    print(f\"  各折结果: {[f'{s:.4f}' for s in scores]}\")\n",
        "    print(f\"  平均值: {scores.mean():.4f}\")\n",
        "    print(f\"  标准差: {scores.std():.4f}\")\n",
        "\n",
        "print(\"\\n说明:\")\n",
        "print(\"- cross_validate可以同时计算多个评估指标\")\n",
        "print(\"- 返回字典包含 'test_指标名' 的键\")\n",
        "print(\"- 可以更全面地评估模型性能\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 模型比较\n",
        "\n",
        "使用交叉验证可以公平地比较不同模型的性能。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建多个模型\n",
        "models = {\n",
        "    '逻辑回归': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    '决策树': DecisionTreeClassifier(random_state=42),\n",
        "    '随机森林': RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "}\n",
        "\n",
        "# 使用交叉验证评估每个模型\n",
        "results = {}\n",
        "print(\"=\" * 60)\n",
        "print(\"模型比较\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
        "    results[name] = scores\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  平均准确率: {scores.mean():.4f} ({scores.mean()*100:.2f}%)\")\n",
        "    print(f\"  标准差: {scores.std():.4f}\")\n",
        "\n",
        "# 可视化模型比较\n",
        "plt.figure(figsize=(10, 6))\n",
        "positions = np.arange(len(models))\n",
        "means = [results[name].mean() for name in models.keys()]\n",
        "stds = [results[name].std() for name in models.keys()]\n",
        "\n",
        "plt.bar(positions, means, yerr=stds, alpha=0.7, \n",
        "        color=['skyblue', 'lightgreen', 'lightcoral'],\n",
        "        edgecolor='black', capsize=5, width=0.6)\n",
        "plt.xticks(positions, models.keys(), fontsize=12)\n",
        "plt.ylabel('准确率', fontsize=12)\n",
        "plt.title('模型比较（5折交叉验证）', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "# 添加数值标签\n",
        "for i, (mean, std) in enumerate(zip(means, stds)):\n",
        "    plt.text(i, mean + std + 0.01, f'{mean:.3f}±{std:.3f}',\n",
        "             ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 找出最佳模型\n",
        "best_model_name = max(results.keys(), key=lambda k: results[k].mean())\n",
        "print(f\"\\n最佳模型: {best_model_name} (准确率: {results[best_model_name].mean():.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 不同K值的影响\n",
        "\n",
        "K值的选择会影响交叉验证的结果。让我们看看不同K值的影响。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试不同的K值\n",
        "k_values = [3, 5, 10, 20]\n",
        "k_results = {}\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"不同K值的影响\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for k in k_values:\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
        "    k_results[k] = scores\n",
        "    print(f\"\\nK={k}:\")\n",
        "    print(f\"  平均准确率: {scores.mean():.4f} ({scores.mean()*100:.2f}%)\")\n",
        "    print(f\"  标准差: {scores.std():.4f}\")\n",
        "    print(f\"  评估次数: {len(scores)}\")\n",
        "\n",
        "# 可视化\n",
        "plt.figure(figsize=(12, 6))\n",
        "means = [k_results[k].mean() for k in k_values]\n",
        "stds = [k_results[k].std() for k in k_values]\n",
        "\n",
        "plt.plot(k_values, means, marker='o', linewidth=2, markersize=10, \n",
        "         label='平均准确率', color='darkblue')\n",
        "plt.fill_between(k_values, \n",
        "                 [m - s for m, s in zip(means, stds)],\n",
        "                 [m + s for m, s in zip(means, stds)],\n",
        "                 alpha=0.3, label='±1标准差', color='lightblue')\n",
        "\n",
        "plt.xlabel('K值（折数）', fontsize=12)\n",
        "plt.ylabel('准确率', fontsize=12)\n",
        "plt.title('不同K值的交叉验证结果', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(k_values)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n说明:\")\n",
        "print(\"- K值小（如3）: 计算快，但方差大，评估结果不够稳定\")\n",
        "print(\"- K值大（如20）: 计算慢，但方差小，评估结果更稳定\")\n",
        "print(\"- 通常K取5-10，平衡计算成本和评估稳定性\")\n",
        "print(\"- 对于小数据集，可以使用留一法（K=样本数）\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 总结与思考\n",
        "\n",
        "### 关键知识点回顾\n",
        "\n",
        "1. **K折交叉验证**：将数据分成K份，每次用K-1份训练，1份验证，重复K次\n",
        "2. **分层交叉验证**：保持每折中各类别的比例，适合类别不平衡的数据\n",
        "3. **留一法**：K等于样本数，计算量大但评估结果无偏\n",
        "4. **多指标交叉验证**：同时计算多个评估指标，全面评估模型性能\n",
        "5. **模型比较**：使用交叉验证可以公平地比较不同模型\n",
        "6. **K值选择**：通常K取5-10，平衡计算成本和评估稳定性\n",
        "\n",
        "### 思考问题\n",
        "\n",
        "1. **什么时候使用分层交叉验证？**\n",
        "   - 类别不平衡的数据\n",
        "   - 需要保持各类别比例的场景\n",
        "\n",
        "2. **如何选择合适的K值？**\n",
        "   - 小数据集（<100样本）：可以使用留一法\n",
        "   - 中等数据集（100-1000样本）：K=5或10\n",
        "   - 大数据集（>1000样本）：K=5即可\n",
        "\n",
        "3. **交叉验证的优缺点？**\n",
        "   - 优点：充分利用数据，评估结果稳定，可以发现过拟合\n",
        "   - 缺点：计算量大，需要多次训练模型\n",
        "\n",
        "### 下一步学习\n",
        "\n",
        "- 学习超参数调优（GridSearchCV、RandomizedSearchCV）\n",
        "- 学习特征选择方法\n",
        "- 学习模型优化技巧\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
