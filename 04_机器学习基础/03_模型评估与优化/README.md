# æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–

## 1. è¯¾ç¨‹æ¦‚è¿°

### è¯¾ç¨‹ç›®æ ‡
1. ç†è§£æ¨¡å‹è¯„ä¼°çš„é‡è¦æ€§å’Œè¯„ä¼°æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ã€ROCã€AUCï¼‰
2. æŒæ¡äº¤å‰éªŒè¯æ–¹æ³•ï¼ˆKæŠ˜äº¤å‰éªŒè¯ã€ç•™ä¸€æ³•ã€åˆ†å±‚äº¤å‰éªŒè¯ï¼‰
3. ç†è§£è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆé—®é¢˜
4. æŒæ¡æ¨¡å‹ä¼˜åŒ–æ–¹æ³•ï¼ˆè¶…å‚æ•°è°ƒä¼˜ã€ç‰¹å¾é€‰æ‹©ã€æ­£åˆ™åŒ–ï¼‰
5. èƒ½å¤Ÿä½¿ç”¨scikit-learnè¿›è¡Œæ¨¡å‹è¯„ä¼°å’Œä¼˜åŒ–
6. èƒ½å¤Ÿåº”ç”¨è¯„ä¼°å’Œä¼˜åŒ–æŠ€æœ¯æå‡æ¨¡å‹æ€§èƒ½

### é¢„è®¡å­¦ä¹ æ—¶é—´
- **ç†è®ºå­¦ä¹ **ï¼š10-12å°æ—¶
- **ä»£ç å®è·µ**ï¼š12-14å°æ—¶
- **ç»ƒä¹ å·©å›º**ï¼š10-12å°æ—¶
- **æ€»è®¡**ï¼š32-38å°æ—¶ï¼ˆçº¦4-5å‘¨ï¼‰

### éš¾åº¦ç­‰çº§
- **ä¸­ç­‰åä¸Š** - éœ€è¦ç†è§£å¤šç§è¯„ä¼°æŒ‡æ ‡å’Œä¼˜åŒ–æ–¹æ³•

### è¯¾ç¨‹å®šä½
- **å‰ç½®è¯¾ç¨‹**ï¼š01_ç›‘ç£å­¦ä¹ ã€02_æ— ç›‘ç£å­¦ä¹ 
- **åç»­è¯¾ç¨‹**ï¼š04_å®æˆ˜é¡¹ç›®ã€05_æ·±åº¦å­¦ä¹ åŸºç¡€
- **åœ¨ä½“ç³»ä¸­çš„ä½ç½®**ï¼šæ¨¡å‹å¼€å‘çš„å…³é”®ç¯èŠ‚ï¼Œç¡®ä¿æ¨¡å‹è´¨é‡

### å­¦å®Œèƒ½åšä»€ä¹ˆ
- èƒ½å¤Ÿæ­£ç¡®è¯„ä¼°æ¨¡å‹æ€§èƒ½
- èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
- èƒ½å¤Ÿä½¿ç”¨äº¤å‰éªŒè¯
- èƒ½å¤Ÿè¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
- èƒ½å¤Ÿä¼˜åŒ–æ¨¡å‹æ€§èƒ½

---

## 2. å‰ç½®çŸ¥è¯†æ£€æŸ¥

### å¿…å¤‡å‰ç½®æ¦‚å¿µæ¸…å•
- **ç›‘ç£å­¦ä¹ **ï¼šåˆ†ç±»ã€å›å½’
- **æ¦‚ç‡ç»Ÿè®¡**ï¼šæ··æ·†çŸ©é˜µã€ROCæ›²çº¿
- **NumPyã€Pandas**ï¼šæ•°æ®å¤„ç†
- **scikit-learn**ï¼šåŸºæœ¬ä½¿ç”¨

### å›é¡¾é“¾æ¥/è·³è½¬
- å¦‚æœä¸ç†Ÿæ‚‰åˆ†ç±»ï¼š`04_æœºå™¨å­¦ä¹ åŸºç¡€/01_ç›‘ç£å­¦ä¹ /`
- å¦‚æœä¸ç†Ÿæ‚‰æ¦‚ç‡ç»Ÿè®¡ï¼š`02_æ•°å­¦åŸºç¡€/02_æ¦‚ç‡ç»Ÿè®¡/`
- å¦‚æœä¸ç†Ÿæ‚‰scikit-learnï¼š`03_æ•°æ®å¤„ç†åŸºç¡€/`

### å…¥é—¨å°æµ‹

**é€‰æ‹©é¢˜**ï¼ˆæ¯é¢˜2åˆ†ï¼Œå…±10åˆ†ï¼‰

1. å‡†ç¡®ç‡é€‚ç”¨äºå“ªç§æƒ…å†µï¼Ÿ
   A. ç±»åˆ«å¹³è¡¡  B. ç±»åˆ«ä¸å¹³è¡¡  C. å›å½’é—®é¢˜  D. èšç±»é—®é¢˜
   **ç­”æ¡ˆ**ï¼šA

2. ç²¾ç¡®ç‡è¡¡é‡çš„æ˜¯ï¼Ÿ
   A. é¢„æµ‹ä¸ºæ­£ä¾‹ä¸­çœŸæ­£ä¾‹çš„æ¯”ä¾‹  B. çœŸæ­£ä¾‹ä¸­é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹  C. å‡†ç¡®ç‡  D. å¬å›ç‡
   **ç­”æ¡ˆ**ï¼šA

3. ROCæ›²çº¿çš„æ¨ªè½´æ˜¯ï¼Ÿ
   A. çœŸæ­£ä¾‹ç‡  B. å‡æ­£ä¾‹ç‡  C. ç²¾ç¡®ç‡  D. å¬å›ç‡
   **ç­”æ¡ˆ**ï¼šB

4. KæŠ˜äº¤å‰éªŒè¯ä¸­ï¼ŒKé€šå¸¸å–ï¼Ÿ
   A. 2-3  B. 5-10  C. 20-30  D. 50+
   **ç­”æ¡ˆ**ï¼šB

5. è¿‡æ‹Ÿåˆçš„è¡¨ç°æ˜¯ï¼Ÿ
   A. è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯¯å·®éƒ½é«˜  B. è®­ç»ƒé›†è¯¯å·®ä½ï¼Œæµ‹è¯•é›†è¯¯å·®é«˜  C. è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯¯å·®éƒ½ä½  D. è®­ç»ƒé›†è¯¯å·®é«˜
   **ç­”æ¡ˆ**ï¼šB

**è¯„åˆ†æ ‡å‡†**ï¼šâ‰¥8åˆ†ï¼ˆ80%ï¼‰ä¸ºé€šè¿‡

---

## 3. æ ¸å¿ƒçŸ¥è¯†ç‚¹è¯¦è§£

### 3.1 åˆ†ç±»è¯„ä¼°æŒ‡æ ‡

#### æ··æ·†çŸ©é˜µ

|  | é¢„æµ‹æ­£ä¾‹ | é¢„æµ‹è´Ÿä¾‹ |
|--|---------|---------|
| å®é™…æ­£ä¾‹ | TP | FN |
| å®é™…è´Ÿä¾‹ | FP | TN |

#### è¯„ä¼°æŒ‡æ ‡

**å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼š
$$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$

**ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰**ï¼š
$$Precision = \frac{TP}{TP + FP}$$

**å¬å›ç‡ï¼ˆRecallï¼‰**ï¼š
$$Recall = \frac{TP}{TP + FN}$$

**F1åˆ†æ•°**ï¼š
$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$

**ROCæ›²çº¿å’ŒAUC**ï¼š
- ROCæ›²çº¿ï¼šä»¥å‡æ­£ä¾‹ç‡ä¸ºæ¨ªè½´ï¼ŒçœŸæ­£ä¾‹ç‡ä¸ºçºµè½´
- AUCï¼šROCæ›²çº¿ä¸‹é¢ç§¯ï¼Œå€¼è¶Šå¤§è¶Šå¥½

---

### 3.2 å›å½’è¯„ä¼°æŒ‡æ ‡

**å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ï¼š
$$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$$

**å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰**ï¼š
$$RMSE = \sqrt{MSE}$$

**å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰**ï¼š
$$MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$$

**RÂ²åˆ†æ•°**ï¼š
$$R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2}$$

---

### 3.3 äº¤å‰éªŒè¯

#### KæŠ˜äº¤å‰éªŒè¯

å°†æ•°æ®åˆ†æˆKä»½ï¼Œæ¯æ¬¡ç”¨K-1ä»½è®­ç»ƒï¼Œ1ä»½æµ‹è¯•ï¼Œé‡å¤Kæ¬¡ã€‚

**ä¼˜ç‚¹**ï¼š
- å……åˆ†åˆ©ç”¨æ•°æ®
- å‡å°‘éšæœºæ€§å½±å“
- æ›´å¯é çš„æ€§èƒ½ä¼°è®¡

#### åˆ†å±‚äº¤å‰éªŒè¯

ä¿æŒæ¯æŠ˜ä¸­ç±»åˆ«æ¯”ä¾‹ä¸åŸå§‹æ•°æ®ä¸€è‡´ã€‚

---

### 3.4 æ¨¡å‹ä¼˜åŒ–

#### è¶…å‚æ•°è°ƒä¼˜

**ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰**ï¼šéå†æ‰€æœ‰å‚æ•°ç»„åˆ

**éšæœºæœç´¢ï¼ˆRandom Searchï¼‰**ï¼šéšæœºé‡‡æ ·å‚æ•°ç»„åˆ

**è´å¶æ–¯ä¼˜åŒ–**ï¼šä½¿ç”¨è´å¶æ–¯æ–¹æ³•é€‰æ‹©å‚æ•°

#### ç‰¹å¾é€‰æ‹©

**è¿‡æ»¤æ³•**ï¼šåŸºäºç»Ÿè®¡ç‰¹å¾é€‰æ‹©

**åŒ…è£…æ³•**ï¼šåŸºäºæ¨¡å‹æ€§èƒ½é€‰æ‹©

**åµŒå…¥æ³•**ï¼šæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­é€‰æ‹©

---

## 4. Pythonä»£ç å®è·µ

### 4.1 åˆ†ç±»è¯„ä¼°

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt

# è¯„ä¼°åˆ†ç±»æ¨¡å‹
y_true = [0, 1, 1, 0, 1, 0, 1, 1, 0, 1]
y_pred = [0, 1, 1, 0, 0, 0, 1, 1, 0, 1]

# åŸºæœ¬æŒ‡æ ‡
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

print(f"å‡†ç¡®ç‡: {accuracy:.4f}")
print(f"ç²¾ç¡®ç‡: {precision:.4f}")
print(f"å¬å›ç‡: {recall:.4f}")
print(f"F1åˆ†æ•°: {f1:.4f}")

# æ··æ·†çŸ©é˜µ
cm = confusion_matrix(y_true, y_pred)
print("\næ··æ·†çŸ©é˜µ:")
print(cm)

# è¯¦ç»†æŠ¥å‘Š
print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_true, y_pred))

# ROCæ›²çº¿
y_scores = [0.1, 0.9, 0.8, 0.2, 0.3, 0.1, 0.9, 0.8, 0.2, 0.9]
fpr, tpr, thresholds = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='éšæœºçŒœæµ‹')
plt.xlabel('å‡æ­£ä¾‹ç‡')
plt.ylabel('çœŸæ­£ä¾‹ç‡')
plt.title('ROCæ›²çº¿')
plt.legend()
plt.grid(True)
plt.show()
```

---

### 4.2 äº¤å‰éªŒè¯

```python
from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

# åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# åˆ›å»ºæ¨¡å‹
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# KæŠ˜äº¤å‰éªŒè¯
cv_scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')
print(f"äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

# åˆ†å±‚äº¤å‰éªŒè¯
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_stratified = cross_val_score(clf, X, y, cv=skf, scoring='accuracy')
print(f"åˆ†å±‚äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores_stratified.mean():.4f} Â± {cv_scores_stratified.std():.4f}")
```

---

### 4.3 è¶…å‚æ•°è°ƒä¼˜

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from scipy.stats import randint

# åŠ è½½æ•°æ®
iris = load_iris()
X, y = iris.data, iris.target

# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, None],
    'min_samples_split': [2, 5, 10]
}

# ç½‘æ ¼æœç´¢
clf = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X, y)

print("æœ€ä½³å‚æ•°:", grid_search.best_params_)
print("æœ€ä½³å¾—åˆ†:", grid_search.best_score_)

# éšæœºæœç´¢
param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': [3, 5, 7, None],
    'min_samples_split': randint(2, 10)
}

random_search = RandomizedSearchCV(clf, param_dist, n_iter=20, cv=5, 
                                   scoring='accuracy', random_state=42, n_jobs=-1)
random_search.fit(X, y)

print("\néšæœºæœç´¢æœ€ä½³å‚æ•°:", random_search.best_params_)
print("éšæœºæœç´¢æœ€ä½³å¾—åˆ†:", random_search.best_score_)
```

---

## 5. åŠ¨æ‰‹ç»ƒä¹ ï¼ˆåˆ†å±‚æ¬¡ï¼‰

### åŸºç¡€ç»ƒä¹ ï¼ˆ3-5é¢˜ï¼‰âš ï¸ã€å¿…é¡»è‡³å°‘3é¢˜ï¼Œéš¾åº¦é€’å¢ã€‘

#### ç»ƒä¹ 1ï¼šå®ç°åˆ†ç±»è¯„ä¼°æŒ‡æ ‡
**ç›®æ ‡**ï¼šä»é›¶å®ç°åˆ†ç±»è¯„ä¼°æŒ‡æ ‡

**è¦æ±‚**ï¼š
1. å®ç°å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
2. å®ç°æ··æ·†çŸ©é˜µ
3. åœ¨æ¨¡æ‹Ÿæ•°æ®ä¸Šæµ‹è¯•
4. ä¸scikit-learnç»“æœå¯¹æ¯”

**éš¾åº¦**ï¼šâ­â­

---

#### ç»ƒä¹ 2ï¼šå®ç°äº¤å‰éªŒè¯
**ç›®æ ‡**ï¼šä»é›¶å®ç°KæŠ˜äº¤å‰éªŒè¯

**è¦æ±‚**ï¼š
1. å®ç°KæŠ˜äº¤å‰éªŒè¯
2. å®ç°åˆ†å±‚äº¤å‰éªŒè¯
3. åœ¨çœŸå®æ•°æ®é›†ä¸Šæµ‹è¯•
4. ä¸scikit-learnç»“æœå¯¹æ¯”

**éš¾åº¦**ï¼šâ­â­â­

---

#### ç»ƒä¹ 3ï¼šè¶…å‚æ•°è°ƒä¼˜å®è·µ
**ç›®æ ‡**ï¼šä½¿ç”¨ç½‘æ ¼æœç´¢å’Œéšæœºæœç´¢è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜

**è¦æ±‚**ï¼š
1. ä½¿ç”¨ç½‘æ ¼æœç´¢
2. ä½¿ç”¨éšæœºæœç´¢
3. æ¯”è¾ƒä¸¤ç§æ–¹æ³•
4. åˆ†ææœ€ä¼˜å‚æ•°

**éš¾åº¦**ï¼šâ­â­â­

---

### è¿›é˜¶ç»ƒä¹ ï¼ˆ2-3é¢˜ï¼‰âš ï¸ã€å¿…é¡»è‡³å°‘2é¢˜ï¼Œéš¾åº¦é€’å¢ã€‘

#### ç»ƒä¹ 1ï¼šå®Œæ•´çš„æ¨¡å‹è¯„ä¼°æµç¨‹
**ç›®æ ‡**ï¼šæ„å»ºå®Œæ•´çš„æ¨¡å‹è¯„ä¼°ç³»ç»Ÿ

**è¦æ±‚**ï¼š
1. å®ç°å¤šç§è¯„ä¼°æŒ‡æ ‡
2. å®ç°äº¤å‰éªŒè¯
3. å¯è§†åŒ–è¯„ä¼°ç»“æœ
4. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

**éš¾åº¦**ï¼šâ­â­â­â­

---

#### ç»ƒä¹ 2ï¼šæ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ
**ç›®æ ‡**ï¼šæ„å»ºè‡ªåŠ¨åŒ–çš„æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ

**è¦æ±‚**ï¼š
1. å®ç°è¶…å‚æ•°è°ƒä¼˜
2. å®ç°ç‰¹å¾é€‰æ‹©
3. å®ç°æ¨¡å‹é›†æˆ
4. è‡ªåŠ¨åŒ–ä¼˜åŒ–æµç¨‹

**éš¾åº¦**ï¼šâ­â­â­â­

---

### æŒ‘æˆ˜ç»ƒä¹ ï¼ˆ1-2é¢˜ï¼‰âš ï¸ã€å¿…é¡»è‡³å°‘1é¢˜ã€‘

#### ç»ƒä¹ 1ï¼šå¤§è§„æ¨¡æ¨¡å‹è¯„ä¼°ä¸ä¼˜åŒ–
**ç›®æ ‡**ï¼šå¤„ç†å¤§è§„æ¨¡æ•°æ®çš„æ¨¡å‹è¯„ä¼°å’Œä¼˜åŒ–

**è¦æ±‚**ï¼š
1. å®ç°å¢é‡äº¤å‰éªŒè¯
2. ä¼˜åŒ–è¶…å‚æ•°æœç´¢æ•ˆç‡
3. å¤„ç†å¤§è§„æ¨¡æ•°æ®
4. å¹¶è¡ŒåŒ–è¯„ä¼°è¿‡ç¨‹
5. å®ç°åˆ†å¸ƒå¼ä¼˜åŒ–

**éš¾åº¦**ï¼šâ­â­â­â­â­

---

## 6. å®é™…æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šåˆ†ç±»æ¨¡å‹è¯„ä¼°ï¼ˆç®€å•é¡¹ç›®ï¼‰

**ä¸šåŠ¡èƒŒæ™¯**ï¼šè¯„ä¼°ä¸€ä¸ªäºŒåˆ†ç±»æ¨¡å‹çš„æ€§èƒ½ã€‚

**ç«¯åˆ°ç«¯å®ç°**ï¼š
```python
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.datasets import make_classification
import matplotlib.pyplot as plt

# ç”Ÿæˆæ•°æ®
X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, 
                           n_redundant=10, random_state=42)

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# é¢„æµ‹
y_pred = clf.predict(X_test)
y_proba = clf.predict_proba(X_test)[:, 1]

# è¯„ä¼°
print("åˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_pred))

print("\næ··æ·†çŸ©é˜µ:")
print(confusion_matrix(y_test, y_pred))

# ROCæ›²çº¿
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROCæ›²çº¿ (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('å‡æ­£ä¾‹ç‡')
plt.ylabel('çœŸæ­£ä¾‹ç‡')
plt.title('ROCæ›²çº¿')
plt.legend()
plt.grid(True)
plt.show()
```

---

### æ¡ˆä¾‹2ï¼šå›å½’æ¨¡å‹è¯„ä¼°ï¼ˆä¸­ç­‰é¡¹ç›®ï¼‰

**ä¸šåŠ¡èƒŒæ™¯**ï¼šè¯„ä¼°ä¸€ä¸ªå›å½’æ¨¡å‹çš„æ€§èƒ½ã€‚

**ç«¯åˆ°ç«¯å®ç°**ï¼š
```python
from sklearn.model_selection import cross_val_score, KFold
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.datasets import load_boston
import numpy as np

# åŠ è½½æ•°æ®
boston = load_boston()
X, y = boston.data, boston.target

# åˆ›å»ºæ¨¡å‹
reg = RandomForestRegressor(n_estimators=100, random_state=42)

# äº¤å‰éªŒè¯
cv_scores = cross_val_score(reg, X, y, cv=5, scoring='neg_mean_squared_error')
rmse_scores = np.sqrt(-cv_scores)

print(f"äº¤å‰éªŒè¯RMSE: {rmse_scores.mean():.2f} Â± {rmse_scores.std():.2f}")

# è®­ç»ƒå’Œè¯„ä¼°
reg.fit(X, y)
y_pred = reg.predict(X)

mse = mean_squared_error(y, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y, y_pred)
r2 = r2_score(y, y_pred)

print(f"\nMSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"RÂ²: {r2:.4f}")
```

---

### æ¡ˆä¾‹3ï¼šå®Œæ•´çš„æ¨¡å‹ä¼˜åŒ–æµç¨‹ï¼ˆè¿›é˜¶é¡¹ç›®ï¼‰

**ä¸šåŠ¡èƒŒæ™¯**ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿï¼ŒåŒ…æ‹¬ç‰¹å¾é€‰æ‹©ã€è¶…å‚æ•°è°ƒä¼˜ã€æ¨¡å‹è¯„ä¼°ã€‚

**ç«¯åˆ°ç«¯å®ç°**ï¼š
```python
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.datasets import load_breast_cancer
import numpy as np

# åŠ è½½æ•°æ®
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# æ­¥éª¤1ï¼šç‰¹å¾é€‰æ‹©
selector = SelectKBest(f_classif, k=10)
X_train_selected = selector.fit_transform(X_train, y_train)
X_test_selected = selector.transform(X_test)

print(f"åŸå§‹ç‰¹å¾æ•°: {X_train.shape[1]}")
print(f"é€‰æ‹©ç‰¹å¾æ•°: {X_train_selected.shape[1]}")

# æ­¥éª¤2ï¼šè¶…å‚æ•°è°ƒä¼˜
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7, None],
    'min_samples_split': [2, 5, 10]
}

clf = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search.fit(X_train_selected, y_train)

print(f"\næœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"æœ€ä½³äº¤å‰éªŒè¯å¾—åˆ†: {grid_search.best_score_:.4f}")

# æ­¥éª¤3ï¼šæœ€ç»ˆè¯„ä¼°
best_clf = grid_search.best_estimator_
y_pred = best_clf.predict(X_test_selected)
y_proba = best_clf.predict_proba(X_test_selected)[:, 1]

print("\næµ‹è¯•é›†æ€§èƒ½:")
print(classification_report(y_test, y_pred))
print(f"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}")
```

---

## 7. è‡ªæˆ‘è¯„ä¼°

### æ¦‚å¿µé¢˜

#### é€‰æ‹©é¢˜ï¼ˆ10-15é“ï¼‰

1. å‡†ç¡®ç‡é€‚ç”¨äºå“ªç§æƒ…å†µï¼Ÿ
   A. ç±»åˆ«å¹³è¡¡  B. ç±»åˆ«ä¸å¹³è¡¡  C. å›å½’é—®é¢˜  D. èšç±»é—®é¢˜
   **ç­”æ¡ˆ**ï¼šA

2. ç²¾ç¡®ç‡è¡¡é‡çš„æ˜¯ï¼Ÿ
   A. é¢„æµ‹ä¸ºæ­£ä¾‹ä¸­çœŸæ­£ä¾‹çš„æ¯”ä¾‹  B. çœŸæ­£ä¾‹ä¸­é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¯”ä¾‹  C. å‡†ç¡®ç‡  D. å¬å›ç‡
   **ç­”æ¡ˆ**ï¼šA

3. ROCæ›²çº¿çš„æ¨ªè½´æ˜¯ï¼Ÿ
   A. çœŸæ­£ä¾‹ç‡  B. å‡æ­£ä¾‹ç‡  C. ç²¾ç¡®ç‡  D. å¬å›ç‡
   **ç­”æ¡ˆ**ï¼šB

4. KæŠ˜äº¤å‰éªŒè¯ä¸­ï¼ŒKé€šå¸¸å–ï¼Ÿ
   A. 2-3  B. 5-10  C. 20-30  D. 50+
   **ç­”æ¡ˆ**ï¼šB

5. è¿‡æ‹Ÿåˆçš„è¡¨ç°æ˜¯ï¼Ÿ
   A. è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯¯å·®éƒ½é«˜  B. è®­ç»ƒé›†è¯¯å·®ä½ï¼Œæµ‹è¯•é›†è¯¯å·®é«˜  C. è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¯¯å·®éƒ½ä½  D. è®­ç»ƒé›†è¯¯å·®é«˜
   **ç­”æ¡ˆ**ï¼šB

#### ç®€ç­”é¢˜ï¼ˆ5-8é“ï¼‰

1. è§£é‡Šå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°çš„å«ä¹‰å’Œé€‚ç”¨åœºæ™¯ã€‚
   **å‚è€ƒç­”æ¡ˆ**ï¼š
   - å‡†ç¡®ç‡ï¼šé€‚ç”¨äºç±»åˆ«å¹³è¡¡çš„æƒ…å†µ
   - ç²¾ç¡®ç‡ï¼šå…³æ³¨é¢„æµ‹ä¸ºæ­£ä¾‹çš„å‡†ç¡®æ€§
   - å¬å›ç‡ï¼šå…³æ³¨çœŸæ­£ä¾‹çš„è¯†åˆ«ç‡
   - F1åˆ†æ•°ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡

2. è¯´æ˜äº¤å‰éªŒè¯çš„åŸç†å’Œä¼˜åŠ¿ã€‚
   **å‚è€ƒç­”æ¡ˆ**ï¼šå°†æ•°æ®åˆ†æˆKä»½ï¼Œæ¯æ¬¡ç”¨K-1ä»½è®­ç»ƒï¼Œ1ä»½æµ‹è¯•ï¼Œé‡å¤Kæ¬¡ã€‚ä¼˜åŠ¿ï¼šå……åˆ†åˆ©ç”¨æ•°æ®ï¼Œå‡å°‘éšæœºæ€§ï¼Œæ›´å¯é çš„æ€§èƒ½ä¼°è®¡ã€‚

---

### ç¼–ç¨‹å®è·µé¢˜ï¼ˆ2-3é“ï¼‰

#### é¢˜ç›®1ï¼šå®ç°åˆ†ç±»è¯„ä¼°ç³»ç»Ÿ
**è¦æ±‚**ï¼š
1. å®ç°å¤šç§è¯„ä¼°æŒ‡æ ‡
2. å®ç°æ··æ·†çŸ©é˜µ
3. å®ç°ROCæ›²çº¿
4. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

**è¯„åˆ†æ ‡å‡†**ï¼š
- æ­£ç¡®å®ç°æŒ‡æ ‡ï¼ˆ40åˆ†ï¼‰
- å¯è§†åŒ–æ¸…æ™°ï¼ˆ20åˆ†ï¼‰
- æŠ¥å‘Šå®Œæ•´ï¼ˆ20åˆ†ï¼‰
- ä»£ç è´¨é‡ï¼ˆ20åˆ†ï¼‰

---

### ç»¼åˆåº”ç”¨é¢˜ï¼ˆ1-2é“ï¼‰

#### é¢˜ç›®1ï¼šæ„å»ºå®Œæ•´çš„æ¨¡å‹ä¼˜åŒ–ç³»ç»Ÿ
**è¦æ±‚**ï¼š
1. å®ç°ç‰¹å¾é€‰æ‹©
2. å®ç°è¶…å‚æ•°è°ƒä¼˜
3. å®ç°äº¤å‰éªŒè¯
4. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
5. åˆ†æä¼˜åŒ–æ•ˆæœ

**è¯„åˆ†æ ‡å‡†**ï¼š
- åŠŸèƒ½å®ç°æ­£ç¡®ï¼ˆ30åˆ†ï¼‰
- ä¼˜åŒ–æ•ˆæœæ˜æ˜¾ï¼ˆ30åˆ†ï¼‰
- åˆ†ææ·±å…¥ï¼ˆ20åˆ†ï¼‰
- ä»£ç è´¨é‡ï¼ˆ20åˆ†ï¼‰

---

## 8. æ‹“å±•å­¦ä¹ 

### è®ºæ–‡æ¨è

1. **Kohavi, R. (1995). "A study of cross-validation and bootstrap for accuracy estimation and model selection."** IJCAI
   - äº¤å‰éªŒè¯ç»å…¸è®ºæ–‡

### ä¹¦ç±æ¨è

1. **ã€Šæœºå™¨å­¦ä¹ ã€‹- å‘¨å¿—å**
   - ç¬¬2ç« ï¼šæ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©

2. **ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹- æèˆª**
   - æ¨¡å‹è¯„ä¼°ç›¸å…³ç« èŠ‚

### ç›¸å…³å·¥å…·ä¸åº“

1. **scikit-learn**
   - æ¨¡å‹è¯„ä¼°å’Œä¼˜åŒ–å·¥å…·
   - æ–‡æ¡£ï¼šhttps://scikit-learn.org/stable/modules/model_evaluation.html

2. **optuna**
   - è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶
   - GitHub: https://github.com/optuna/optuna

### è¿›é˜¶è¯é¢˜æŒ‡å¼•

1. **é«˜çº§è¯„ä¼°æ–¹æ³•**
   - æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
   - åµŒå¥—äº¤å‰éªŒè¯
   - è‡ªåŠ©æ³•ï¼ˆBootstrapï¼‰

2. **é«˜çº§ä¼˜åŒ–æ–¹æ³•**
   - è´å¶æ–¯ä¼˜åŒ–
   - è¿›åŒ–ç®—æ³•
   - å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–

3. **æ¨¡å‹è§£é‡Šæ€§**
   - SHAPå€¼
   - LIME
   - ç‰¹å¾é‡è¦æ€§

### ä¸‹èŠ‚è¯¾é¢„å‘Šä¸å­¦ä¹ å»ºè®®

**ä¸‹èŠ‚è¯¾**ï¼š`04_å®æˆ˜é¡¹ç›®`

**å­¦ä¹ å»ºè®®**ï¼š
1. å®Œæˆæ‰€æœ‰ç»ƒä¹ é¢˜
2. ç†è§£ä¸åŒè¯„ä¼°æŒ‡æ ‡çš„é€‚ç”¨åœºæ™¯
3. æŒæ¡äº¤å‰éªŒè¯æ–¹æ³•
4. äº†è§£æ¨¡å‹ä¼˜åŒ–çš„ç­–ç•¥

**å‰ç½®å‡†å¤‡**ï¼š
- å¤ä¹ ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ 
- å‡†å¤‡çœŸå®æ•°æ®é›†
- äº†è§£é¡¹ç›®å¼€å‘æµç¨‹

---

**å®Œæˆæœ¬è¯¾ç¨‹åï¼Œä½ å°†èƒ½å¤Ÿï¼š**
- âœ… æ­£ç¡®è¯„ä¼°æ¨¡å‹æ€§èƒ½
- âœ… é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
- âœ… ä½¿ç”¨äº¤å‰éªŒè¯
- âœ… è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
- âœ… ä¼˜åŒ–æ¨¡å‹æ€§èƒ½

**ç»§ç»­å­¦ä¹ ï¼Œæˆä¸ºAIå¤§å¸ˆï¼** ğŸš€

