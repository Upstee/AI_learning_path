# 练习1：完整评估系统

## 练习目标

构建一个完整的模型评估系统，能够对多种模型进行全面的评估和对比分析。

## 练习要求

### 任务1：创建评估类

创建一个`ModelEvaluator`类，包含以下功能：

1. **初始化方法**
   ```python
   def __init__(self, models, X_train, y_train, X_test, y_test):
       """
       初始化评估器
       参数:
           models: 模型字典，格式为 {'模型名': 模型对象}
           X_train, y_train: 训练数据
           X_test, y_test: 测试数据
       """
   ```

2. **训练所有模型**
   ```python
   def train_all(self):
       """训练所有模型"""
   ```

3. **评估分类模型**
   ```python
   def evaluate_classification(self):
       """
       评估分类模型
       返回:
           dict: 包含所有评估指标的字典
       """
   ```

4. **评估回归模型**
   ```python
   def evaluate_regression(self):
       """
       评估回归模型
       返回:
           dict: 包含所有评估指标的字典
       """
   ```

5. **生成评估报告**
   ```python
   def generate_report(self, task_type='classification'):
       """
       生成评估报告
       参数:
           task_type: 'classification' 或 'regression'
       返回:
           str: 格式化的评估报告
       """
   ```

6. **可视化结果**
   ```python
   def visualize_results(self, task_type='classification', save_path=None):
       """
       可视化评估结果
         - 混淆矩阵热力图
         - ROC曲线（分类）
         - 预测值vs真实值散点图（回归）
         - 模型性能对比图
       """
   ```

### 任务2：实现交叉验证评估

扩展`ModelEvaluator`类，添加交叉验证功能：

1. **交叉验证评估**
   ```python
   def cross_validate(self, cv=5, scoring=None):
       """
       对每个模型进行交叉验证
       参数:
           cv: 交叉验证折数
           scoring: 评估指标
       返回:
           dict: 每个模型的交叉验证结果
       """
   ```

2. **比较训练集和测试集性能**
   ```python
   def compare_train_test(self):
       """
       比较训练集和测试集性能，检测过拟合
       返回:
           dict: 包含训练集和测试集性能对比
       """
   ```

### 任务3：模型选择和建议

1. **自动选择最佳模型**
   ```python
   def select_best_model(self, metric='f1', task_type='classification'):
       """
       根据指定指标选择最佳模型
       参数:
           metric: 评估指标名称
           task_type: 任务类型
       返回:
           tuple: (最佳模型名, 最佳模型对象, 最佳分数)
       """
   ```

2. **生成模型建议**
   ```python
   def generate_recommendations(self):
       """
       根据评估结果生成模型选择建议
       返回:
           str: 建议报告
       """
   ```

### 任务4：完整应用示例

使用`ModelEvaluator`完成以下任务：

1. **分类任务**：
   - 加载一个分类数据集（如`load_breast_cancer`）
   - 训练多个分类模型（至少5个）
   - 进行完整评估
   - 生成评估报告和可视化
   - 选择最佳模型

2. **回归任务**：
   - 加载一个回归数据集（如`load_diabetes`）
   - 训练多个回归模型（至少5个）
   - 进行完整评估
   - 生成评估报告和可视化
   - 选择最佳模型

## 代码框架

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer, load_diabetes
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import (
    RandomForestClassifier, RandomForestRegressor,
    GradientBoostingClassifier, GradientBoostingRegressor
)
from sklearn.svm import SVC, SVR
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, auc, r2_score,
    mean_squared_error, mean_absolute_error
)

class ModelEvaluator:
    def __init__(self, models, X_train, y_train, X_test, y_test):
        # TODO: 初始化
        pass
    
    def train_all(self):
        # TODO: 训练所有模型
        pass
    
    def evaluate_classification(self):
        # TODO: 评估分类模型
        pass
    
    def evaluate_regression(self):
        # TODO: 评估回归模型
        pass
    
    def generate_report(self, task_type='classification'):
        # TODO: 生成评估报告
        pass
    
    def visualize_results(self, task_type='classification', save_path=None):
        # TODO: 可视化结果
        pass
    
    def cross_validate(self, cv=5, scoring=None):
        # TODO: 交叉验证
        pass
    
    def compare_train_test(self):
        # TODO: 比较训练集和测试集性能
        pass
    
    def select_best_model(self, metric='f1', task_type='classification'):
        # TODO: 选择最佳模型
        pass
    
    def generate_recommendations(self):
        # TODO: 生成建议
        pass

# TODO: 使用ModelEvaluator完成分类和回归任务
```

## 输出要求

1. **分类任务输出**：
   - 完整的评估报告（包含所有指标）
   - 混淆矩阵热力图（每个模型）
   - ROC曲线图
   - 模型性能对比图
   - 交叉验证结果对比
   - 训练集vs测试集性能对比
   - 最佳模型选择结果
   - 模型建议报告

2. **回归任务输出**：
   - 完整的评估报告（包含所有指标）
   - 预测值vs真实值散点图（每个模型）
   - 残差图
   - 模型性能对比图
   - 交叉验证结果对比
   - 训练集vs测试集性能对比
   - 最佳模型选择结果
   - 模型建议报告

## 提示

1. 使用字典存储模型和结果，便于管理和访问
2. 使用`pandas.DataFrame`存储评估结果，便于分析和可视化
3. 使用`matplotlib`和`seaborn`进行可视化
4. 考虑使用`joblib`保存训练好的模型
5. 报告应该包含：
   - 模型列表
   - 评估指标表格
   - 可视化图表
   - 最佳模型推荐
   - 改进建议

## 思考题

1. 如何设计评估系统使其易于扩展新的模型？
2. 如何平衡评估的全面性和计算效率？
3. 在什么情况下，交叉验证结果比单次测试集评估更可靠？
4. 如何根据评估结果给出具体的模型改进建议？

## 难度等级

**进阶** - 需要综合运用多种评估方法和编程技能

## 预计时间

6-8小时

