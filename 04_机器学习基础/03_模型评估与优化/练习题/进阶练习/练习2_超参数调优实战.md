# 练习2：超参数调优实战

## 练习目标

掌握超参数调优的方法，包括网格搜索、随机搜索和贝叶斯优化，并理解如何评估调优效果。

## 练习要求

### 任务1：网格搜索（Grid Search）

1. **从零实现网格搜索**
   - 实现一个`GridSearch`类，不使用scikit-learn的`GridSearchCV`
   - 支持：
     - 参数网格定义
     - K折交叉验证
     - 最佳参数选择
     - 结果存储和可视化

2. **使用scikit-learn的网格搜索**
   - 使用`GridSearchCV`进行超参数调优
   - 比较从零实现与scikit-learn实现的性能

3. **网格搜索实战**
   - 对随机森林分类器进行超参数调优
   - 参数包括：`n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`
   - 使用交叉验证评估每个参数组合

### 任务2：随机搜索（Random Search）

1. **实现随机搜索**
   - 实现一个`RandomSearch`类
   - 从参数分布中随机采样参数组合
   - 使用交叉验证评估

2. **使用scikit-learn的随机搜索**
   - 使用`RandomizedSearchCV`进行超参数调优
   - 比较网格搜索和随机搜索的效率

3. **随机搜索实战**
   - 对SVM分类器进行超参数调优
   - 参数包括：`C`, `gamma`, `kernel`
   - 比较网格搜索和随机搜索的结果

### 任务3：贝叶斯优化

1. **使用Optuna进行贝叶斯优化**
   - 安装和使用`optuna`库
   - 定义参数搜索空间
   - 使用贝叶斯优化寻找最佳参数

2. **贝叶斯优化实战**
   - 对XGBoost分类器进行超参数调优
   - 比较贝叶斯优化与网格搜索、随机搜索的效率

### 任务4：超参数调优系统

创建一个`HyperparameterTuner`类，整合所有调优方法：

```python
class HyperparameterTuner:
    def __init__(self, model, param_grid, X, y, cv=5, scoring='accuracy'):
        """
        初始化超参数调优器
        参数:
           model: 模型类
           param_grid: 参数网格
           X, y: 数据
           cv: 交叉验证折数
           scoring: 评估指标
        """
        pass
    
    def grid_search(self):
        """网格搜索"""
        pass
    
    def random_search(self, n_iter=100):
        """随机搜索"""
        pass
    
    def bayesian_optimization(self, n_trials=100):
        """贝叶斯优化"""
        pass
    
    def compare_methods(self):
        """比较不同调优方法"""
        pass
```

### 任务5：完整应用

使用超参数调优系统完成以下任务：

1. **分类任务**：
   - 加载分类数据集
   - 对至少3个模型进行超参数调优
   - 比较调优前后的性能
   - 分析不同调优方法的效率

2. **回归任务**：
   - 加载回归数据集
   - 对至少3个模型进行超参数调优
   - 比较调优前后的性能
   - 分析不同调优方法的效率

## 代码框架

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import product
from sklearn.datasets import load_breast_cancer, load_diabetes
from sklearn.model_selection import (
    train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score
)
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.svm import SVC, SVR
from sklearn.metrics import accuracy_score, r2_score
import optuna

# TODO: 从零实现网格搜索
class GridSearch:
    def __init__(self, model, param_grid, X, y, cv=5, scoring='accuracy'):
        pass
    
    def fit(self):
        pass
    
    def best_params_(self):
        pass
    
    def best_score_(self):
        pass

# TODO: 实现随机搜索
class RandomSearch:
    def __init__(self, model, param_distributions, X, y, n_iter=100, cv=5, scoring='accuracy'):
        pass
    
    def fit(self):
        pass

# TODO: 创建HyperparameterTuner类
class HyperparameterTuner:
    pass

# TODO: 完成分类和回归任务的超参数调优
```

## 输出要求

1. **网格搜索结果**：
   - 参数组合和对应的交叉验证分数
   - 最佳参数和最佳分数
   - 参数重要性分析（如果适用）
   - 调优前后性能对比

2. **随机搜索结果**：
   - 搜索的参数组合和分数
   - 最佳参数和最佳分数
   - 与网格搜索的对比

3. **贝叶斯优化结果**：
   - 优化历史
   - 最佳参数和最佳分数
   - 与网格搜索、随机搜索的对比

4. **综合分析报告**：
   - 不同调优方法的效率对比
   - 不同调优方法的结果对比
   - 适用场景建议
   - 调优效果分析

## 测试数据集

1. **分类数据集**：`load_breast_cancer`
2. **回归数据集**：`load_diabetes`

## 提示

1. **网格搜索**：
   - 适合参数空间较小的情况
   - 计算成本高，但结果全面

2. **随机搜索**：
   - 适合参数空间较大的情况
   - 计算效率高，可能找到更好的参数

3. **贝叶斯优化**：
   - 使用历史信息指导搜索
   - 通常比随机搜索更高效
   - 需要安装`optuna`库

4. **参数网格定义**：
   - 使用字典定义参数网格
   - 对于连续参数，使用`np.logspace`或`np.linspace`生成候选值

## 思考题

1. 为什么随机搜索可能比网格搜索找到更好的参数？
2. 贝叶斯优化的原理是什么？为什么它更高效？
3. 如何平衡超参数调优的计算成本和性能提升？
4. 在什么情况下应该使用网格搜索而不是随机搜索？
5. 如何判断超参数调优是否过拟合？

## 难度等级

**进阶** - 需要理解超参数调优的原理和不同方法的适用场景

## 预计时间

8-10小时

