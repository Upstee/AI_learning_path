# K-means - 概念题

## 一、选择题（每题2分，共20分）

### 1. K-means是什么类型的算法？
A. 监督学习  
B. 无监督学习  
C. 强化学习  
D. 半监督学习  

**答案**：B

**解释**：⚠️【详细解释】K-means是无监督学习算法，不需要标签，通过数据本身的特征进行聚类。

---

### 2. K-means的目标函数是？
A. 最大化簇间距离  
B. 最小化簇内平方和  
C. 最大化准确率  
D. 最小化误差率  

**答案**：B

**解释**：⚠️【详细解释】K-means的目标是最小化簇内平方和（WCSS），即最小化所有样本到其所属簇中心的距离平方和。

---

### 3. K-means的初始化方法不包括？
A. 随机初始化  
B. K-means++  
C. 层次聚类初始化  
D. 均值初始化  

**答案**：D

**解释**：⚠️【详细解释】K-means的初始化方法包括随机初始化和K-means++，不包括均值初始化。

---

### 4. 肘部法则用于？
A. 选择K值  
B. 选择距离度量  
C. 选择初始化方法  
D. 选择迭代次数  

**答案**：A

**解释**：⚠️【详细解释】肘部法则是选择K值的方法，通过绘制K值与WCSS的关系图，找到"肘部"点作为最优K值。

---

### 5. 轮廓系数的范围是？
A. [0, 1]  
B. [-1, 1]  
C. [0, ∞)  
D. (-∞, ∞)  

**答案**：B

**解释**：⚠️【详细解释】轮廓系数的范围是[-1, 1]，越接近1表示聚类质量越好。

---

### 6. K-means假设簇是？
A. 球形的  
B. 长条形的  
C. 任意形状的  
D. 圆形的  

**答案**：A

**解释**：⚠️【详细解释】K-means假设簇是球形的，使用欧氏距离，适合球形簇，对非球形簇效果不好。

---

### 7. Mini-batch K-means的主要优势是？
A. 准确率更高  
B. 计算更快  
C. 结果更稳定  
D. 不需要K值  

**答案**：B

**解释**：⚠️【详细解释】Mini-batch K-means每次只使用部分样本更新聚类中心，计算更快，适合大规模数据。

---

### 8. K-means的迭代过程包括？
A. 分配和更新  
B. 训练和测试  
C. 前向和反向  
D. 编码和解码  

**答案**：A

**解释**：⚠️【详细解释】K-means的迭代过程包括：分配样本到最近的簇，然后更新聚类中心，重复这两个步骤直到收敛。

---

### 9. K-means对什么敏感？
A. 初始值  
B. 数据量  
C. 特征数  
D. 样本顺序  

**答案**：A

**解释**：⚠️【详细解释】K-means对初始值敏感，不同的初始化可能导致不同的结果，可能收敛到局部最优。

---

### 10. K-means++的主要改进是？
A. 更快的计算  
B. 更好的初始化  
C. 更少的迭代  
D. 更小的内存  

**答案**：B

**解释**：⚠️【详细解释】K-means++改进了初始化方法，选择距离已选中心较远的点，通常能获得更好的结果。

---

## 二、简答题（每题10分，共40分）

### 1. 解释K-means的算法流程。

**参考答案**：
- **初始化**：随机选择K个样本作为初始聚类中心
- **分配**：将每个样本分配到最近的聚类中心
- **更新**：计算每个簇的均值，更新聚类中心
- **重复**：重复分配和更新步骤，直到聚类中心不再变化（或变化很小）
- **收敛**：算法保证收敛，但可能收敛到局部最优

---

### 2. 说明肘部法则的原理和应用。

**参考答案**：
- **原理**：绘制K值与簇内平方和（WCSS）的关系图，WCSS会随着K值增加而减少
- **肘部点**：当K值增加到一定程度，WCSS减少变慢，转折点就是"肘部"点
- **应用**：选择"肘部"点作为最优K值，平衡簇数和聚类质量
- **优点**：简单直观，容易理解
- **缺点**：有时"肘部"点不明显，需要主观判断

---

### 3. 解释轮廓系数的含义和计算方法。

**参考答案**：
- **含义**：评估聚类质量，衡量样本与其所属簇的相似度
- **公式**：s(i) = (b(i) - a(i)) / max(a(i), b(i))
  - a(i)：样本i到同簇其他样本的平均距离（簇内距离）
  - b(i)：样本i到最近其他簇的样本的平均距离（簇间距离）
- **范围**：[-1, 1]
- **解释**：
  - 接近1：样本聚类很好
  - 接近0：样本在两个簇的边界
  - 接近-1：样本可能被分错了

---

### 4. 说明K-means的优缺点。

**参考答案**：
- **优点**：
  1. 简单高效，容易理解和实现
  2. 计算快速，适合大规模数据
  3. 结果直观，每个簇有一个中心
  4. 可扩展，适合增量学习
  
- **缺点**：
  1. 需要指定K值
  2. 对初始值敏感，可能收敛到局部最优
  3. 假设簇是球形的，不适合非球形簇
  4. 对异常值敏感，异常值会影响聚类中心

---

## 三、计算题（每题10分，共20分）

### 1. 给定以下数据，使用K-means（K=2）进行一轮迭代：

初始中心：
- 中心1：(1, 1)
- 中心2：(5, 5)

样本：
- 样本1：(2, 2)
- 样本2：(3, 3)
- 样本3：(6, 6)
- 样本4：(7, 7)

使用欧氏距离，计算分配和更新后的中心。

**参考答案**：
- **分配**：
  - 样本1到中心1距离：√((2-1)²+(2-1)²) = √2 ≈ 1.41
  - 样本1到中心2距离：√((2-5)²+(2-5)²) = √18 ≈ 4.24
  - 样本1分配到中心1
  
  - 样本2到中心1距离：√((3-1)²+(3-1)²) = √8 ≈ 2.83
  - 样本2到中心2距离：√((3-5)²+(3-5)²) = √8 ≈ 2.83
  - 样本2分配到中心1（距离相等，选择第一个）
  
  - 样本3和4分配到中心2（类似计算）
  
- **更新**：
  - 中心1新位置：((2+3)/2, (2+3)/2) = (2.5, 2.5)
  - 中心2新位置：((6+7)/2, (6+7)/2) = (6.5, 6.5)

---

### 2. 给定K=3，计算轮廓系数（简化版）：

样本1：
- a(1) = 2.0（到同簇其他样本的平均距离）
- b(1) = 5.0（到最近其他簇的样本的平均距离）

**参考答案**：
- s(1) = (b(1) - a(1)) / max(a(1), b(1))
- s(1) = (5.0 - 2.0) / max(2.0, 5.0)
- s(1) = 3.0 / 5.0 = 0.6
- **解释**：轮廓系数为0.6，表示样本1聚类较好，但还有改进空间

---

## 评分标准

- **选择题**：每题2分，共20分
- **简答题**：每题10分，共40分
- **计算题**：每题10分，共20分
- **总分**：80分
- **及格线**：64分（80%）

---

**完成后请对照答案检查，理解每道题的原理！**

