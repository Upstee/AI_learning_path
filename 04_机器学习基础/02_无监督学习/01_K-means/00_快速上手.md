# K-meanså¿«é€Ÿä¸Šæ‰‹

> **ç›®æ ‡**ï¼š30åˆ†é’Ÿå†…å¿«é€Ÿä½“éªŒK-meansï¼Œå»ºç«‹å­¦ä¹ ä¿¡å¿ƒï¼Œæ˜ç¡®å­¦ä¹ ç›®æ ‡

---

## ğŸš€ 30åˆ†é’Ÿå¿«é€Ÿä½“éªŒ

### æ­¥éª¤1ï¼šå®‰è£…ä¾èµ–ï¼ˆ2åˆ†é’Ÿï¼‰

```bash
pip install numpy pandas matplotlib scikit-learn
```

### æ­¥éª¤2ï¼šè¿è¡Œç¬¬ä¸€ä¸ªK-meansç¤ºä¾‹ï¼ˆ5åˆ†é’Ÿï¼‰

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
import numpy as np

# ç”Ÿæˆç¤ºä¾‹æ•°æ®ï¼ˆ300ä¸ªç‚¹ï¼Œ3ä¸ªç°‡ï¼‰
X, y_true = make_blobs(n_samples=300, centers=3, n_features=2, random_state=42)

# ä½¿ç”¨K-meansèšç±»ï¼ˆåªéœ€è¦3è¡Œä»£ç ï¼ï¼‰
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X)
labels = kmeans.labels_

# å¯è§†åŒ–ç»“æœ
plt.figure(figsize=(10, 5))

# çœŸå®æ ‡ç­¾
plt.subplot(1, 2, 1)
plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis', alpha=0.6)
plt.title('çœŸå®æ ‡ç­¾ï¼ˆ3ä¸ªç°‡ï¼‰')
plt.xlabel('ç‰¹å¾1')
plt.ylabel('ç‰¹å¾2')

# K-meansèšç±»ç»“æœ
plt.subplot(1, 2, 2)
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
           c='red', marker='x', s=200, linewidths=3, label='è´¨å¿ƒ')
plt.title('K-meansèšç±»ç»“æœ')
plt.xlabel('ç‰¹å¾1')
plt.ylabel('ç‰¹å¾2')
plt.legend()

plt.tight_layout()
plt.show()

print(f"âœ… æˆåŠŸï¼æ•°æ®è¢«åˆ†æˆ {len(np.unique(labels))} ä¸ªç°‡")
print(f"è´¨å¿ƒä½ç½®:\n{kmeans.cluster_centers_}")
```

**è¿è¡Œç»“æœ**ï¼šä½ ä¼šçœ‹åˆ°æ•°æ®è¢«æˆåŠŸåˆ†æˆ3ä¸ªç°‡ï¼Œçº¢è‰²Xæ ‡è®°æ˜¯è´¨å¿ƒä½ç½®ã€‚

### æ­¥éª¤3ï¼šä¿®æ”¹å‚æ•°çœ‹æ•ˆæœï¼ˆ10åˆ†é’Ÿï¼‰

å°è¯•ä¿®æ”¹ä»¥ä¸‹å‚æ•°ï¼Œè§‚å¯Ÿæ•ˆæœï¼š

```python
# ä¿®æ”¹Kå€¼ï¼ˆç°‡çš„æ•°é‡ï¼‰
for k in [2, 3, 4, 5]:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    labels = kmeans.labels_
    
    plt.figure(figsize=(8, 6))
    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)
    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
               c='red', marker='x', s=200, linewidths=3)
    plt.title(f'K={k} çš„èšç±»ç»“æœ')
    plt.show()
```

**è§‚å¯Ÿ**ï¼š
- K=2ï¼šæ•°æ®è¢«åˆ†æˆ2ä¸ªç°‡
- K=3ï¼šæ•°æ®è¢«åˆ†æˆ3ä¸ªç°‡ï¼ˆæœ€åˆé€‚ï¼‰
- K=4ï¼šæ•°æ®è¢«åˆ†æˆ4ä¸ªç°‡ï¼ˆå¯èƒ½è¿‡æ‹Ÿåˆï¼‰
- K=5ï¼šæ•°æ®è¢«åˆ†æˆ5ä¸ªç°‡ï¼ˆæ˜æ˜¾è¿‡æ‹Ÿåˆï¼‰

### æ­¥éª¤4ï¼šåº”ç”¨åˆ°çœŸå®åœºæ™¯ï¼ˆ10åˆ†é’Ÿï¼‰

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler

# æ¨¡æ‹Ÿå®¢æˆ·æ•°æ®
np.random.seed(42)
data = {
    'æ¶ˆè´¹é‡‘é¢': np.random.normal(1000, 300, 200),
    'æ¶ˆè´¹é¢‘ç‡': np.random.poisson(5, 200),
    'æœ€è¿‘æ¶ˆè´¹': np.random.randint(0, 365, 200)
}
df = pd.DataFrame(data)

# æ ‡å‡†åŒ–æ•°æ®ï¼ˆé‡è¦ï¼ï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df)

# K-meansèšç±»
kmeans = KMeans(n_clusters=3, random_state=42)
kmeans.fit(X_scaled)
df['å®¢æˆ·ç¾¤ä½“'] = kmeans.labels_

# åˆ†ææ¯ä¸ªç¾¤ä½“çš„ç‰¹å¾
print("å®¢æˆ·åˆ†ç¾¤ç»“æœï¼š")
for i in range(3):
    group = df[df['å®¢æˆ·ç¾¤ä½“'] == i]
    print(f"\nç¾¤ä½“{i} (å…±{len(group)}äºº):")
    print(f"  å¹³å‡æ¶ˆè´¹é‡‘é¢: {group['æ¶ˆè´¹é‡‘é¢'].mean():.2f}")
    print(f"  å¹³å‡æ¶ˆè´¹é¢‘ç‡: {group['æ¶ˆè´¹é¢‘ç‡'].mean():.2f}")
    print(f"  å¹³å‡æœ€è¿‘æ¶ˆè´¹: {group['æœ€è¿‘æ¶ˆè´¹'].mean():.2f}å¤©å‰")
```

**ç»“æœ**ï¼šå®¢æˆ·è¢«åˆ†æˆ3ä¸ªç¾¤ä½“ï¼Œæ¯ä¸ªç¾¤ä½“æœ‰ä¸åŒçš„æ¶ˆè´¹ç‰¹å¾ï¼

---

## ğŸ¯ ç†è§£K-meansåœ¨åšä»€ä¹ˆ

### ç›´è§‚ç†è§£

**K-meanså°±åƒ"æ‰¾Kä¸ªä¸­å¿ƒç‚¹"**ï¼š
1. éšæœºé€‰æ‹©Kä¸ªä¸­å¿ƒç‚¹ï¼ˆè´¨å¿ƒï¼‰
2. æŠŠæ¯ä¸ªæ•°æ®ç‚¹åˆ†é…åˆ°æœ€è¿‘çš„ä¸­å¿ƒç‚¹
3. é‡æ–°è®¡ç®—ä¸­å¿ƒç‚¹ä½ç½®
4. é‡å¤æ­¥éª¤2-3ï¼Œç›´åˆ°ä¸­å¿ƒç‚¹ä¸å†å˜åŒ–

**ç±»æ¯”**ï¼š
- å°±åƒæŠŠå­¦ç”Ÿåˆ†æˆKä¸ªç­çº§ï¼Œæ¯ä¸ªç­çº§æœ‰ä¸€ä¸ª"ç­é•¿"ï¼ˆè´¨å¿ƒï¼‰
- æ¯ä¸ªå­¦ç”Ÿé€‰æ‹©æœ€è¿‘çš„ç­é•¿
- ç­é•¿ä½ç½®ä¼šæ ¹æ®å­¦ç”Ÿä½ç½®è°ƒæ•´
- ç›´åˆ°ç­çº§ç¨³å®šä¸‹æ¥

### å¯è§†åŒ–ç†è§£

è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œä½ ä¼šçœ‹åˆ°ï¼š
- **æ•°æ®ç‚¹**ï¼šä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒçš„ç°‡
- **è´¨å¿ƒ**ï¼šçº¢è‰²Xæ ‡è®°ï¼Œæ˜¯æ¯ä¸ªç°‡çš„ä¸­å¿ƒ
- **åˆ†é…**ï¼šæ¯ä¸ªç‚¹è¢«åˆ†é…åˆ°æœ€è¿‘çš„è´¨å¿ƒ

---

## ğŸ“‹ å»ºç«‹å­¦ä¹ ç›®æ ‡

å®Œæˆå¿«é€Ÿä¸Šæ‰‹åï¼Œä½ åº”è¯¥ï¼š

### âœ… å·²ç»èƒ½åšåˆ°
- [x] ä½¿ç”¨scikit-learnè¿è¡ŒK-means
- [x] ç†è§£K-meansçš„åŸºæœ¬æ•ˆæœ
- [x] çŸ¥é“å¦‚ä½•ä¿®æ”¹å‚æ•°

### ğŸ¯ æ¥ä¸‹æ¥è¦å­¦
- [ ] **ç†è§£åŸç†**ï¼šK-meansæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ
- [ ] **ä»é›¶å®ç°**ï¼šä¸ä¾èµ–åº“ï¼Œè‡ªå·±å®ç°K-means
- [ ] **Kå€¼é€‰æ‹©**ï¼šå¦‚ä½•é€‰æ‹©æœ€ä½³çš„Kå€¼ï¼Ÿ
- [ ] **ä¼˜åŒ–æ–¹æ³•**ï¼šK-means++ã€Mini-batchç­‰æ”¹è¿›
- [ ] **å®é™…åº”ç”¨**ï¼šåœ¨çœŸå®é¡¹ç›®ä¸­å¦‚ä½•ä½¿ç”¨ï¼Ÿ

---

## ğŸ’¡ å­¦ä¹ å»ºè®®

1. **å…ˆä½“éªŒå†å­¦ä¹ **ï¼šä½ å·²ç»è¿è¡Œäº†ä»£ç ï¼Œçœ‹åˆ°äº†æ•ˆæœï¼Œç°åœ¨å­¦ä¹ åŸç†ä¼šæ›´å®¹æ˜“ç†è§£
2. **å¤šåŠ¨æ‰‹å®éªŒ**ï¼šä¿®æ”¹å‚æ•°ï¼Œè§‚å¯Ÿæ•ˆæœï¼ŒåŠ æ·±ç†è§£
3. **å¾ªåºæ¸è¿›**ï¼šå…ˆç†è§£åŸºæœ¬æ¦‚å¿µï¼Œå†æ·±å…¥ç»†èŠ‚
4. **ç†è®ºå®è·µç»“åˆ**ï¼šæ¯å­¦ä¸€ä¸ªæ¦‚å¿µï¼Œç«‹å³ç”¨ä»£ç éªŒè¯

---

## âš ï¸ å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆéœ€è¦æ ‡å‡†åŒ–æ•°æ®ï¼Ÿ**
A: K-meansåŸºäºè·ç¦»è®¡ç®—ï¼Œå¦‚æœç‰¹å¾é‡çº²ä¸åŒï¼ˆå¦‚é‡‘é¢å’Œé¢‘ç‡ï¼‰ï¼Œè·ç¦»è®¡ç®—ä¼šä¸å‡†ç¡®ã€‚

**Q: å¦‚ä½•é€‰æ‹©Kå€¼ï¼Ÿ**
A: å¯ä»¥ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™æˆ–è½®å»“ç³»æ•°ï¼Œåç»­ä¼šè¯¦ç»†å­¦ä¹ ã€‚

**Q: K-meansä¸€å®šèƒ½æ‰¾åˆ°æœ€ä½³ç»“æœå—ï¼Ÿ**
A: ä¸ä¸€å®šï¼ŒK-meanså¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå¯ä»¥ä½¿ç”¨K-means++åˆå§‹åŒ–æˆ–å¤šæ¬¡è¿è¡Œã€‚

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿç°åœ¨å¼€å§‹æ­£å¼å­¦ä¹ K-meansçš„åŸç†å’Œå®ç°ï¼** ğŸš€
