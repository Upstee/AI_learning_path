{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 文本分类详解\n",
        "\n",
        "## 📋 文档说明\n",
        "\n",
        "本文档是文本分类的详细理论讲解，比父目录的《语言理解任务详解》更加深入和详细。本文档将深入讲解文本分类的原理、数学推导和实现细节。通过本文档，你将能够：\n",
        "\n",
        "1. **深入理解文本分类的原理**：从特征提取、分类头到损失函数的完整流程\n",
        "2. **掌握文本分类的数学原理**：理解文本分类的数学定义、为什么有效、如何优化\n",
        "3. **理解文本分类的网络架构**：理解语言编码器、分类头、softmax归一化等关键组件\n",
        "4. **掌握文本分类在VLA中的应用**：理解文本分类在VLA模型中的具体应用和优势\n",
        "5. **了解文本分类的评估指标**：理解准确率、精确率、召回率、F1分数等评估指标\n",
        "\n",
        "**学习方式**：本文件是Jupyter Notebook格式，你可以边看边运行代码，通过可视化图表和数学推导更好地理解文本分类的原理和过程。\n",
        "\n",
        "**文档结构**：\n",
        "- 父目录：语言理解任务详解（见../语言理解任务详解.ipynb）\n",
        "- 本文档：文本分类详解（本文档）\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 术语表（按出现顺序）\n",
        "\n",
        "### 1. 文本分类 (Text Classification)\n",
        "- **中文名称**：文本分类\n",
        "- **英文全称**：Text Classification\n",
        "- **定义**：文本分类是指将输入文本分类到预定义的类别中的任务，是自然语言处理中最基础的任务之一。文本分类的目标是识别文本的类别或标签，输出文本的类别概率。文本分类通常使用预训练语言模型（如BERT、GPT）或传统机器学习方法（如朴素贝叶斯、SVM）作为特征提取器，然后使用全连接层或分类头输出类别概率。文本分类的损失函数通常是交叉熵损失，评估指标通常是准确率（Accuracy）、精确率（Precision）、召回率（Recall）、F1分数等。文本分类在VLA中的应用包括识别指令类型、识别场景描述、识别动作意图等，这些信息可以帮助VLA模型理解语言指令，生成相应的动作序列。文本分类是VLA语言理解的基础，通过文本分类，VLA模型能够识别指令类型（如\"拿起\"、\"放下\"、\"移动\"），识别场景描述（如\"厨房\"、\"客厅\"、\"卧室\"），识别动作意图（如\"抓取\"、\"放置\"、\"导航\"），这些信息为后续的动作生成提供了重要的上下文信息。文本分类的质量直接影响VLA模型的性能，好的文本分类能力能够帮助模型更好地理解语言指令，生成更准确的动作序列。\n",
        "- **核心组成**：文本分类的核心组成包括：1）特征提取：使用语言编码器（如BERT、GPT）从文本中提取语言特征；2）分类头：使用全连接层或线性层将特征映射到类别空间；3）损失函数：使用交叉熵损失函数训练模型；4）文本预处理：使用分词、编码等技术处理输入文本；5）评估指标：使用准确率、精确率、召回率、F1分数等指标评估模型性能；6）后处理：对模型输出进行softmax归一化，得到类别概率。文本分类通常使用预训练的语言编码器，然后在特定数据集上进行微调。文本分类的网络架构通常包括语言编码器（用于特征提取）和分类头（用于类别预测），语言编码器可以是BERT、GPT、RoBERTa等，分类头通常是全连接层或线性层，将特征映射到类别空间。\n",
        "- **在VLA中的应用**：在VLA中，文本分类用于识别指令类型、识别场景描述、识别动作意图等。例如，VLA模型可以使用文本分类识别指令是\"拿起\"、\"放下\"还是\"移动\"，识别场景描述是\"厨房\"、\"客厅\"还是\"卧室\"，识别动作意图是\"抓取\"、\"放置\"还是\"导航\"等。这些分类结果可以帮助VLA模型理解语言指令，生成相应的动作序列。在VLA训练过程中，文本分类通常是端到端训练的，即与语言编码器、多模态融合、动作生成模块一起训练，以学习最适合VLA任务的特征表示。文本分类还可以用于VLA的预训练，通过大规模文本分类任务预训练语言编码器，然后在VLA任务上进行微调。文本分类的结果可以作为VLA模型的输入特征，帮助模型理解语言指令的语义信息，从而生成更准确的动作序列。\n",
        "- **相关概念**：语言编码器、分类头、交叉熵损失、准确率、精确率、召回率、F1分数、softmax归一化\n",
        "- **首次出现位置**：本文档标题\n",
        "- **深入学习**：参考父目录的[语言理解任务详解](../语言理解任务详解.ipynb)和[语言编码器详解](../../02_语言编码器/理论笔记/语言编码器详解.ipynb)\n",
        "- **直观理解**：想象文本分类就像给文本贴标签，识别文本的类别或意图。例如，看到\"拿起桌子上的杯子\"这个指令，文本分类模型会输出\"抓取\"这个类别标签；看到\"把杯子放在架子上\"这个指令，文本分类模型会输出\"放置\"这个类别标签。在VLA中，文本分类帮助模型理解语言指令的基本信息，从而生成相应的动作。文本分类就像让模型回答\"这是什么类型的指令\"的问题，通过识别文本的类别或意图，为后续的动作生成提供重要的上下文信息。\n",
        "\n",
        "### 2. 分类头 (Classification Head)\n",
        "- **中文名称**：分类头\n",
        "- **英文全称**：Classification Head\n",
        "- **定义**：分类头是指将语言特征映射到类别空间的网络层，通常是全连接层或线性层。分类头的作用是将语言编码器提取的特征向量映射到类别数量的维度，然后通过softmax归一化得到类别概率。分类头的设计直接影响文本分类的性能，好的分类头能够有效地将特征映射到类别空间，提高分类准确率。分类头通常包括：1）全连接层或线性层：将特征维度映射到类别数量；2）可选的dropout层：防止过拟合；3）可选的批归一化层：加速训练，提高稳定性；4）softmax归一化：将输出转换为概率分布。分类头是文本分类网络的关键组件，它将语言编码器提取的丰富特征表示转换为类别预测，是文本分类任务的核心。\n",
        "- **核心组成**：分类头的核心组成包括：1）线性变换：使用全连接层或线性层将特征维度映射到类别数量，数学表示为 $y = Wx + b$，其中 $W$ 是权重矩阵，$b$ 是偏置向量，$x$ 是输入特征，$y$ 是输出logits；2）可选的dropout层：在训练时随机丢弃部分神经元，防止过拟合；3）可选的批归一化层：对特征进行归一化，加速训练，提高稳定性；4）softmax归一化：将logits转换为概率分布，数学表示为 $P(y_i|x) = \\frac{\\exp(y_i)}{\\sum_{j=1}^{C} \\exp(y_j)}$，其中 $C$ 是类别数量。分类头的设计需要考虑特征维度、类别数量、计算效率等因素，通常使用全连接层作为分类头，但在某些情况下也可以使用其他结构。\n",
        "- **在VLA中的应用**：在VLA中，分类头用于将语言特征映射到类别空间，识别指令类型、识别场景描述、识别动作意图等。例如，VLA模型可以使用分类头识别指令是\"拿起\"、\"放下\"还是\"移动\"，识别场景描述是\"厨房\"、\"客厅\"还是\"卧室\"，识别动作意图是\"抓取\"、\"放置\"还是\"导航\"等。这些分类结果可以帮助VLA模型理解语言指令，生成相应的动作序列。在VLA训练过程中，分类头通常是端到端训练的，即与语言编码器、多模态融合、动作生成模块一起训练，以学习最适合VLA任务的特征表示。分类头的输出可以作为VLA模型的输入特征，帮助模型理解语言指令的语义信息，从而生成更准确的动作序列。\n",
        "- **相关概念**：全连接层、线性层、softmax归一化、dropout、批归一化、类别概率\n",
        "- **首次出现位置**：本文档第1.2节\n",
        "- **深入学习**：参考本文档的分类头详细讲解部分\n",
        "- **直观理解**：想象分类头就像一位\"翻译官\"，它能够将语言编码器提取的\"语言特征\"（特征向量）\"翻译\"成\"类别语言\"（类别概率）。例如，语言编码器提取的特征向量可能包含\"这是一个抓取指令\"、\"目标是杯子\"、\"位置在桌子上\"等信息，分类头将这些信息\"翻译\"成\"抓取\"这个类别标签。在VLA中，分类头帮助模型理解语言指令的语义信息，从而生成相应的动作。\n",
        "\n",
        "### 3. 交叉熵损失 (Cross-Entropy Loss)\n",
        "- **中文名称**：交叉熵损失\n",
        "- **英文全称**：Cross-Entropy Loss\n",
        "- **定义**：交叉熵损失是文本分类任务中最常用的损失函数，用于衡量模型预测的类别概率分布与真实标签之间的差异。交叉熵损失的数学表示为：$\\mathcal{L} = -\\sum_{i=1}^{C} y_i \\log(P(y_i|x))$，其中 $C$ 是类别数量，$y_i$ 是真实标签的one-hot编码，$P(y_i|x)$ 是模型预测的类别概率。交叉熵损失的优势在于：1）概率解释：损失函数与概率分布相关，具有明确的概率解释；2）梯度友好：损失函数的梯度计算简单，易于优化；3）类别平衡：能够处理类别不平衡的问题；4）可扩展性：适用于多类别分类任务。交叉熵损失是文本分类任务的核心损失函数，它通过最小化预测概率分布与真实标签之间的差异，使模型学习正确的类别预测。\n",
        "- **核心组成**：交叉熵损失的核心组成包括：1）真实标签编码：将真实标签编码为one-hot向量，例如类别3编码为 $[0, 0, 1, 0, \\ldots]$；2）预测概率计算：使用softmax将模型输出的logits转换为概率分布，数学表示为 $P(y_i|x) = \\frac{\\exp(y_i)}{\\sum_{j=1}^{C} \\exp(y_j)}$；3）交叉熵计算：计算真实标签与预测概率之间的交叉熵，数学表示为 $\\mathcal{L} = -\\sum_{i=1}^{C} y_i \\log(P(y_i|x))$；4）损失聚合：对所有样本的损失进行平均，得到总损失。交叉熵损失通过最小化预测概率分布与真实标签之间的差异，使模型学习正确的类别预测。交叉熵损失的梯度计算简单，易于优化，这使得它成为文本分类任务的首选损失函数。\n",
        "- **在VLA中的应用**：在VLA中，交叉熵损失用于训练文本分类模型，识别指令类型、识别场景描述、识别动作意图等。例如，VLA模型可以使用交叉熵损失训练分类模型，识别指令是\"拿起\"、\"放下\"还是\"移动\"，识别场景描述是\"厨房\"、\"客厅\"还是\"卧室\"，识别动作意图是\"抓取\"、\"放置\"还是\"导航\"等。这些分类结果可以帮助VLA模型理解语言指令，生成相应的动作序列。在VLA训练过程中，交叉熵损失通常是端到端训练的，即与语言编码器、多模态融合、动作生成模块一起训练，以学习最适合VLA任务的特征表示。交叉熵损失的优化使得模型能够学习正确的类别预测，提高文本分类的准确率，从而为VLA模型提供更准确的语言指令理解。\n",
        "- **相关概念**：softmax归一化、one-hot编码、概率分布、梯度下降、类别概率\n",
        "- **首次出现位置**：本文档第2.1节\n",
        "- **深入学习**：参考本文档的交叉熵损失详细讲解部分\n",
        "- **直观理解**：想象交叉熵损失就像让模型学习\"猜谜游戏\"，模型需要猜测文本的类别，交叉熵损失衡量猜测的准确性。如果模型猜测正确（预测概率高），损失值小；如果模型猜测错误（预测概率低），损失值大。通过最小化交叉熵损失，模型学会了如何正确猜测文本的类别。在VLA中，交叉熵损失帮助模型学习正确的类别预测，从而为动作生成提供准确的语言指令理解。\n",
        "\n",
        "### 4. 精确率 (Precision)\n",
        "- **中文名称**：精确率\n",
        "- **英文全称**：Precision\n",
        "- **定义**：精确率是指模型预测为正类的样本中，真正为正类的样本所占的比例，用于衡量模型预测的准确性。精确率的数学表示为：$\\text{Precision} = \\frac{TP}{TP + FP}$，其中 $TP$ 是真正例（True Positive），$FP$ 是假正例（False Positive）。精确率越高，说明模型预测为正类的样本中，真正为正类的样本越多，模型的预测越准确。精确率是文本分类任务的重要评估指标，它帮助评估模型在特定类别上的预测准确性。在多类别分类任务中，精确率通常按类别计算，然后取平均（宏平均）或加权平均（微平均）。精确率与召回率（Recall）一起使用，可以全面评估模型的性能，精确率高但召回率低说明模型预测保守，精确率低但召回率高说明模型预测激进。\n",
        "- **核心组成**：精确率的核心组成包括：1）真正例（TP）：模型预测为正类且实际为正类的样本数量；2）假正例（FP）：模型预测为正类但实际为负类的样本数量；3）精确率计算：计算真正例与所有预测为正类的样本数量的比值，数学表示为 $\\text{Precision} = \\frac{TP}{TP + FP}$；4）多类别精确率：在多类别分类任务中，按类别计算精确率，然后取平均或加权平均。精确率通过衡量模型预测为正类的样本中真正为正类的比例，评估模型预测的准确性。精确率越高，说明模型预测越准确，但精确率单独使用可能无法全面评估模型性能，需要与召回率、F1分数等指标一起使用。\n",
        "- **在VLA中的应用**：在VLA中，精确率用于评估文本分类模型的性能，识别指令类型、识别场景描述、识别动作意图等。例如，VLA模型可以使用精确率评估分类模型在识别\"抓取\"指令时的准确性，如果精确率高，说明模型预测为\"抓取\"的指令中，真正是\"抓取\"指令的比例高，模型的预测准确。精确率帮助VLA模型评估文本分类的质量，从而为动作生成提供准确的语言指令理解。在VLA训练过程中，精确率通常与召回率、F1分数一起使用，全面评估模型性能，优化模型参数，提高文本分类的准确率。\n",
        "- **相关概念**：召回率、F1分数、混淆矩阵、真正例、假正例、假负例\n",
        "- **首次出现位置**：本文档第3.1节\n",
        "- **深入学习**：参考本文档的评估指标详细讲解部分\n",
        "- **直观理解**：想象精确率就像让模型回答\"我预测为正类的样本中，有多少是真正为正类的\"的问题。例如，如果模型预测100个样本为\"抓取\"指令，其中90个真正是\"抓取\"指令，那么精确率就是90%。精确率越高，说明模型预测越准确，但精确率单独使用可能无法全面评估模型性能，需要与召回率、F1分数等指标一起使用。\n",
        "\n",
        "### 5. 召回率 (Recall)\n",
        "- **中文名称**：召回率\n",
        "- **英文全称**：Recall\n",
        "- **定义**：召回率是指实际为正类的样本中，模型预测为正类的样本所占的比例，用于衡量模型预测的完整性。召回率的数学表示为：$\\text{Recall} = \\frac{TP}{TP + FN}$，其中 $TP$ 是真正例（True Positive），$FN$ 是假负例（False Negative）。召回率越高，说明实际为正类的样本中，模型预测为正类的样本越多，模型的预测越完整。召回率是文本分类任务的重要评估指标，它帮助评估模型在特定类别上的预测完整性。在多类别分类任务中，召回率通常按类别计算，然后取平均（宏平均）或加权平均（微平均）。召回率与精确率（Precision）一起使用，可以全面评估模型的性能，召回率高但精确率低说明模型预测激进，召回率低但精确率高说明模型预测保守。\n",
        "- **核心组成**：召回率的核心组成包括：1）真正例（TP）：模型预测为正类且实际为正类的样本数量；2）假负例（FN）：模型预测为负类但实际为正类的样本数量；3）召回率计算：计算真正例与所有实际为正类的样本数量的比值，数学表示为 $\\text{Recall} = \\frac{TP}{TP + FN}$；4）多类别召回率：在多类别分类任务中，按类别计算召回率，然后取平均或加权平均。召回率通过衡量实际为正类的样本中模型预测为正类的比例，评估模型预测的完整性。召回率越高，说明模型预测越完整，但召回率单独使用可能无法全面评估模型性能，需要与精确率、F1分数等指标一起使用。\n",
        "- **在VLA中的应用**：在VLA中，召回率用于评估文本分类模型的性能，识别指令类型、识别场景描述、识别动作意图等。例如，VLA模型可以使用召回率评估分类模型在识别\"抓取\"指令时的完整性，如果召回率高，说明实际为\"抓取\"指令的样本中，模型预测为\"抓取\"指令的比例高，模型的预测完整。召回率帮助VLA模型评估文本分类的质量，从而为动作生成提供准确的语言指令理解。在VLA训练过程中，召回率通常与精确率、F1分数一起使用，全面评估模型性能，优化模型参数，提高文本分类的准确率。\n",
        "- **相关概念**：精确率、F1分数、混淆矩阵、真正例、假正例、假负例\n",
        "- **首次出现位置**：本文档第3.2节\n",
        "- **深入学习**：参考本文档的评估指标详细讲解部分\n",
        "- **直观理解**：想象召回率就像让模型回答\"实际为正类的样本中，有多少被我预测为正类\"的问题。例如，如果实际有100个\"抓取\"指令，模型预测了90个为\"抓取\"指令，那么召回率就是90%。召回率越高，说明模型预测越完整，但召回率单独使用可能无法全面评估模型性能，需要与精确率、F1分数等指标一起使用。\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 概述\n",
        "\n",
        "### 什么是文本分类\n",
        "\n",
        "文本分类是指将输入文本分类到预定义的类别中的任务，是自然语言处理中最基础的任务之一。文本分类的目标是识别文本的类别或标签，输出文本的类别概率。\n",
        "\n",
        "### 为什么重要\n",
        "\n",
        "文本分类对于VLA学习非常重要，原因包括：\n",
        "\n",
        "1. **语言理解的基础**：文本分类是VLA语言理解的基础，帮助模型理解语言指令\n",
        "2. **指令类型识别**：能够识别指令类型，为动作生成提供上下文信息\n",
        "3. **场景描述识别**：能够识别场景描述，为动作生成提供环境信息\n",
        "4. **预训练方法**：文本分类可以用于VLA的预训练，提高特征提取质量\n",
        "\n",
        "### 学习目标\n",
        "\n",
        "通过本文档的学习，你将能够：\n",
        "\n",
        "1. **深入理解文本分类**：理解文本分类的原理和方法\n",
        "2. **掌握交叉熵损失**：理解交叉熵损失的数学定义和计算方法\n",
        "3. **理解分类头的设计**：理解分类头的架构和实现\n",
        "4. **掌握文本分类在VLA中的应用**：理解文本分类在VLA模型中的具体应用\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 导入必要的库\n",
        "# ============================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'Microsoft YaHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 文本分类的基本原理\n",
        "\n",
        "### 1.1 什么是文本分类\n",
        "\n",
        "**直观理解**：想象文本分类就像给文本贴标签，识别文本的类别或意图。\n",
        "\n",
        "**定义**：文本分类是指将输入文本分类到预定义的类别中的任务，是自然语言处理中最基础的任务之一。\n",
        "\n",
        "### 1.2 文本分类的网络架构\n",
        "\n",
        "文本分类的网络架构通常包括：\n",
        "\n",
        "1. **语言编码器**：使用BERT、GPT等提取语言特征\n",
        "2. **分类头**：使用全连接层或线性层将特征映射到类别空间\n",
        "3. **softmax归一化**：将输出转换为概率分布\n",
        "\n",
        "### 1.3 文本分类的数学表示\n",
        "\n",
        "文本分类的数学表示为：\n",
        "\n",
        "$$P(y|x) = \\text{softmax}(\\text{Classifier}(\\text{Encoder}(x)))$$\n",
        "\n",
        "其中：\n",
        "- $x$ 是输入文本\n",
        "- $\\text{Encoder}(x)$ 是语言编码器提取的特征\n",
        "- $\\text{Classifier}(\\cdot)$ 是分类头\n",
        "- $P(y|x)$ 是类别概率分布\n",
        "\n",
        "### 1.4 文本分类的可视化\n",
        "\n",
        "下面我们通过代码可视化文本分类的过程：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 文本分类可视化（示例：指令类型分类）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA指令类型分类\n",
        "instructions = [\n",
        "    \"拿起桌子上的杯子\",\n",
        "    \"把杯子放在架子上\",\n",
        "    \"移动到厨房\",\n",
        "    \"打开抽屉\",\n",
        "    \"关闭门\",\n",
        "]\n",
        "\n",
        "# 类别：抓取、放置、导航、操作\n",
        "categories = ['抓取', '放置', '导航', '操作']\n",
        "num_categories = len(categories)\n",
        "\n",
        "# 模拟语言编码器提取的特征（简化版）\n",
        "d_model = 768\n",
        "text_features = np.random.randn(len(instructions), d_model)\n",
        "\n",
        "# 模拟分类头的输出logits\n",
        "np.random.seed(42)\n",
        "classifier = nn.Linear(d_model, num_categories)\n",
        "with torch.no_grad():\n",
        "    logits = classifier(torch.tensor(text_features, dtype=torch.float32))\n",
        "    probs = F.softmax(logits, dim=1).numpy()\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (instruction, prob) in enumerate(zip(instructions, probs)):\n",
        "    if idx < len(axes):\n",
        "        ax = axes[idx]\n",
        "        predicted_class = np.argmax(prob)\n",
        "        colors = ['red' if i == predicted_class else 'steelblue' for i in range(num_categories)]\n",
        "        bars = ax.bar(range(num_categories), prob, color=colors, \n",
        "                     edgecolor='black', linewidth=2, alpha=0.7)\n",
        "        ax.set_title(f'指令: {instruction}\\n预测类别: {categories[predicted_class]}', \n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('类别')\n",
        "        ax.set_ylabel('概率')\n",
        "        ax.set_xticks(range(num_categories))\n",
        "        ax.set_xticklabels(categories, rotation=45, ha='right')\n",
        "        ax.set_ylim(0, 1.1)\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # 标注概率值\n",
        "        for i, (bar, p) in enumerate(zip(bars, prob)):\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                   f'{p:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "# 隐藏最后一个子图\n",
        "axes[-1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('文本分类可视化：VLA指令类型分类', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"文本分类可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 每个子图显示一个指令的分类结果\")\n",
        "print(\"2. 红色柱表示预测类别，蓝色柱表示其他类别\")\n",
        "print(\"3. 文本分类的目标是最大化正确类别的概率\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 交叉熵损失可视化（不同预测概率的影响）\n",
        "# ============================================\n",
        "\n",
        "# 真实标签：类别1（抓取）\n",
        "true_label = 1\n",
        "num_classes = 4\n",
        "categories = ['抓取', '放置', '导航', '操作']\n",
        "\n",
        "# 不同的预测概率分布\n",
        "pred_probs_list = [\n",
        "    [0.1, 0.7, 0.15, 0.05],  # 预测较准确\n",
        "    [0.25, 0.35, 0.25, 0.15],  # 预测不确定\n",
        "    [0.6, 0.2, 0.15, 0.05],  # 预测错误\n",
        "    [0.05, 0.9, 0.03, 0.02]  # 预测非常准确\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, pred_probs in enumerate(pred_probs_list):\n",
        "    ax = axes[idx]\n",
        "    \n",
        "    # 计算交叉熵损失\n",
        "    loss = -np.log(pred_probs[true_label] + 1e-8)\n",
        "    \n",
        "    # 可视化\n",
        "    colors = ['red' if i == true_label else 'steelblue' for i in range(num_classes)]\n",
        "    bars = ax.bar(range(num_classes), pred_probs, color=colors, \n",
        "                 edgecolor='black', linewidth=2, alpha=0.7)\n",
        "    ax.set_title(f'预测概率分布\\n交叉熵损失: {loss:.3f}', \n",
        "                fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel('类别')\n",
        "    ax.set_ylabel('概率')\n",
        "    ax.set_xticks(range(num_classes))\n",
        "    ax.set_xticklabels(categories, rotation=45, ha='right')\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # 标注概率值\n",
        "    for i, (bar, prob) in enumerate(zip(bars, pred_probs)):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "               f'{prob:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "    \n",
        "    # 标记真实标签\n",
        "    ax.axvline(true_label, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"交叉熵损失可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 红色柱表示真实标签对应的类别，蓝色柱表示其他类别\")\n",
        "print(\"2. 交叉熵损失越小，说明预测概率与真实标签越接近\")\n",
        "print(\"3. 当预测概率接近1时，损失值接近0；当预测概率接近0时，损失值很大\")\n",
        "print(\"4. 交叉熵损失鼓励模型对正确类别给出高概率，对错误类别给出低概率\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. 评估指标详解\n",
        "\n",
        "### 3.1 精确率 (Precision)\n",
        "\n",
        "精确率是指模型预测为正类的样本中，真正为正类的样本所占的比例：\n",
        "\n",
        "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "### 3.2 召回率 (Recall)\n",
        "\n",
        "召回率是指实际为正类的样本中，模型预测为正类的样本所占的比例：\n",
        "\n",
        "$$\\text{Recall} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "### 3.3 F1分数 (F1 Score)\n",
        "\n",
        "F1分数是精确率和召回率的调和平均：\n",
        "\n",
        "$$\\text{F1} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
        "\n",
        "### 3.4 评估指标的可视化\n",
        "\n",
        "下面我们通过代码可视化评估指标：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 评估指标可视化（混淆矩阵和性能指标）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 模拟文本分类的预测结果\n",
        "categories = ['抓取', '放置', '导航', '操作']\n",
        "num_classes = len(categories)\n",
        "\n",
        "# 模拟真实标签和预测标签\n",
        "y_true = np.random.randint(0, num_classes, size=100)\n",
        "y_pred = y_true.copy()\n",
        "\n",
        "# 添加一些错误预测（模拟模型不完美）\n",
        "error_rate = 0.15\n",
        "num_errors = int(len(y_true) * error_rate)\n",
        "error_indices = np.random.choice(len(y_true), num_errors, replace=False)\n",
        "y_pred[error_indices] = np.random.randint(0, num_classes, size=num_errors)\n",
        "\n",
        "# 计算混淆矩阵\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# 计算评估指标\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "precision = precision_score(y_true, y_pred, average=None)\n",
        "recall = recall_score(y_true, y_pred, average=None)\n",
        "f1 = f1_score(y_true, y_pred, average=None)\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 左图：混淆矩阵\n",
        "ax1 = axes[0]\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
        "            xticklabels=categories, yticklabels=categories)\n",
        "ax1.set_title('混淆矩阵', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('预测类别')\n",
        "ax1.set_ylabel('真实类别')\n",
        "\n",
        "# 右图：性能指标\n",
        "ax2 = axes[1]\n",
        "x_pos = np.arange(len(categories))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax2.bar(x_pos - width, precision, width, label='精确率', \n",
        "               color='steelblue', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "bars2 = ax2.bar(x_pos, recall, width, label='召回率', \n",
        "               color='lightcoral', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "bars3 = ax2.bar(x_pos + width, f1, width, label='F1分数', \n",
        "               color='lightgreen', alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "ax2.set_title(f'性能指标（准确率: {accuracy:.3f}）', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('类别')\n",
        "ax2.set_ylabel('分数')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(categories, rotation=45, ha='right')\n",
        "ax2.set_ylim(0, 1.1)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.legend()\n",
        "\n",
        "# 添加数值标注\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "                f'{height:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"评估指标可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左图：混淆矩阵显示真实标签和预测标签的对应关系\")\n",
        "print(\"2. 右图：性能指标显示每个类别的精确率、召回率和F1分数\")\n",
        "print(\"3. 准确率显示整体分类准确率\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. 文本分类在VLA中的应用\n",
        "\n",
        "### 4.1 指令类型识别\n",
        "\n",
        "在VLA中，文本分类用于识别指令类型，例如：\n",
        "- **抓取指令**：识别\"拿起\"、\"抓取\"等指令，帮助模型理解动作类型\n",
        "- **放置指令**：识别\"放下\"、\"放置\"等指令，帮助模型理解动作类型\n",
        "- **导航指令**：识别\"移动到\"、\"前往\"等指令，帮助模型理解动作类型\n",
        "- **操作指令**：识别\"打开\"、\"关闭\"等指令，帮助模型理解动作类型\n",
        "\n",
        "### 4.2 场景描述识别\n",
        "\n",
        "在VLA中，文本分类用于识别场景描述，例如：\n",
        "- **厨房场景**：识别\"厨房\"，帮助模型理解场景上下文\n",
        "- **客厅场景**：识别\"客厅\"，帮助模型理解场景布局\n",
        "- **卧室场景**：识别\"卧室\"，帮助模型理解场景功能\n",
        "\n",
        "### 4.3 动作意图识别\n",
        "\n",
        "在VLA中，文本分类用于识别动作意图，例如：\n",
        "- **抓取意图**：识别\"抓取\"意图，帮助模型理解动作目标\n",
        "- **放置意图**：识别\"放置\"意图，帮助模型理解动作目标\n",
        "- **导航意图**：识别\"导航\"意图，帮助模型理解动作目标\n",
        "\n",
        "### 4.4 预训练方法\n",
        "\n",
        "文本分类可以用于VLA的预训练，通过大规模文本分类任务预训练语言编码器，然后在VLA任务上进行微调。\n",
        "\n",
        "---\n",
        "\n",
        "## 5. 总结\n",
        "\n",
        "### 5.1 文本分类的核心思想\n",
        "\n",
        "文本分类的核心思想包括：\n",
        "\n",
        "1. **特征提取**：使用语言编码器从文本中提取语言特征\n",
        "2. **类别映射**：使用分类头将特征映射到类别空间\n",
        "3. **概率预测**：使用softmax归一化得到类别概率\n",
        "4. **损失优化**：使用交叉熵损失优化模型参数\n",
        "\n",
        "### 5.2 文本分类的优势\n",
        "\n",
        "文本分类的优势包括：\n",
        "\n",
        "1. **语言理解的基础**：文本分类是VLA语言理解的基础，帮助模型理解语言指令\n",
        "2. **指令类型识别**：能够识别指令类型，为动作生成提供上下文信息\n",
        "3. **场景描述识别**：能够识别场景描述，为动作生成提供环境信息\n",
        "4. **预训练方法**：文本分类可以用于VLA的预训练，提高特征提取质量\n",
        "\n",
        "### 5.3 文本分类在VLA中的重要性\n",
        "\n",
        "文本分类在VLA中的重要性体现在：\n",
        "\n",
        "1. **指令理解**：文本分类是VLA指令理解的重要方法，能够帮助模型理解语言指令的类型和意图\n",
        "2. **特征提取**：文本分类能够从输入文本中提取语言特征，这些特征能够理解语言指令的语义信息\n",
        "3. **预训练优势**：文本分类的预训练权重能够提供通用的语言表示，减少VLA任务的训练数据需求\n",
        "4. **应用优势**：文本分类的结果可以作为VLA模型的输入特征，帮助模型理解语言指令的语义信息，从而生成更准确的动作序列\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 文档信息\n",
        "\n",
        "- **创建时间**：2024年\n",
        "- **文档版本**：v1.0\n",
        "- **维护者**：VLA学习团队\n",
        "- **相关文档**：\n",
        "  - [语言理解任务详解](../语言理解任务详解.ipynb)\n",
        "  - [语言编码器详解](../../02_语言编码器/理论笔记/语言编码器详解.ipynb)\n",
        "  - [BERT详解](../../02_语言编码器/01_BERT/理论笔记/BERT详解.ipynb)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
