{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 分类方法详解\n",
        "\n",
        "## 📋 文档说明\n",
        "\n",
        "本文档是分类方法的详细理论讲解，比父目录的《动作执行基础详解》更加深入和详细。本文档将深入讲解分类方法的原理、数学推导和实现细节。通过本文档，你将能够：\n",
        "\n",
        "1. **深入理解分类方法的原理**：从多模态特征到动作概率的完整流程\n",
        "2. **掌握分类方法的数学原理**：理解Softmax函数、交叉熵损失的数学定义、为什么有效、如何实现\n",
        "3. **理解分类网络架构**：理解如何使用神经网络实现分类预测\n",
        "4. **掌握损失函数优化**：理解如何使用梯度下降优化分类模型\n",
        "5. **掌握分类方法在VLA中的应用**：理解分类方法在VLA模型中的具体应用和优势\n",
        "\n",
        "**学习方式**：本文件是Jupyter Notebook格式，你可以边看边运行代码，通过可视化图表和数学推导更好地理解分类方法的原理和过程。\n",
        "\n",
        "**文档结构**：\n",
        "- 父目录：动作执行基础详解（见../../理论笔记/动作执行基础详解.ipynb）\n",
        "- 本文档：分类方法详解（本文档）\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 术语表（按出现顺序）\n",
        "\n",
        "### 1. 分类方法 (Classification Method)\n",
        "- **中文名称**：分类方法\n",
        "- **英文全称**：Classification Method\n",
        "- **定义**：分类方法是指使用分类模型预测离散动作类别的方法，是离散动作空间中最常用的预测方法。在分类方法中，模型将多模态特征映射到动作概率分布，然后选择概率最高的动作作为预测结果。分类方法的优势在于：1）简单高效：分类方法实现简单，计算效率高；2）概率解释：输出是概率分布，具有明确的概率解释；3）训练稳定：分类方法的训练相对稳定，收敛速度快；4）适合离散动作：适合离散动作空间的预测任务。分类方法的数学表示为：$P(a|s) = \\text{softmax}(W \\cdot s + b)$，其中$s$是多模态特征，$W$是权重矩阵，$b$是偏置向量，$P(a|s)$是动作概率分布。分类方法在VLA中的应用包括预测离散动作空间中的动作类别，这些动作将被用于动作执行。分类方法是VLA动作预测的重要方法，通过分类方法，VLA模型能够从多模态特征中预测应该执行的动作类别，从而完成指定的任务。分类方法的质量直接影响VLA模型的性能，好的分类方法能够帮助模型更准确地预测动作，提高任务完成率。在VLA训练过程中，分类方法通常与交叉熵损失函数一起使用，通过梯度下降优化模型参数，学习最适合VLA任务的动作预测方法。\n",
        "- **核心组成**：分类方法的核心组成包括：1）特征输入：接收多模态特征作为输入；2）分类网络：使用分类网络（如全连接网络）将特征映射到动作概率分布；3）Softmax函数：使用Softmax函数将logits转换为概率分布；4）动作选择：选择概率最高的动作作为预测结果；5）损失计算：使用交叉熵损失函数计算预测误差；6）模型优化：使用梯度下降优化模型参数。分类方法通常使用全连接网络实现，这些网络能够从多模态特征中学习动作模式，预测动作类别。分类方法的设计需要考虑任务特点，选择合适的网络架构和损失函数，以平衡预测准确性和计算复杂度。\n",
        "- **在VLA中的应用**：在VLA中，分类方法用于预测离散动作空间中的动作类别。例如，对于导航任务的离散动作空间（前进、后退、左转、右转、停止），VLA模型使用分类方法预测应该执行的动作类别，然后执行相应的动作。分类方法的优势在于实现简单、计算效率高，适合大规模VLA任务。在VLA训练过程中，分类方法通常与交叉熵损失函数一起使用，通过梯度下降优化模型参数。分类方法的结果可以作为VLA模型的输出，帮助模型预测动作类别，从而执行相应的动作。\n",
        "- **相关概念**：离散动作空间、Softmax函数、交叉熵损失、动作概率分布、分类网络\n",
        "- **首次出现位置**：本文档标题\n",
        "- **深入学习**：参考父目录的[动作执行基础详解](../../理论笔记/动作执行基础详解.ipynb)和[离散动作空间详解](../../01_动作表示/01_离散动作空间/理论笔记/离散动作空间详解.ipynb)\n",
        "- **直观理解**：想象分类方法就像让模型做选择题，给定一个问题（多模态特征），模型需要从多个选项（动作类别）中选择一个正确答案。例如，给定\"看到前方有障碍物\"和\"听到向左转\"的指令，模型需要从\"前进\"、\"后退\"、\"左转\"、\"右转\"、\"停止\"中选择\"左转\"。在VLA中，分类方法帮助模型从多个动作选项中选择正确的动作，从而完成任务。分类方法就像让模型做选择题，帮助模型选择正确的动作。\n",
        "\n",
        "### 2. Softmax函数 (Softmax Function)\n",
        "- **中文名称**：Softmax函数\n",
        "- **英文全称**：Softmax Function\n",
        "- **定义**：Softmax函数是指将一组数值转换为概率分布的函数，是分类方法中的核心函数。在Softmax函数中，输入是一组logits（未归一化的分数），输出是概率分布，所有值的和为1。Softmax函数的数学表示为：$\\text{softmax}(z)_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^{n} \\exp(z_j)}$，其中$z$是logits向量，$n$是类别数量。Softmax函数的优势在于：1）概率分布：输出是概率分布，所有值的和为1；2）非负性：所有值都是非负的；3）可微性：Softmax是可微的，便于梯度下降；4）放大差异：指数函数会放大logits之间的差异，使得概率分布更加集中。Softmax函数在VLA中的应用包括将分类网络的输出转换为动作概率分布，这些概率分布将被用于动作选择和损失计算。Softmax函数是分类方法的核心，通过Softmax函数，VLA模型能够将分类网络的输出转换为概率分布，从而进行动作预测和损失计算。Softmax函数的性质直接影响分类方法的性能，好的Softmax函数能够帮助模型更准确地预测动作，提高任务完成率。\n",
        "- **核心组成**：Softmax函数的核心组成包括：1）指数函数：使用指数函数$\\exp(x)$将logits转换为非负值；2）归一化：将所有指数值归一化，使得所有值的和为1；3）概率分布：输出是概率分布，每个值表示对应类别的概率；4）梯度计算：计算Softmax的梯度，用于反向传播。Softmax函数通常使用数值稳定的实现方法，如减去最大值后再计算指数，以避免数值溢出。Softmax函数的设计需要考虑数值稳定性，选择合适的实现方法，以平衡计算效率和数值精度。\n",
        "- **在VLA中的应用**：在VLA中，Softmax函数用于将分类网络的输出转换为动作概率分布。例如，对于导航任务的离散动作空间，分类网络输出5个logits值，Softmax函数将这些值转换为5个概率值，表示每个动作的概率。Softmax函数的优势在于能够将分类网络的输出转换为概率分布，这对于动作预测和损失计算非常重要。在VLA训练过程中，Softmax函数通常与分类网络一起使用，通过端到端训练学习最适合任务的特征表示。Softmax函数的结果可以作为VLA模型的输出，帮助模型预测动作概率，从而选择和执行动作。\n",
        "- **相关概念**：分类方法、交叉熵损失、动作概率分布、指数函数、归一化\n",
        "- **首次出现位置**：本文档第2.1节\n",
        "- **深入学习**：参考本文档的Softmax函数详细讲解部分\n",
        "- **直观理解**：想象Softmax函数就像将一组分数转换为百分比，所有百分比的和为100%。例如，如果5个动作的分数是[2.5, 0.3, -0.8, 0.1, 1.2]，Softmax函数会将这些分数转换为概率[0.662, 0.073, 0.024, 0.060, 0.180]，表示每个动作的概率。在VLA中，Softmax函数帮助模型将分类网络的输出转换为概率分布，从而进行动作预测。Softmax函数就像将分数转换为百分比，帮助模型理解动作的概率。\n",
        "\n",
        "### 3. 交叉熵损失 (Cross-Entropy Loss)\n",
        "- **中文名称**：交叉熵损失\n",
        "- **英文全称**：Cross-Entropy Loss\n",
        "- **定义**：交叉熵损失是分类任务中最常用的损失函数，用于衡量预测概率分布和真实标签之间的差异。交叉熵损失的数学表示为：$\\mathcal{L}_{CE} = -\\sum_{i=1}^{|\\mathcal{A}|} y_i \\log(P(a_i|s))$，其中$y$是真实标签的one-hot编码，$P(a_i|s)$是模型预测的动作概率。交叉熵损失的优势在于：1）概率解释：损失函数与概率分布相关，具有明确的概率解释；2）梯度友好：损失函数的梯度计算简单，易于优化；3）类别平衡：能够处理类别不平衡的问题；4）可扩展性：适用于多类别分类任务。交叉熵损失是分类方法的核心损失函数，它通过最小化预测概率分布与真实标签之间的差异，使模型学习正确的动作预测。交叉熵损失的质量直接影响分类方法的性能，好的交叉熵损失能够帮助模型更准确地预测动作，提高任务完成率。在VLA训练过程中，交叉熵损失通常与分类方法一起使用，通过梯度下降优化模型参数，学习最适合VLA任务的动作预测方法。\n",
        "- **核心组成**：交叉熵损失的核心组成包括：1）真实标签编码：将真实标签编码为one-hot向量，例如动作类别3编码为$[0, 0, 1, 0, \\ldots]$；2）预测概率计算：使用Softmax将模型输出的logits转换为概率分布；3）交叉熵计算：计算真实标签与预测概率之间的交叉熵；4）损失聚合：对所有样本的损失进行平均，得到总损失。交叉熵损失通过最小化预测概率分布与真实标签之间的差异，使模型学习正确的动作预测。交叉熵损失的梯度计算简单，易于优化，这使得它成为分类方法的首选损失函数。\n",
        "- **在VLA中的应用**：在VLA中，交叉熵损失用于训练分类模型，预测离散动作空间中的动作类别。例如，对于导航任务的离散动作空间，VLA模型使用交叉熵损失训练分类模型，预测应该执行的动作类别（前进、后退、左转、右转、停止）。交叉熵损失的优势在于能够精确衡量预测误差，有助于模型学习正确的动作预测。在VLA训练过程中，交叉熵损失通常与分类方法一起使用，通过梯度下降优化模型参数。交叉熵损失的结果可以作为VLA模型的训练目标，帮助模型学习正确的动作预测。\n",
        "- **相关概念**：分类方法、Softmax函数、动作概率分布、one-hot编码、梯度下降\n",
        "- **首次出现位置**：本文档第3.1节\n",
        "- **深入学习**：参考本文档的交叉熵损失详细讲解部分\n",
        "- **直观理解**：想象交叉熵损失就像让模型学习\"猜谜游戏\"，模型需要猜测动作类别，交叉熵损失衡量猜测的准确性。如果模型猜测正确（预测概率高），损失值小；如果模型猜测错误（预测概率低），损失值大。通过最小化交叉熵损失，模型学会了如何正确猜测动作类别。在VLA中，交叉熵损失帮助模型学习正确的动作预测，从而完成任务。交叉熵损失就像让模型学习\"猜谜游戏\"，帮助模型学习正确的动作预测。\n",
        "\n",
        "### 4. 动作概率分布 (Action Probability Distribution)\n",
        "- **中文名称**：动作概率分布\n",
        "- **英文全称**：Action Probability Distribution\n",
        "- **定义**：动作概率分布是指模型对每个动作类别的预测概率，是分类方法的输出。在动作概率分布中，每个动作类别都有一个对应的概率值，所有概率值的和为1。动作概率分布的数学表示为：$P(a|s) = [P(a_1|s), P(a_2|s), \\ldots, P(a_{|\\mathcal{A}|}|s)]$，其中$s$是多模态特征，$|\\mathcal{A}|$是动作空间大小。动作概率分布的优势在于：1）概率解释：每个值表示对应动作的概率，具有明确的概率解释；2）不确定性量化：能够量化模型对动作预测的不确定性；3）动作选择：能够根据概率选择动作，如选择概率最高的动作或根据概率采样；4）损失计算：能够用于计算交叉熵损失，训练模型。动作概率分布在VLA中的应用包括预测动作类别、量化预测不确定性、选择和执行动作等。动作概率分布是分类方法的核心输出，通过动作概率分布，VLA模型能够理解每个动作的概率，从而进行动作预测和执行。动作概率分布的质量直接影响分类方法的性能，好的动作概率分布能够帮助模型更准确地预测动作，提高任务完成率。\n",
        "- **核心组成**：动作概率分布的核心组成包括：1）概率值：每个动作类别都有一个对应的概率值；2）归一化：所有概率值的和为1；3）概率排序：概率值可以排序，找出概率最高的动作；4）概率采样：可以根据概率分布采样动作，用于探索。动作概率分布通常使用Softmax函数从logits转换得到，这些概率值表示模型对每个动作的置信度。动作概率分布的设计需要考虑概率解释、不确定性量化、动作选择等因素，以平衡预测准确性和探索性。\n",
        "- **在VLA中的应用**：在VLA中，动作概率分布用于预测动作类别、量化预测不确定性、选择和执行动作。例如，对于导航任务的离散动作空间，VLA模型输出5个动作的概率分布，然后选择概率最高的动作执行。动作概率分布的优势在于能够量化模型对动作预测的不确定性，这对于安全控制和探索性学习非常重要。在VLA训练过程中，动作概率分布通常与分类方法一起使用，通过端到端训练学习最适合任务的特征表示。动作概率分布的结果可以作为VLA模型的输出，帮助模型预测和执行动作。\n",
        "- **相关概念**：分类方法、Softmax函数、交叉熵损失、动作选择、不确定性量化\n",
        "- **首次出现位置**：本文档第2.2节\n",
        "- **深入学习**：参考本文档的动作概率分布详细讲解部分\n",
        "- **直观理解**：想象动作概率分布就像天气预报，预报每个动作的\"可能性\"。例如，对于导航任务，模型可能预测\"前进\"的概率是0.6，\"左转\"的概率是0.3，\"停止\"的概率是0.1。在VLA中，动作概率分布帮助模型理解每个动作的可能性，从而选择和执行动作。动作概率分布就像天气预报，帮助模型理解每个动作的可能性。\n",
        "\n",
        "### 5. 分类网络 (Classification Network)\n",
        "- **中文名称**：分类网络\n",
        "- **英文全称**：Classification Network\n",
        "- **定义**：分类网络是指用于分类任务的神经网络，是分类方法的核心组件。在分类网络中，输入是多模态特征，输出是动作概率分布。分类网络的数学表示为：$P(a|s) = \\text{softmax}(W \\cdot s + b)$，其中$s$是多模态特征，$W$是权重矩阵，$b$是偏置向量，$P(a|s)$是动作概率分布。分类网络的优势在于：1）特征学习：能够从多模态特征中学习动作模式；2）非线性表达：能够表达复杂的动作特征关系；3）端到端训练：能够与VLA模型的其他模块一起端到端训练；4）可扩展性：适用于各种规模的分类任务。分类网络在VLA中的应用包括从多模态特征中预测动作类别，这些预测将被用于动作执行。分类网络是分类方法的核心，通过分类网络，VLA模型能够从多模态特征中学习动作模式，预测动作类别，从而完成任务。分类网络的质量直接影响分类方法的性能，好的分类网络能够帮助模型更准确地预测动作，提高任务完成率。\n",
        "- **核心组成**：分类网络的核心组成包括：1）输入层：接收多模态特征作为输入；2）隐藏层：使用隐藏层学习动作的特征表示；3）输出层：输出动作的logits；4）Softmax层：使用Softmax层将logits转换为概率分布；5）激活函数：使用激活函数增加非线性；6）损失函数：定义损失函数，如交叉熵损失。分类网络通常使用全连接网络实现，这些网络能够从多模态特征中学习动作模式，预测动作类别。分类网络的设计需要考虑网络深度、宽度、激活函数等因素，以平衡表达能力和计算复杂度。\n",
        "- **在VLA中的应用**：在VLA中，分类网络用于从多模态特征中预测动作类别。例如，对于导航任务的离散动作空间，分类网络接收视觉特征和语言特征，输出5个动作的概率分布，然后选择概率最高的动作执行。分类网络的优势在于能够从多模态特征中学习动作模式，这对于理解复杂任务非常重要。在VLA训练过程中，分类网络通常与交叉熵损失函数一起使用，通过端到端训练学习最适合任务的特征表示。分类网络的结果可以作为VLA模型的输出，帮助模型预测和执行动作。\n",
        "- **相关概念**：分类方法、Softmax函数、交叉熵损失、动作概率分布、神经网络\n",
        "- **首次出现位置**：本文档第4.1节\n",
        "- **深入学习**：参考本文档的分类网络详细讲解部分\n",
        "- **直观理解**：想象分类网络就像一台\"决策机器\"，输入是视觉和语言信息，输出是应该执行的动作。例如，输入\"看到前方有障碍物\"和\"听到向左转\"的指令，分类网络会输出\"左转\"的概率最高，从而选择\"左转\"动作。在VLA中，分类网络帮助模型从多模态特征中预测动作，从而完成任务。分类网络就像一台\"决策机器\"，帮助模型预测和执行动作。\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 概述\n",
        "\n",
        "### 什么是分类方法\n",
        "\n",
        "分类方法是指使用分类模型预测离散动作类别的方法，是离散动作空间中最常用的预测方法。在分类方法中，模型将多模态特征映射到动作概率分布，然后选择概率最高的动作作为预测结果。\n",
        "\n",
        "### 为什么重要\n",
        "\n",
        "分类方法对于VLA学习非常重要，原因包括：\n",
        "\n",
        "1. **简单高效**：分类方法实现简单，计算效率高\n",
        "2. **概率解释**：输出是概率分布，具有明确的概率解释\n",
        "3. **训练稳定**：分类方法的训练相对稳定，收敛速度快\n",
        "4. **适合离散动作**：适合离散动作空间的预测任务\n",
        "\n",
        "### 学习目标\n",
        "\n",
        "通过本文档的学习，你将能够：\n",
        "\n",
        "1. **深入理解分类方法**：理解分类方法的原理和方法\n",
        "2. **掌握Softmax函数**：理解Softmax函数的数学原理和实现方法\n",
        "3. **理解交叉熵损失**：理解交叉熵损失的数学原理和优化方法\n",
        "4. **掌握分类方法在VLA中的应用**：理解分类方法在VLA模型中的具体应用\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 导入必要的库\n",
        "# ============================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'Microsoft YaHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 分类方法的基本原理\n",
        "\n",
        "### 1.1 什么是分类方法\n",
        "\n",
        "**直观理解**：想象分类方法就像让模型做选择题，给定一个问题（多模态特征），模型需要从多个选项（动作类别）中选择一个正确答案。\n",
        "\n",
        "**定义**：分类方法是指使用分类模型预测离散动作类别的方法，是离散动作空间中最常用的预测方法。\n",
        "\n",
        "### 1.2 分类方法的数学表示\n",
        "\n",
        "分类方法的数学表示为：\n",
        "\n",
        "$$P(a|s) = \\text{softmax}(W \\cdot s + b)$$\n",
        "\n",
        "其中：\n",
        "- $s \\in \\mathbb{R}^{d}$是多模态特征\n",
        "- $W \\in \\mathbb{R}^{|\\mathcal{A}| \\times d}$是权重矩阵\n",
        "- $b \\in \\mathbb{R}^{|\\mathcal{A}|}$是偏置向量\n",
        "- $P(a|s) \\in \\mathbb{R}^{|\\mathcal{A}|}$是动作概率分布\n",
        "- $|\\mathcal{A}|$是动作空间大小\n",
        "\n",
        "### 1.3 分类方法的流程\n",
        "\n",
        "分类方法的流程包括：\n",
        "\n",
        "1. **特征输入**：接收多模态特征$s$\n",
        "2. **线性变换**：计算$z = W \\cdot s + b$（logits）\n",
        "3. **Softmax归一化**：计算$P(a|s) = \\text{softmax}(z)$\n",
        "4. **动作选择**：选择$\\hat{a} = \\arg\\max_i P(a_i|s)$\n",
        "\n",
        "### 1.4 分类方法 vs 回归方法\n",
        "\n",
        "| 特性 | 分类方法 | 回归方法 |\n",
        "|------|---------|---------|\n",
        "| **输出类型** | 离散类别 | 连续数值 |\n",
        "| **输出表示** | 概率分布 | 数值向量 |\n",
        "| **损失函数** | 交叉熵损失 | 均方误差损失 |\n",
        "| **适用场景** | 离散动作空间 | 连续动作空间 |\n",
        "\n",
        "---\n",
        "\n",
        "## 2. 为什么需要分类方法\n",
        "\n",
        "### 2.1 分类方法的优势\n",
        "\n",
        "分类方法的优势包括：\n",
        "\n",
        "1. **简单高效**：\n",
        "   - 分类方法实现简单，计算效率高\n",
        "   - 只需要一次前向传播就能得到预测结果\n",
        "   - 适合大规模VLA任务\n",
        "\n",
        "2. **概率解释**：\n",
        "   - 输出是概率分布，具有明确的概率解释\n",
        "   - 能够量化模型对动作预测的不确定性\n",
        "   - 便于进行动作选择和探索\n",
        "\n",
        "3. **训练稳定**：\n",
        "   - 分类方法的训练相对稳定，收敛速度快\n",
        "   - 交叉熵损失的梯度计算简单，易于优化\n",
        "   - 适合端到端训练\n",
        "\n",
        "4. **适合离散动作**：\n",
        "   - 适合离散动作空间的预测任务\n",
        "   - 能够处理多类别分类问题\n",
        "   - 能够处理类别不平衡问题\n",
        "\n",
        "### 2.2 分类方法的适用场景\n",
        "\n",
        "**适合使用分类方法的场景**：\n",
        "\n",
        "1. **离散动作空间**：\n",
        "   - 动作空间是离散的\n",
        "   - 动作数量有限\n",
        "   - 需要预测动作类别\n",
        "\n",
        "2. **导航任务**：\n",
        "   - 动作是离散的（前进、后退、左转、右转、停止）\n",
        "   - 需要从多个选项中选择一个动作\n",
        "   - 适合使用分类方法\n",
        "\n",
        "3. **简单操作任务**：\n",
        "   - 动作是离散的（抓取、放置、移动等）\n",
        "   - 需要预测动作类别\n",
        "   - 适合使用分类方法\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Softmax函数详解\n",
        "\n",
        "### 3.1 什么是Softmax函数\n",
        "\n",
        "**直观理解**：想象Softmax函数就像将一组分数转换为百分比，所有百分比的和为100%。\n",
        "\n",
        "**定义**：Softmax函数是指将一组数值转换为概率分布的函数，是分类方法中的核心函数。\n",
        "\n",
        "### 3.2 为什么需要Softmax函数\n",
        "\n",
        "Softmax函数的必要性在于：\n",
        "\n",
        "1. **概率分布**：\n",
        "   - 输出是概率分布，所有值的和为1\n",
        "   - 每个值表示对应类别的概率\n",
        "   - 便于进行动作选择和损失计算\n",
        "\n",
        "2. **非负性**：\n",
        "   - 所有值都是非负的\n",
        "   - 符合概率的定义\n",
        "   - 便于进行概率解释\n",
        "\n",
        "3. **可微性**：\n",
        "   - Softmax是可微的，便于梯度下降\n",
        "   - 梯度计算简单，易于优化\n",
        "   - 适合端到端训练\n",
        "\n",
        "4. **放大差异**：\n",
        "   - 指数函数会放大logits之间的差异\n",
        "   - 使得概率分布更加集中\n",
        "   - 有助于模型做出明确的预测\n",
        "\n",
        "### 3.3 Softmax函数的数学推导详解\n",
        "\n",
        "#### 3.3.1 从基础数学开始\n",
        "\n",
        "**步骤1：理解指数函数**\n",
        "\n",
        "指数函数$\\exp(x) = e^x$的性质：\n",
        "- 单调递增：$x_1 < x_2 \\Rightarrow \\exp(x_1) < \\exp(x_2)$\n",
        "- 非负性：$\\exp(x) > 0$对所有$x$成立\n",
        "- 放大差异：大的值会被放大，小的值会被缩小\n",
        "\n",
        "**步骤2：理解归一化**\n",
        "\n",
        "归一化是指将一组值转换为概率分布，使得所有值的和为1：\n",
        "\n",
        "$$\\sum_{i=1}^{n} P_i = 1$$\n",
        "\n",
        "**步骤3：理解Softmax的推导**\n",
        "\n",
        "Softmax的推导过程：\n",
        "\n",
        "1. **计算logits**：$z = [z_1, z_2, \\ldots, z_n]$\n",
        "2. **应用指数函数**：$\\exp(z_i)$对所有$i$\n",
        "3. **归一化**：$\\frac{\\exp(z_i)}{\\sum_{j=1}^{n} \\exp(z_j)}$\n",
        "\n",
        "**为什么使用Softmax**：\n",
        "- **概率分布**：输出是概率分布，所有值的和为1\n",
        "- **非负性**：所有值都是非负的\n",
        "- **可微性**：Softmax是可微的，便于梯度下降\n",
        "- **放大差异**：指数函数会放大logits之间的差异\n",
        "\n",
        "#### 3.3.2 Softmax函数的具体计算示例\n",
        "\n",
        "**示例：Softmax函数计算**\n",
        "\n",
        "假设：\n",
        "- logits：$z = [2.5, 0.3, -0.8, 0.1, 1.2]$\n",
        "- 动作空间大小：$|\\mathcal{A}| = 5$\n",
        "\n",
        "**步骤1：应用指数函数**\n",
        "\n",
        "$$\\exp(z) = [\\exp(2.5), \\exp(0.3), \\exp(-0.8), \\exp(0.1), \\exp(1.2)]$$\n",
        "\n",
        "计算：\n",
        "- $\\exp(2.5) \\approx 12.182$\n",
        "- $\\exp(0.3) \\approx 1.350$\n",
        "- $\\exp(-0.8) \\approx 0.449$\n",
        "- $\\exp(0.1) \\approx 1.105$\n",
        "- $\\exp(1.2) \\approx 3.320$\n",
        "\n",
        "所以：\n",
        "$$\\exp(z) \\approx [12.182, 1.350, 0.449, 1.105, 3.320]$$\n",
        "\n",
        "**步骤2：归一化**\n",
        "\n",
        "归一化因子：\n",
        "$$Z = \\sum_{i=1}^{5} \\exp(z_i) \\approx 12.182 + 1.350 + 0.449 + 1.105 + 3.320 = 18.406$$\n",
        "\n",
        "概率分布：\n",
        "$$P(a|s) = \\frac{\\exp(z)}{Z} \\approx [0.662, 0.073, 0.024, 0.060, 0.180]$$\n",
        "\n",
        "**步骤3：验证归一化**\n",
        "\n",
        "$$\\sum_{i=1}^{5} P(a_i|s) \\approx 0.662 + 0.073 + 0.024 + 0.060 + 0.180 = 0.999 \\approx 1$$\n",
        "\n",
        "### 3.4 Softmax函数的可视化\n",
        "\n",
        "下面我们通过代码可视化Softmax函数的过程：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Softmax函数可视化（示例：VLA任务的Softmax函数）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的离散动作空间\n",
        "actions = ['前进', '后退', '左转', '右转', '停止']\n",
        "num_actions = len(actions)\n",
        "\n",
        "# 示例logits\n",
        "logits = np.array([2.5, 0.3, -0.8, 0.1, 1.2])\n",
        "\n",
        "# 计算Softmax\n",
        "exp_logits = np.exp(logits)\n",
        "softmax_probs = exp_logits / np.sum(exp_logits)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：Logits vs Softmax概率\n",
        "ax1 = axes[0, 0]\n",
        "x_pos = np.arange(num_actions)\n",
        "width = 0.35\n",
        "bars1 = ax1.bar(x_pos - width/2, logits, width, label='Logits', \n",
        "               color='steelblue', alpha=0.7, edgecolor='black', linewidth=2)\n",
        "bars2 = ax1.bar(x_pos + width/2, softmax_probs, width, label='Softmax概率', \n",
        "               color='orange', alpha=0.7, edgecolor='black', linewidth=2)\n",
        "ax1.set_title('Logits vs Softmax概率', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('动作类别')\n",
        "ax1.set_ylabel('值')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "ax1.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "\n",
        "# 添加数值标注\n",
        "for i, (bar1, bar2, logit, prob) in enumerate(zip(bars1, bars2, logits, softmax_probs)):\n",
        "    height1 = bar1.get_height()\n",
        "    height2 = bar2.get_height()\n",
        "    ax1.text(bar1.get_x() + bar1.get_width()/2., height1 + 0.1 if height1 >= 0 else height1 - 0.1,\n",
        "            f'{logit:.2f}', ha='center', va='bottom' if height1 >= 0 else 'top', \n",
        "            fontsize=9, fontweight='bold')\n",
        "    ax1.text(bar2.get_x() + bar2.get_width()/2., height2 + 0.02,\n",
        "            f'{prob:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "# 右上：Softmax概率分布\n",
        "ax2 = axes[0, 1]\n",
        "bars = ax2.bar(x_pos, softmax_probs, color='steelblue', alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "ax2.set_title('Softmax概率分布', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('动作类别')\n",
        "ax2.set_ylabel('概率')\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax2.set_ylim(0, 1.1)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 添加数值标注和选择标记\n",
        "max_idx = np.argmax(softmax_probs)\n",
        "for i, (bar, prob) in enumerate(zip(bars, softmax_probs)):\n",
        "    height = bar.get_height()\n",
        "    color = 'red' if i == max_idx else 'steelblue'\n",
        "    bar.set_color(color)\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "            f'{prob:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    if i == max_idx:\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "                '✓', ha='center', va='bottom', fontsize=16, fontweight='bold', color='red')\n",
        "\n",
        "# 左下：Softmax函数过程\n",
        "ax3 = axes[1, 0]\n",
        "ax3.axis('off')\n",
        "# 绘制Softmax函数过程\n",
        "flow_boxes = [\n",
        "    ('Logits', 0.2, 0.9),\n",
        "    ('指数函数', 0.5, 0.9),\n",
        "    ('归一化', 0.8, 0.9),\n",
        "    ('z = [2.5, 0.3, ...]', 0.2, 0.7),\n",
        "    ('exp(z)', 0.5, 0.7),\n",
        "    ('P = exp(z)/Σ', 0.8, 0.7),\n",
        "    ('概率分布', 0.5, 0.5),\n",
        "    ('P = [0.662, 0.073, ...]', 0.5, 0.3),\n",
        "]\n",
        "\n",
        "for text, x, y in flow_boxes:\n",
        "    ax3.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "    if y < 0.9:\n",
        "        if y > 0.5:\n",
        "            ax3.arrow(x, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "        else:\n",
        "            ax3.arrow(0.5, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "\n",
        "ax3.set_xlim(0, 1)\n",
        "ax3.set_ylim(0, 1)\n",
        "ax3.set_title('Softmax函数过程', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 右下：不同logits的Softmax效果\n",
        "ax4 = axes[1, 1]\n",
        "# 生成不同范围的logits\n",
        "logits_cases = [\n",
        "    ([1.0, 0.5, 0.0], '小差异'),\n",
        "    ([2.0, 1.5, 1.0], '中等差异'),\n",
        "    ([5.0, 2.0, 0.0], '大差异'),\n",
        "]\n",
        "x_pos_cases = np.arange(3)\n",
        "width_case = 0.25\n",
        "\n",
        "for i, (logits_case, label) in enumerate(logits_cases):\n",
        "    exp_logits_case = np.exp(logits_case)\n",
        "    softmax_case = exp_logits_case / np.sum(exp_logits_case)\n",
        "    offset = (i - len(logits_cases)/2) * width_case\n",
        "    bars = ax4.bar(x_pos_cases + offset, softmax_case, width_case, \n",
        "                  label=label, alpha=0.7, edgecolor='black', linewidth=1)\n",
        "\n",
        "ax4.set_title('不同logits差异的Softmax效果', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('动作类别')\n",
        "ax4.set_ylabel('概率')\n",
        "ax4.set_xticks(x_pos_cases)\n",
        "ax4.set_xticklabels(['动作1', '动作2', '动作3'])\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Softmax函数可视化：VLA任务的Softmax函数', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Softmax函数可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：Logits vs Softmax概率，显示logits和对应的概率值\")\n",
        "print(\"2. 右上：Softmax概率分布，显示每个动作的概率（红色标记为最高概率）\")\n",
        "print(\"3. 左下：Softmax函数过程，显示从logits到概率分布的转换过程\")\n",
        "print(\"4. 右下：不同logits差异的Softmax效果，显示logits差异对概率分布的影响\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 交叉熵损失可视化（示例：VLA任务的交叉熵损失）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的离散动作空间\n",
        "actions = ['前进', '后退', '左转', '右转', '停止']\n",
        "num_actions = len(actions)\n",
        "\n",
        "# 示例：真实动作和预测概率\n",
        "true_action_idx = 2  # 左转\n",
        "true_label = np.zeros(num_actions)\n",
        "true_label[true_action_idx] = 1\n",
        "\n",
        "# 不同预测概率情况\n",
        "pred_probs_cases = [\n",
        "    ([0.1, 0.1, 0.7, 0.05, 0.05], '准确预测'),\n",
        "    ([0.2, 0.2, 0.3, 0.2, 0.1], '中等预测'),\n",
        "    ([0.662, 0.073, 0.024, 0.060, 0.180], '错误预测'),\n",
        "]\n",
        "\n",
        "# 计算交叉熵损失\n",
        "losses = []\n",
        "for pred_probs, _ in pred_probs_cases:\n",
        "    loss = -np.log(pred_probs[true_action_idx])\n",
        "    losses.append(loss)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：不同预测概率的交叉熵损失\n",
        "ax1 = axes[0, 0]\n",
        "x_pos = np.arange(len(pred_probs_cases))\n",
        "bars = ax1.bar(x_pos, losses, color=['green', 'orange', 'red'], alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "ax1.set_title('不同预测概率的交叉熵损失', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('预测情况')\n",
        "ax1.set_ylabel('交叉熵损失')\n",
        "ax1.set_xticks(x_pos)\n",
        "ax1.set_xticklabels([label for _, label in pred_probs_cases])\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 添加数值标注\n",
        "for i, (bar, loss) in enumerate(zip(bars, losses)):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{loss:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# 右上：预测概率分布对比\n",
        "ax2 = axes[0, 1]\n",
        "x_pos_actions = np.arange(num_actions)\n",
        "width = 0.25\n",
        "for i, (pred_probs, label) in enumerate(pred_probs_cases):\n",
        "    offset = (i - len(pred_probs_cases)/2) * width\n",
        "    bars = ax2.bar(x_pos_actions + offset, pred_probs, width, \n",
        "                  label=label, alpha=0.7, edgecolor='black', linewidth=1)\n",
        "    # 标记真实动作\n",
        "    if i == 0:  # 只标记一次\n",
        "        ax2.axvline(x=true_action_idx, color='red', linestyle='--', \n",
        "                   linewidth=2, label='真实动作')\n",
        "ax2.set_title('预测概率分布对比', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('动作类别')\n",
        "ax2.set_ylabel('概率')\n",
        "ax2.set_xticks(x_pos_actions)\n",
        "ax2.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 左下：交叉熵损失 vs 预测概率\n",
        "ax3 = axes[1, 0]\n",
        "prob_range = np.linspace(0.01, 0.99, 100)\n",
        "loss_range = -np.log(prob_range)\n",
        "ax3.plot(prob_range, loss_range, linewidth=2, color='steelblue')\n",
        "ax3.set_title('交叉熵损失 vs 预测概率', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('预测概率 P(a_true|s)')\n",
        "ax3.set_ylabel('交叉熵损失 -log(P)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "# 标记示例点\n",
        "for pred_probs, label in pred_probs_cases:\n",
        "    prob = pred_probs[true_action_idx]\n",
        "    loss = -np.log(prob)\n",
        "    ax3.scatter(prob, loss, s=100, alpha=0.7, edgecolors='black', linewidth=2)\n",
        "    ax3.annotate(label, (prob, loss), xytext=(5, 5), textcoords='offset points', \n",
        "                fontsize=9, fontweight='bold')\n",
        "\n",
        "# 右下：交叉熵损失计算过程\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "# 绘制交叉熵损失计算过程\n",
        "flow_boxes = [\n",
        "    ('真实标签', 0.2, 0.9),\n",
        "    ('预测概率', 0.5, 0.9),\n",
        "    ('交叉熵', 0.8, 0.9),\n",
        "    ('y = [0, 0, 1, 0, 0]', 0.2, 0.7),\n",
        "    ('P = [0.1, 0.1, 0.7, ...]', 0.5, 0.7),\n",
        "    ('L = -log(P_true)', 0.8, 0.7),\n",
        "    ('损失值', 0.5, 0.5),\n",
        "    ('L = -log(0.7) ≈ 0.357', 0.5, 0.3),\n",
        "]\n",
        "\n",
        "for text, x, y in flow_boxes:\n",
        "    ax4.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "    if y < 0.9:\n",
        "        if y > 0.5:\n",
        "            ax4.arrow(x, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "        else:\n",
        "            ax4.arrow(0.5, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "\n",
        "ax4.set_xlim(0, 1)\n",
        "ax4.set_ylim(0, 1)\n",
        "ax4.set_title('交叉熵损失计算过程', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('交叉熵损失可视化：VLA任务的交叉熵损失', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"交叉熵损失可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：不同预测概率的交叉熵损失，显示准确预测、中等预测、错误预测的损失值\")\n",
        "print(\"2. 右上：预测概率分布对比，显示不同预测情况下的概率分布\")\n",
        "print(\"3. 左下：交叉熵损失 vs 预测概率，显示损失值与预测概率的关系\")\n",
        "print(\"4. 右下：交叉熵损失计算过程，显示从真实标签和预测概率到损失值的计算过程\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. 分类网络详解\n",
        "\n",
        "### 5.1 什么是分类网络\n",
        "\n",
        "**直观理解**：想象分类网络就像一台\"决策机器\"，输入是视觉和语言信息，输出是应该执行的动作。\n",
        "\n",
        "**定义**：分类网络是指用于分类任务的神经网络，是分类方法的核心组件。\n",
        "\n",
        "### 5.2 为什么需要分类网络\n",
        "\n",
        "分类网络的必要性在于：\n",
        "\n",
        "1. **特征学习**：\n",
        "   - 能够从多模态特征中学习动作模式\n",
        "   - 能够提取动作相关的特征表示\n",
        "   - 有助于提高预测准确性\n",
        "\n",
        "2. **非线性表达**：\n",
        "   - 能够表达复杂的动作特征关系\n",
        "   - 能够处理非线性映射\n",
        "   - 适合复杂的分类任务\n",
        "\n",
        "3. **端到端训练**：\n",
        "   - 能够与VLA模型的其他模块一起端到端训练\n",
        "   - 能够学习最适合任务的特征表示\n",
        "   - 能够优化整体性能\n",
        "\n",
        "4. **可扩展性**：\n",
        "   - 适用于各种规模的分类任务\n",
        "   - 能够处理大规模动作空间\n",
        "   - 适合各种分类场景\n",
        "\n",
        "### 5.3 分类网络的数学推导详解\n",
        "\n",
        "#### 5.3.1 从基础数学开始\n",
        "\n",
        "**步骤1：理解线性层**\n",
        "\n",
        "线性层的数学表示为：\n",
        "\n",
        "$$z = W \\cdot x + b$$\n",
        "\n",
        "其中：\n",
        "- $x \\in \\mathbb{R}^{d_{in}}$是输入\n",
        "- $W \\in \\mathbb{R}^{d_{out} \\times d_{in}}$是权重矩阵\n",
        "- $b \\in \\mathbb{R}^{d_{out}}$是偏置向量\n",
        "- $z \\in \\mathbb{R}^{d_{out}}$是输出（logits）\n",
        "\n",
        "**步骤2：理解激活函数**\n",
        "\n",
        "激活函数增加非线性，常用的激活函数包括ReLU、tanh、sigmoid等。\n",
        "\n",
        "**步骤3：理解分类网络**\n",
        "\n",
        "分类网络的数学表示为：\n",
        "\n",
        "$$P(a|s) = \\text{softmax}(W_2 \\cdot \\text{ReLU}(W_1 \\cdot s + b_1) + b_2)$$\n",
        "\n",
        "其中：\n",
        "- $s$是多模态特征\n",
        "- $W_1, b_1$是第一层的权重和偏置\n",
        "- $W_2, b_2$是第二层的权重和偏置\n",
        "\n",
        "#### 5.3.2 分类网络的具体计算示例\n",
        "\n",
        "**示例：分类网络计算**\n",
        "\n",
        "假设：\n",
        "- 多模态特征维度：$d = 128$\n",
        "- 隐藏层维度：$d_{hidden} = 64$\n",
        "- 动作空间大小：$|\\mathcal{A}| = 5$\n",
        "- 多模态特征：$s \\in \\mathbb{R}^{128}$（随机生成）\n",
        "\n",
        "**步骤1：第一层计算**\n",
        "\n",
        "$$h = \\text{ReLU}(W_1 \\cdot s + b_1)$$\n",
        "\n",
        "其中$W_1 \\in \\mathbb{R}^{64 \\times 128}$，$b_1 \\in \\mathbb{R}^{64}$。\n",
        "\n",
        "**步骤2：第二层计算**\n",
        "\n",
        "$$z = W_2 \\cdot h + b_2$$\n",
        "\n",
        "其中$W_2 \\in \\mathbb{R}^{5 \\times 64}$，$b_2 \\in \\mathbb{R}^{5}$。\n",
        "\n",
        "**步骤3：Softmax归一化**\n",
        "\n",
        "$$P(a|s) = \\text{softmax}(z)$$\n",
        "\n",
        "### 5.4 分类网络的可视化\n",
        "\n",
        "下面我们通过代码可视化分类网络的过程：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 分类网络可视化（示例：VLA任务的分类网络）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的分类网络\n",
        "d_input = 128  # 多模态特征维度\n",
        "d_hidden = 64  # 隐藏层维度\n",
        "num_actions = 5  # 动作空间大小\n",
        "actions = ['前进', '后退', '左转', '右转', '停止']\n",
        "\n",
        "# 模拟分类网络\n",
        "W1 = np.random.randn(d_hidden, d_input) * 0.1\n",
        "b1 = np.random.randn(d_hidden) * 0.1\n",
        "W2 = np.random.randn(num_actions, d_hidden) * 0.1\n",
        "b2 = np.random.randn(num_actions) * 0.1\n",
        "\n",
        "# 生成示例多模态特征\n",
        "num_samples = 20\n",
        "multimodal_features = np.random.randn(num_samples, d_input)\n",
        "\n",
        "# 前向传播\n",
        "h = np.maximum(0, multimodal_features @ W1.T + b1)  # ReLU\n",
        "logits = h @ W2.T + b2\n",
        "probs = F.softmax(torch.tensor(logits), dim=1).numpy()\n",
        "predicted_actions = np.argmax(probs, axis=1)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：分类网络架构\n",
        "ax1 = axes[0, 0]\n",
        "ax1.axis('off')\n",
        "# 绘制分类网络架构\n",
        "layers = [\n",
        "    ('多模态特征', 0.1, 0.5, d_input),\n",
        "    ('隐藏层', 0.5, 0.5, d_hidden),\n",
        "    ('输出层', 0.9, 0.5, num_actions),\n",
        "]\n",
        "\n",
        "for i, (name, x, y, dim) in enumerate(layers):\n",
        "    # 绘制层\n",
        "    rect_height = min(0.3, dim * 0.005)\n",
        "    rect = plt.Rectangle((x - 0.05, y - rect_height/2), 0.1, rect_height,\n",
        "                        facecolor='lightblue', edgecolor='black', linewidth=2)\n",
        "    ax1.add_patch(rect)\n",
        "    ax1.text(x, y, name, ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "    ax1.text(x, y - rect_height/2 - 0.05, f'{dim}维', ha='center', va='top', \n",
        "            fontsize=9)\n",
        "    \n",
        "    # 绘制连接\n",
        "    if i < len(layers) - 1:\n",
        "        next_x = layers[i+1][1]\n",
        "        ax1.arrow(x + 0.05, y, next_x - x - 0.1, 0, head_width=0.02, \n",
        "                 head_length=0.02, fc='black', ec='black')\n",
        "\n",
        "ax1.set_xlim(0, 1)\n",
        "ax1.set_ylim(0, 1)\n",
        "ax1.set_title('分类网络架构', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 右上：预测动作分布\n",
        "ax2 = axes[0, 1]\n",
        "action_counts = np.bincount(predicted_actions, minlength=num_actions)\n",
        "bars = ax2.bar(range(num_actions), action_counts, color='steelblue', alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "ax2.set_title('预测动作分布', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('动作类别')\n",
        "ax2.set_ylabel('预测次数')\n",
        "ax2.set_xticks(range(num_actions))\n",
        "ax2.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 添加数值标注\n",
        "for i, (bar, count) in enumerate(zip(bars, action_counts)):\n",
        "    height = bar.get_height()\n",
        "    if height > 0:\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.2,\n",
        "                f'{int(count)}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "# 左下：预测概率分布（单个样本）\n",
        "ax3 = axes[1, 0]\n",
        "sample_idx = 0\n",
        "sample_probs = probs[sample_idx]\n",
        "bars = ax3.bar(range(num_actions), sample_probs, color='steelblue', alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "max_idx = np.argmax(sample_probs)\n",
        "bars[max_idx].set_color('red')\n",
        "ax3.set_title(f'样本{sample_idx+1}的预测概率分布', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('动作类别')\n",
        "ax3.set_ylabel('概率')\n",
        "ax3.set_xticks(range(num_actions))\n",
        "ax3.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax3.set_ylim(0, 1.1)\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 添加数值标注\n",
        "for i, (bar, prob) in enumerate(zip(bars, sample_probs)):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "            f'{prob:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "    if i == max_idx:\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "                '✓', ha='center', va='bottom', fontsize=16, fontweight='bold', color='red')\n",
        "\n",
        "# 右下：分类网络流程\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "# 绘制分类网络流程\n",
        "flow_boxes = [\n",
        "    ('多模态特征', 0.5, 0.9),\n",
        "    ('线性层1', 0.3, 0.7),\n",
        "    ('ReLU', 0.5, 0.7),\n",
        "    ('线性层2', 0.7, 0.7),\n",
        "    ('Logits', 0.5, 0.5),\n",
        "    ('Softmax', 0.5, 0.3),\n",
        "    ('动作概率', 0.5, 0.1),\n",
        "]\n",
        "\n",
        "for text, x, y in flow_boxes:\n",
        "    ax4.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "    if y < 0.9:\n",
        "        ax4.arrow(0.5, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                 fc='black', ec='black')\n",
        "\n",
        "ax4.set_xlim(0, 1)\n",
        "ax4.set_ylim(0, 1)\n",
        "ax4.set_title('分类网络流程', fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('分类网络可视化：VLA任务的分类网络', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"分类网络可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：分类网络架构，显示从多模态特征到动作概率的网络结构\")\n",
        "print(\"2. 右上：预测动作分布，显示所有样本的预测动作分布\")\n",
        "print(\"3. 左下：单个样本的预测概率分布，显示模型对每个动作的预测概率\")\n",
        "print(\"4. 右下：分类网络流程，显示从多模态特征到动作概率的完整流程\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. 分类方法在VLA中的应用\n",
        "\n",
        "### 6.1 分类方法在VLA中的角色\n",
        "\n",
        "在VLA中，分类方法用于预测离散动作空间中的动作类别。VLA模型使用分类方法从多模态特征中预测应该执行的动作，然后执行相应的动作。\n",
        "\n",
        "### 6.2 分类方法在VLA中的优势\n",
        "\n",
        "分类方法在VLA中的优势包括：\n",
        "\n",
        "1. **简单高效**：实现简单，计算效率高，适合大规模VLA任务\n",
        "2. **概率解释**：输出是概率分布，能够量化模型对动作预测的不确定性\n",
        "3. **训练稳定**：训练相对稳定，收敛速度快，适合端到端训练\n",
        "4. **适合离散动作**：适合离散动作空间的预测任务，能够处理多类别分类问题\n",
        "\n",
        "### 6.3 分类方法在VLA中的使用流程\n",
        "\n",
        "**步骤1：定义动作空间**\n",
        "\n",
        "定义离散动作空间，包括动作类型和动作数量：\n",
        "\n",
        "```python\n",
        "action_space = {\n",
        "    'actions': ['前进', '后退', '左转', '右转', '停止'],\n",
        "    'num_actions': 5,\n",
        "}\n",
        "```\n",
        "\n",
        "**步骤2：创建分类网络**\n",
        "\n",
        "创建分类网络，将多模态特征映射到动作概率分布：\n",
        "\n",
        "```python\n",
        "class ActionClassifier(nn.Module):\n",
        "    def __init__(self, d_input, d_hidden, num_actions):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_input, d_hidden)\n",
        "        self.fc2 = nn.Linear(d_hidden, num_actions)\n",
        "    \n",
        "    def forward(self, multimodal_features):\n",
        "        h = F.relu(self.fc1(multimodal_features))\n",
        "        logits = self.fc2(h)\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        return probs\n",
        "```\n",
        "\n",
        "**步骤3：训练分类模型**\n",
        "\n",
        "使用交叉熵损失训练分类模型：\n",
        "\n",
        "```python\n",
        "# 获取动作概率\n",
        "probs = action_classifier(multimodal_features)\n",
        "\n",
        "# 计算交叉熵损失\n",
        "loss = F.cross_entropy(logits, true_action_labels)\n",
        "\n",
        "# 反向传播\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "**步骤4：动作预测**\n",
        "\n",
        "选择概率最高的动作作为预测结果：\n",
        "\n",
        "```python\n",
        "# 预测动作\n",
        "predicted_action = torch.argmax(probs, dim=1)\n",
        "```\n",
        "\n",
        "### 6.4 分类方法在VLA中的典型应用\n",
        "\n",
        "#### 6.4.1 导航任务\n",
        "\n",
        "**应用场景**：机器人导航任务\n",
        "\n",
        "**动作空间**：\n",
        "```python\n",
        "navigation_actions = ['前进', '后退', '左转', '右转', '停止']\n",
        "```\n",
        "\n",
        "**优势**：\n",
        "- 动作空间是离散的，适合使用分类方法\n",
        "- 能够从视觉和语言信息中预测导航动作\n",
        "- 实现简单，计算效率高\n",
        "\n",
        "#### 6.4.2 简单操作任务\n",
        "\n",
        "**应用场景**：机器人简单操作任务\n",
        "\n",
        "**动作空间**：\n",
        "```python\n",
        "manipulation_actions = ['抓取', '放置', '移动', '旋转', '停止']\n",
        "```\n",
        "\n",
        "**优势**：\n",
        "- 动作空间是离散的，适合使用分类方法\n",
        "- 能够从视觉和语言信息中预测操作动作\n",
        "- 训练稳定，收敛速度快\n",
        "\n",
        "---\n",
        "\n",
        "## 7. 总结\n",
        "\n",
        "### 7.1 分类方法的核心思想\n",
        "\n",
        "分类方法的核心思想包括：\n",
        "\n",
        "1. **概率预测**：将多模态特征映射到动作概率分布\n",
        "2. **Softmax归一化**：使用Softmax函数将logits转换为概率分布\n",
        "3. **交叉熵损失**：使用交叉熵损失函数训练模型\n",
        "4. **动作选择**：选择概率最高的动作作为预测结果\n",
        "\n",
        "### 7.2 分类方法的优势\n",
        "\n",
        "分类方法的优势包括：\n",
        "\n",
        "1. **简单高效**：实现简单，计算效率高\n",
        "2. **概率解释**：输出是概率分布，具有明确的概率解释\n",
        "3. **训练稳定**：训练相对稳定，收敛速度快\n",
        "4. **适合离散动作**：适合离散动作空间的预测任务\n",
        "\n",
        "### 7.3 分类方法在VLA中的重要性\n",
        "\n",
        "分类方法在VLA中的重要性体现在：\n",
        "\n",
        "1. **离散动作预测的基础**：分类方法是预测离散动作的基础，是VLA动作预测的重要方法\n",
        "2. **简单高效**：实现简单，计算效率高，适合大规模VLA任务\n",
        "3. **概率解释**：输出是概率分布，能够量化模型对动作预测的不确定性\n",
        "4. **应用广泛**：在VLA中应用广泛，是VLA动作预测的重要方法\n",
        "\n",
        "### 7.4 学习建议\n",
        "\n",
        "1. **理解基础概念**：深入理解分类方法、Softmax函数、交叉熵损失等基础概念\n",
        "2. **掌握数学原理**：掌握Softmax函数和交叉熵损失的数学原理和实现方法\n",
        "3. **实践设计**：通过实践设计不同任务的分类网络，理解设计原则\n",
        "4. **对比学习**：对比分类方法和回归方法，理解各自的适用场景\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 文档信息\n",
        "\n",
        "- **创建时间**：2024年\n",
        "- **文档版本**：v1.0\n",
        "- **维护者**：VLA学习团队\n",
        "- **相关文档**：\n",
        "  - [动作执行基础详解](../../理论笔记/动作执行基础详解.ipynb)\n",
        "  - [离散动作空间详解](../../01_动作表示/01_离散动作空间/理论笔记/离散动作空间详解.ipynb)\n",
        "  - [回归方法详解](../02_回归方法/理论笔记/回归方法详解.ipynb)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
