{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 动作嵌入详解\n",
        "\n",
        "## 📋 文档说明\n",
        "\n",
        "本文档是动作嵌入的详细理论讲解，比父目录的《动作执行基础详解》更加深入和详细。本文档将深入讲解动作嵌入的原理、数学推导和实现细节。通过本文档，你将能够：\n",
        "\n",
        "1. **深入理解动作嵌入的原理**：从嵌入定义到向量空间学习的完整流程\n",
        "2. **掌握动作嵌入的数学原理**：理解动作嵌入的数学定义、为什么有效、如何实现\n",
        "3. **理解嵌入学习方法**：理解如何使用神经网络学习动作嵌入\n",
        "4. **掌握语义相似性**：理解动作嵌入如何捕获语义相似性\n",
        "5. **掌握动作嵌入在VLA中的应用**：理解动作嵌入在VLA模型中的具体应用和优势\n",
        "\n",
        "**学习方式**：本文件是Jupyter Notebook格式，你可以边看边运行代码，通过可视化图表和数学推导更好地理解动作嵌入的原理和过程。\n",
        "\n",
        "**文档结构**：\n",
        "- 父目录：动作执行基础详解（见../../理论笔记/动作执行基础详解.ipynb）\n",
        "- 本文档：动作嵌入详解（本文档）\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 术语表（按出现顺序）\n",
        "\n",
        "### 1. 动作嵌入 (Action Embedding)\n",
        "- **中文名称**：动作嵌入\n",
        "- **英文全称**：Action Embedding\n",
        "- **定义**：动作嵌入是指将动作嵌入到向量空间中的方法，是动作表示的重要技术。在动作嵌入中，每个动作都被映射到一个固定维度的向量，这个向量捕获了动作的语义信息。动作嵌入的优势在于：1）语义相似性：语义相似的动作在向量空间中距离较近；2）泛化能力：能够泛化到未见过的动作；3）特征学习：能够学习动作的特征表示；4）统一表示：能够将不同类型的动作（离散动作、连续动作）统一表示为向量。动作嵌入的表示方法包括查找表嵌入（Lookup Table Embedding）、神经网络嵌入（Neural Network Embedding）等。动作嵌入在VLA中的应用包括将动作转换为向量表示，这些表示将被用于动作预测、动作相似性计算、动作泛化等。动作嵌入是VLA动作表示的重要方法，通过动作嵌入，VLA模型能够将动作表示为向量，使用向量空间中的距离度量动作相似性，从而更好地预测和执行动作。动作嵌入的质量直接影响VLA模型的性能，好的动作嵌入能够帮助模型更好地理解动作的语义，提高任务完成率。在VLA训练过程中，动作嵌入通常与动作预测网络一起端到端训练，学习最适合VLA任务的动作表示方法。\n",
        "- **核心组成**：动作嵌入的核心组成包括：1）嵌入函数：定义从动作到向量的映射函数；2）嵌入维度：定义嵌入向量的维度；3）嵌入学习：使用神经网络学习动作嵌入；4）语义相似性：捕获动作的语义相似性；5）特征提取：提取动作的特征表示；6）嵌入评估：评估嵌入质量，如语义相似性、泛化能力等。动作嵌入通常使用神经网络实现，如全连接网络、Transformer等，这些模型能够从动作数据中学习动作的特征表示。动作嵌入的设计需要考虑任务特点，选择合适的嵌入维度和嵌入方法，以平衡表达能力和计算复杂度。\n",
        "- **在VLA中的应用**：在VLA中，动作嵌入用于将动作转换为向量表示，便于模型处理和预测。例如，对于离散动作空间中的动作（如\"抓取\"、\"放置\"、\"移动\"等），VLA模型使用动作嵌入将这些动作转换为向量表示，这些表示将被用于动作预测、动作相似性计算等。动作嵌入的优势在于能够捕获动作的语义信息，这对于理解动作和预测动作非常重要。在VLA训练过程中，动作嵌入通常与动作预测网络一起端到端训练，通过端到端训练学习最适合任务的动作表示。动作嵌入的结果可以作为VLA模型的中间表示，帮助模型理解动作的语义，从而更好地预测和执行动作。\n",
        "- **相关概念**：离散动作空间、连续动作空间、词向量、向量空间、语义相似性、嵌入学习\n",
        "- **首次出现位置**：本文档标题\n",
        "- **深入学习**：参考父目录的[动作执行基础详解](../../理论笔记/动作执行基础详解.ipynb)和[词向量详解](../../../02_语言理解基础/01_文本特征提取/01_词向量/理论笔记/词向量详解.ipynb)\n",
        "- **直观理解**：想象动作嵌入就像给每个动作分配一个\"身份证号码\"，这个号码是一个向量，语义相似的动作有相似的向量。例如，\"抓取\"和\"拿起\"语义相似，它们的动作嵌入在向量空间中距离较近。在VLA中，动作嵌入帮助模型理解动作的语义，从而更好地预测和执行动作。动作嵌入就像给每个动作分配一个\"身份证号码\"，帮助模型理解动作的语义。\n",
        "\n",
        "### 2. 向量空间 (Vector Space)\n",
        "- **中文名称**：向量空间\n",
        "- **英文全称**：Vector Space\n",
        "- **定义**：向量空间是指由向量组成的数学空间，是动作嵌入的基础。在向量空间中，每个动作都被表示为一个向量，向量之间的距离可以度量动作的相似性。向量空间的优势在于：1）统一表示：能够将不同类型的动作统一表示为向量；2）距离度量：能够使用向量之间的距离度量动作相似性；3）数学运算：能够对向量进行数学运算，如加法、减法、点积等；4）维度控制：能够通过控制向量维度控制表达能力和计算复杂度。向量空间在VLA中的应用包括表示动作嵌入，使用向量空间中的距离度量动作相似性，进行动作预测等。向量空间是动作嵌入的基础，通过向量空间，VLA模型能够将动作表示为向量，使用向量空间中的距离度量动作相似性，从而更好地预测和执行动作。\n",
        "- **核心组成**：向量空间的核心组成包括：1）向量表示：将动作表示为向量；2）距离度量：定义向量之间的距离度量方法，如欧氏距离、余弦相似度等；3）维度控制：控制向量的维度，平衡表达能力和计算复杂度；4）数学运算：对向量进行数学运算，如加法、减法、点积等；5）空间结构：理解向量空间的结构，如线性结构、非线性结构等；6）空间可视化：可视化向量空间，理解动作在空间中的分布。向量空间通常使用欧氏空间（$\\mathbb{R}^d$）表示，其中$d$是向量维度。\n",
        "- **在VLA中的应用**：在VLA中，向量空间用于表示动作嵌入，使用向量空间中的距离度量动作相似性。例如，对于离散动作空间中的动作，VLA模型使用动作嵌入将这些动作映射到向量空间，然后使用向量空间中的距离度量动作相似性。向量空间的优势在于能够统一表示不同类型的动作，这对于理解动作和预测动作非常重要。在VLA训练过程中，向量空间通常与动作嵌入一起学习，通过端到端训练学习最适合任务的动作表示。向量空间的结果可以作为VLA模型的中间表示，帮助模型理解动作的语义，从而更好地预测和执行动作。\n",
        "- **相关概念**：动作嵌入、语义相似性、距离度量、欧氏距离、余弦相似度\n",
        "- **首次出现位置**：本文档第1.2节\n",
        "- **深入学习**：参考本文档的向量空间详细讲解部分\n",
        "- **直观理解**：想象向量空间就像一张地图，每个动作在这张地图上都有一个位置，位置相近的动作语义相似。例如，\"抓取\"和\"拿起\"在向量空间中位置相近，而\"抓取\"和\"放置\"在向量空间中位置较远。在VLA中，向量空间帮助模型理解动作的语义，从而更好地预测和执行动作。向量空间就像一张地图，帮助模型理解动作的语义。\n",
        "\n",
        "### 3. 语义相似性 (Semantic Similarity)\n",
        "- **中文名称**：语义相似性\n",
        "- **英文全称**：Semantic Similarity\n",
        "- **定义**：语义相似性是指动作之间在语义上的相似程度，是动作嵌入的重要特征。在动作嵌入中，语义相似的动作在向量空间中距离较近，语义不相似的动作在向量空间中距离较远。语义相似性的优势在于：1）捕获语义关系：能够捕获动作之间的语义关系；2）泛化能力：能够泛化到未见过的动作；3）特征学习：能够学习动作的特征表示；4）任务理解：能够帮助模型理解任务的语义。语义相似性的度量方法包括欧氏距离、余弦相似度等。语义相似性在VLA中的应用包括理解动作的语义关系，预测相似动作，泛化到未见过的动作等。语义相似性是动作嵌入的重要特征，通过语义相似性，VLA模型能够理解动作的语义关系，从而更好地预测和执行动作。\n",
        "- **核心组成**：语义相似性的核心组成包括：1）相似性定义：定义动作之间的语义相似性；2）相似性度量：使用距离度量方法度量动作相似性，如欧氏距离、余弦相似度等；3）相似性学习：使用神经网络学习动作的语义相似性；4）相似性可视化：可视化动作的语义相似性，理解动作在向量空间中的分布；5）相似性评估：评估语义相似性的质量，如相似动作是否距离较近等；6）相似性应用：将语义相似性应用于动作预测、动作泛化等。语义相似性通常使用向量空间中的距离度量，如欧氏距离、余弦相似度等。\n",
        "- **在VLA中的应用**：在VLA中，语义相似性用于理解动作的语义关系，预测相似动作。例如，如果模型学会了\"抓取\"的动作嵌入，它可以通过语义相似性理解\"拿起\"、\"握住\"等相似动作，从而泛化到这些未见过的动作。语义相似性的优势在于能够捕获动作的语义关系，这对于理解动作和预测动作非常重要。在VLA训练过程中，语义相似性通常与动作嵌入一起学习，通过端到端训练学习最适合任务的动作表示。语义相似性的结果可以作为VLA模型的中间表示，帮助模型理解动作的语义，从而更好地预测和执行动作。\n",
        "- **相关概念**：动作嵌入、向量空间、距离度量、欧氏距离、余弦相似度\n",
        "- **首次出现位置**：本文档第1.3节\n",
        "- **深入学习**：参考本文档的语义相似性详细讲解部分\n",
        "- **直观理解**：想象语义相似性就像动作之间的\"亲戚关系\"，关系越近的动作语义越相似。例如，\"抓取\"和\"拿起\"是\"近亲\"，它们的语义相似性高；而\"抓取\"和\"放置\"是\"远亲\"，它们的语义相似性低。在VLA中，语义相似性帮助模型理解动作的语义关系，从而更好地预测和执行动作。语义相似性就像动作之间的\"亲戚关系\"，帮助模型理解动作的语义。\n",
        "\n",
        "### 4. 查找表嵌入 (Lookup Table Embedding)\n",
        "- **中文名称**：查找表嵌入\n",
        "- **英文全称**：Lookup Table Embedding\n",
        "- **定义**：查找表嵌入是指使用查找表（Lookup Table）将离散动作映射到向量的方法，是动作嵌入中最常用的方法。在查找表嵌入中，每个离散动作都有一个对应的嵌入向量，这些向量存储在查找表中。查找表嵌入的优势在于：1）简单高效：查找表嵌入实现简单，计算效率高；2）可学习：嵌入向量可以通过训练学习；3）固定维度：所有动作的嵌入向量具有相同的维度；4）易于扩展：可以轻松添加新的动作。查找表嵌入的劣势在于：1）只适用于离散动作：查找表嵌入只适用于离散动作空间；2）无法处理连续动作：无法直接处理连续动作空间。查找表嵌入在VLA中的应用包括将离散动作映射到向量，这些向量将被用于动作预测、动作相似性计算等。\n",
        "- **核心组成**：查找表嵌入的核心组成包括：1）查找表：存储动作到向量的映射；2）嵌入维度：定义嵌入向量的维度；3）嵌入初始化：初始化嵌入向量，如随机初始化、预训练初始化等；4）嵌入学习：通过训练学习嵌入向量；5）嵌入更新：在训练过程中更新嵌入向量；6）嵌入查询：根据动作查询对应的嵌入向量。查找表嵌入通常使用矩阵实现，其中矩阵的每一行对应一个动作的嵌入向量。\n",
        "- **在VLA中的应用**：在VLA中，查找表嵌入用于将离散动作映射到向量。例如，对于离散动作空间中的动作（如\"抓取\"、\"放置\"、\"移动\"等），VLA模型使用查找表嵌入将这些动作映射到向量，这些向量将被用于动作预测、动作相似性计算等。查找表嵌入的优势在于实现简单、计算效率高，这对于大规模VLA任务非常重要。在VLA训练过程中，查找表嵌入通常与动作预测网络一起端到端训练，通过端到端训练学习最适合任务的动作表示。查找表嵌入的结果可以作为VLA模型的中间表示，帮助模型理解动作的语义，从而更好地预测和执行动作。\n",
        "- **相关概念**：动作嵌入、离散动作空间、向量空间、嵌入学习\n",
        "- **首次出现位置**：本文档第2.1节\n",
        "- **深入学习**：参考本文档的查找表嵌入详细讲解部分\n",
        "- **直观理解**：想象查找表嵌入就像一本字典，每个动作对应一个词条，词条的内容是一个向量。例如，\"抓取\"对应向量$[0.1, 0.2, 0.3, ...]$，\"放置\"对应向量$[0.4, 0.5, 0.6, ...]$。在VLA中，查找表嵌入帮助模型将动作转换为向量，从而更好地预测和执行动作。查找表嵌入就像一本字典，帮助模型将动作转换为向量。\n",
        "\n",
        "### 5. 神经网络嵌入 (Neural Network Embedding)\n",
        "- **中文名称**：神经网络嵌入\n",
        "- **英文全称**：Neural Network Embedding\n",
        "- **定义**：神经网络嵌入是指使用神经网络将动作映射到向量的方法，是动作嵌入的高级方法。在神经网络嵌入中，动作通过神经网络映射到向量，这个映射过程可以学习动作的特征表示。神经网络嵌入的优势在于：1）灵活表达：能够表达复杂的动作特征；2）端到端训练：能够与VLA模型的其他模块一起端到端训练；3）特征学习：能够学习动作的特征表示；4）适用性广：能够处理离散动作和连续动作。神经网络嵌入的劣势在于：1）计算复杂度：神经网络嵌入的计算复杂度较高；2）训练复杂：神经网络嵌入的训练相对复杂。神经网络嵌入在VLA中的应用包括将动作映射到向量，这些向量将被用于动作预测、动作相似性计算等。\n",
        "- **核心组成**：神经网络嵌入的核心组成包括：1）输入层：接收动作作为输入；2）隐藏层：使用隐藏层学习动作的特征表示；3）输出层：输出动作的嵌入向量；4）激活函数：使用激活函数增加非线性；5）损失函数：定义损失函数，如对比损失、三元组损失等；6）优化方法：使用优化方法训练网络。神经网络嵌入通常使用全连接网络、Transformer等实现，这些模型能够从动作数据中学习动作的特征表示。\n",
        "- **在VLA中的应用**：在VLA中，神经网络嵌入用于将动作映射到向量。例如，对于连续动作空间中的动作（如位置、速度、力度等），VLA模型使用神经网络嵌入将这些动作映射到向量，这些向量将被用于动作预测、动作相似性计算等。神经网络嵌入的优势在于能够表达复杂的动作特征，这对于理解复杂动作非常重要。在VLA训练过程中，神经网络嵌入通常与动作预测网络一起端到端训练，通过端到端训练学习最适合任务的动作表示。神经网络嵌入的结果可以作为VLA模型的中间表示，帮助模型理解动作的语义，从而更好地预测和执行动作。\n",
        "- **相关概念**：动作嵌入、连续动作空间、神经网络、嵌入学习、端到端训练\n",
        "- **首次出现位置**：本文档第2.2节\n",
        "- **深入学习**：参考本文档的神经网络嵌入详细讲解部分\n",
        "- **直观理解**：想象神经网络嵌入就像一台\"翻译机\"，将动作\"翻译\"成向量。例如，输入\"抓取\"这个动作，神经网络嵌入会输出一个向量，这个向量包含了\"抓取\"的特征信息。在VLA中，神经网络嵌入帮助模型将动作转换为向量，从而更好地预测和执行动作。神经网络嵌入就像一台\"翻译机\"，帮助模型将动作转换为向量。\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 概述\n",
        "\n",
        "### 什么是动作嵌入\n",
        "\n",
        "动作嵌入是指将动作嵌入到向量空间中的方法，是动作表示的重要技术。在动作嵌入中，每个动作都被映射到一个固定维度的向量，这个向量捕获了动作的语义信息。\n",
        "\n",
        "### 为什么重要\n",
        "\n",
        "动作嵌入对于VLA学习非常重要，原因包括：\n",
        "\n",
        "1. **语义相似性**：语义相似的动作在向量空间中距离较近\n",
        "2. **泛化能力**：能够泛化到未见过的动作\n",
        "3. **特征学习**：能够学习动作的特征表示\n",
        "4. **统一表示**：能够将不同类型的动作统一表示为向量\n",
        "\n",
        "### 学习目标\n",
        "\n",
        "通过本文档的学习，你将能够：\n",
        "\n",
        "1. **深入理解动作嵌入**：理解动作嵌入的原理和方法\n",
        "2. **掌握嵌入学习方法**：理解如何使用查找表嵌入和神经网络嵌入学习动作嵌入\n",
        "3. **理解语义相似性**：理解动作嵌入如何捕获语义相似性\n",
        "4. **掌握动作嵌入在VLA中的应用**：理解动作嵌入在VLA模型中的具体应用\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 导入必要的库\n",
        "# ============================================\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "import seaborn as sns\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'Microsoft YaHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 设置图表样式\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "print(\"环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 动作嵌入的基本原理\n",
        "\n",
        "### 1.1 什么是动作嵌入\n",
        "\n",
        "**直观理解**：想象动作嵌入就像给每个动作分配一个\"身份证号码\"，这个号码是一个向量，语义相似的动作有相似的向量。\n",
        "\n",
        "**定义**：动作嵌入是指将动作嵌入到向量空间中的方法，是动作表示的重要技术。\n",
        "\n",
        "### 1.2 动作嵌入的数学表示\n",
        "\n",
        "动作嵌入的数学表示为：\n",
        "\n",
        "$$e_a = \\text{Embedding}(a) \\in \\mathbb{R}^d$$\n",
        "\n",
        "其中：\n",
        "- $a$ 是动作（可以是离散动作或连续动作）\n",
        "- $e_a$ 是动作的嵌入向量\n",
        "- $d$ 是嵌入维度\n",
        "\n",
        "### 1.3 向量空间\n",
        "\n",
        "在向量空间中，每个动作都被表示为一个向量，向量之间的距离可以度量动作的相似性。\n",
        "\n",
        "**欧氏距离**：\n",
        "\n",
        "$$d_{\\text{Euclidean}}(e_{a_1}, e_{a_2}) = \\|e_{a_1} - e_{a_2}\\|_2 = \\sqrt{\\sum_{i=1}^{d}(e_{a_1,i} - e_{a_2,i})^2}$$\n",
        "\n",
        "**余弦相似度**：\n",
        "\n",
        "$$\\text{cosine}(e_{a_1}, e_{a_2}) = \\frac{e_{a_1} \\cdot e_{a_2}}{\\|e_{a_1}\\|_2 \\|e_{a_2}\\|_2} = \\frac{\\sum_{i=1}^{d} e_{a_1,i} e_{a_2,i}}{\\sqrt{\\sum_{i=1}^{d} e_{a_1,i}^2} \\sqrt{\\sum_{i=1}^{d} e_{a_2,i}^2}}$$\n",
        "\n",
        "### 1.4 语义相似性\n",
        "\n",
        "在动作嵌入中，语义相似的动作在向量空间中距离较近，语义不相似的动作在向量空间中距离较远。\n",
        "\n",
        "### 1.5 动作嵌入的可视化\n",
        "\n",
        "下面我们通过代码可视化动作嵌入的结构：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 动作嵌入可视化（示例：VLA任务的动作嵌入）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的离散动作空间\n",
        "actions = ['抓取', '放置', '移动', '旋转', '停止', '拿起', '放下', '推', '拉', '抬起']\n",
        "num_actions = len(actions)\n",
        "embedding_dim = 64\n",
        "\n",
        "# 模拟动作嵌入（语义相似的动作距离较近）\n",
        "# 创建语义相似的动作组\n",
        "similar_groups = [\n",
        "    ['抓取', '拿起'],  # 语义相似\n",
        "    ['放置', '放下'],  # 语义相似\n",
        "    ['推', '拉'],      # 语义相似\n",
        "]\n",
        "\n",
        "# 生成动作嵌入\n",
        "action_embeddings = np.random.randn(num_actions, embedding_dim) * 0.1\n",
        "\n",
        "# 调整语义相似的动作，使它们在向量空间中距离较近\n",
        "for group in similar_groups:\n",
        "    group_indices = [actions.index(a) for a in group]\n",
        "    # 为组内的动作生成相似的嵌入\n",
        "    base_embedding = np.random.randn(embedding_dim) * 0.1\n",
        "    for idx in group_indices:\n",
        "        action_embeddings[idx] = base_embedding + np.random.randn(embedding_dim) * 0.05\n",
        "\n",
        "# 归一化嵌入向量\n",
        "action_embeddings = action_embeddings / np.linalg.norm(action_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# 计算动作之间的相似性\n",
        "cosine_sim = cosine_similarity(action_embeddings)\n",
        "euclidean_dist = euclidean_distances(action_embeddings)\n",
        "\n",
        "# 使用PCA降维可视化\n",
        "pca = PCA(n_components=2)\n",
        "action_embeddings_2d = pca.fit_transform(action_embeddings)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：动作嵌入在向量空间中的分布（2D投影）\n",
        "ax1 = axes[0, 0]\n",
        "for i, action in enumerate(actions):\n",
        "    ax1.scatter(action_embeddings_2d[i, 0], action_embeddings_2d[i, 1], \n",
        "               s=200, alpha=0.7, edgecolors='black', linewidth=2)\n",
        "    ax1.annotate(action, (action_embeddings_2d[i, 0], action_embeddings_2d[i, 1]), \n",
        "               xytext=(5, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # 连接语义相似的动作\n",
        "    for group in similar_groups:\n",
        "        if action in group:\n",
        "            group_indices = [actions.index(a) for a in group]\n",
        "            for other_idx in group_indices:\n",
        "                if other_idx != i:\n",
        "                    ax1.plot([action_embeddings_2d[i, 0], action_embeddings_2d[other_idx, 0]], \n",
        "                            [action_embeddings_2d[i, 1], action_embeddings_2d[other_idx, 1]], \n",
        "                            'r--', alpha=0.5, linewidth=2)\n",
        "\n",
        "ax1.set_title('动作嵌入在向量空间中的分布（2D投影）', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('PCA维度1')\n",
        "ax1.set_ylabel('PCA维度2')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 右上：动作之间的余弦相似度\n",
        "ax2 = axes[0, 1]\n",
        "im = ax2.imshow(cosine_sim, cmap='viridis', aspect='auto', vmin=-1, vmax=1)\n",
        "ax2.set_title('动作之间的余弦相似度', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('动作索引')\n",
        "ax2.set_ylabel('动作索引')\n",
        "ax2.set_xticks(range(num_actions))\n",
        "ax2.set_yticks(range(num_actions))\n",
        "ax2.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax2.set_yticklabels(actions)\n",
        "cbar = plt.colorbar(im, ax=ax2)\n",
        "cbar.set_label('余弦相似度', fontsize=10)\n",
        "\n",
        "# 左下：语义相似的动作对\n",
        "ax3 = axes[1, 0]\n",
        "similar_pairs = []\n",
        "for group in similar_groups:\n",
        "    for i in range(len(group)):\n",
        "        for j in range(i+1, len(group)):\n",
        "            idx1 = actions.index(group[i])\n",
        "            idx2 = actions.index(group[j])\n",
        "            similar_pairs.append((group[i], group[j], cosine_sim[idx1, idx2]))\n",
        "\n",
        "similar_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "actions1, actions2, sims = zip(*similar_pairs) if similar_pairs else ([], [], [])\n",
        "if similar_pairs:\n",
        "    y_pos = np.arange(len(similar_pairs))\n",
        "    bars = ax3.barh(y_pos, sims, color='steelblue', alpha=0.7, edgecolor='black', linewidth=2)\n",
        "    ax3.set_title('语义相似的动作对', fontsize=12, fontweight='bold')\n",
        "    ax3.set_xlabel('余弦相似度')\n",
        "    ax3.set_ylabel('动作对')\n",
        "    ax3.set_yticks(y_pos)\n",
        "    ax3.set_yticklabels([f'{a1}-{a2}' for a1, a2 in zip(actions1, actions2)])\n",
        "    ax3.set_xlim(0, 1.1)\n",
        "    ax3.invert_yaxis()\n",
        "    ax3.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # 添加数值标注\n",
        "    for i, (bar, sim) in enumerate(zip(bars, sims)):\n",
        "        width = bar.get_width()\n",
        "        ax3.text(width + 0.02, bar.get_y() + bar.get_height()/2,\n",
        "                f'{sim:.3f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# 右下：动作嵌入维度分布\n",
        "ax4 = axes[1, 1]\n",
        "embedding_norms = np.linalg.norm(action_embeddings, axis=1)\n",
        "bars = ax4.bar(range(num_actions), embedding_norms, color='orange', \n",
        "              alpha=0.7, edgecolor='black', linewidth=2)\n",
        "ax4.set_title('动作嵌入向量范数', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('动作索引')\n",
        "ax4.set_ylabel('向量范数')\n",
        "ax4.set_xticks(range(num_actions))\n",
        "ax4.set_xticklabels(actions, rotation=45, ha='right')\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('动作嵌入可视化：VLA任务的动作嵌入', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"动作嵌入可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：动作嵌入在向量空间中的分布（2D投影），语义相似的动作距离较近\")\n",
        "print(\"2. 右上：动作之间的余弦相似度，显示动作之间的相似性\")\n",
        "print(\"3. 左下：语义相似的动作对，显示语义相似的动作对及其相似度\")\n",
        "print(\"4. 右下：动作嵌入向量范数，显示每个动作嵌入向量的范数\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 查找表嵌入可视化（示例：VLA任务的查找表嵌入）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的离散动作空间\n",
        "actions = ['抓取', '放置', '移动', '旋转', '停止']\n",
        "num_actions = len(actions)\n",
        "embedding_dim = 8\n",
        "\n",
        "# 创建查找表（随机初始化）\n",
        "lookup_table = np.random.randn(num_actions, embedding_dim) * 0.1\n",
        "\n",
        "# 归一化\n",
        "lookup_table = lookup_table / np.linalg.norm(lookup_table, axis=1, keepdims=True)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：查找表结构\n",
        "ax1 = axes[0, 0]\n",
        "im = ax1.imshow(lookup_table, cmap='viridis', aspect='auto')\n",
        "ax1.set_title('查找表结构（动作 × 嵌入维度）', fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel('嵌入维度')\n",
        "ax1.set_ylabel('动作索引')\n",
        "ax1.set_xticks(range(embedding_dim))\n",
        "ax1.set_xticklabels([f'维度{i+1}' for i in range(embedding_dim)])\n",
        "ax1.set_yticks(range(num_actions))\n",
        "ax1.set_yticklabels(actions)\n",
        "cbar = plt.colorbar(im, ax=ax1)\n",
        "cbar.set_label('嵌入值', fontsize=10)\n",
        "\n",
        "# 右上：查找表嵌入查询过程\n",
        "ax2 = axes[0, 1]\n",
        "ax2.axis('off')\n",
        "# 绘制查找表嵌入查询过程\n",
        "flow_boxes = [\n",
        "    ('动作索引', 0.2, 0.9),\n",
        "    ('查找表', 0.5, 0.9),\n",
        "    ('嵌入向量', 0.8, 0.9),\n",
        "    ('动作: 抓取', 0.2, 0.7),\n",
        "    ('索引: 0', 0.2, 0.5),\n",
        "    ('E[0, :]', 0.5, 0.5),\n",
        "    ('[0.1, 0.2, ...]', 0.8, 0.5),\n",
        "]\n",
        "\n",
        "for text, x, y in flow_boxes:\n",
        "    ax2.text(x, y, text, ha='center', va='center', fontsize=10, fontweight='bold',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
        "    if y < 0.9:\n",
        "        if x < 0.5:\n",
        "            ax2.arrow(x, y + 0.1, 0, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "        else:\n",
        "            ax2.arrow(x - 0.2, y + 0.1, 0.1, -0.05, head_width=0.02, head_length=0.02, \n",
        "                     fc='black', ec='black')\n",
        "\n",
        "ax2.set_xlim(0, 1)\n",
        "ax2.set_ylim(0, 1)\n",
        "ax2.set_title('查找表嵌入查询过程', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 左下：嵌入向量可视化（单个动作）\n",
        "ax3 = axes[1, 0]\n",
        "action_idx = 0  # 抓取\n",
        "embedding_vector = lookup_table[action_idx]\n",
        "x_pos = np.arange(embedding_dim)\n",
        "bars = ax3.bar(x_pos, embedding_vector, color='steelblue', alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "ax3.set_title(f'动作\"{actions[action_idx]}\"的嵌入向量', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('嵌入维度')\n",
        "ax3.set_ylabel('嵌入值')\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels([f'维度{i+1}' for i in range(embedding_dim)])\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "ax3.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "\n",
        "# 添加数值标注\n",
        "for i, (bar, val) in enumerate(zip(bars, embedding_vector)):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.01 if height >= 0 else height - 0.01,\n",
        "            f'{val:.2f}', ha='center', va='bottom' if height >= 0 else 'top', \n",
        "            fontsize=9, fontweight='bold')\n",
        "\n",
        "# 右下：所有动作的嵌入向量对比\n",
        "ax4 = axes[1, 1]\n",
        "x_pos = np.arange(embedding_dim)\n",
        "width = 0.15\n",
        "for i, action in enumerate(actions):\n",
        "    offset = (i - num_actions/2) * width\n",
        "    bars = ax4.bar(x_pos + offset, lookup_table[i], width, \n",
        "                  label=action, alpha=0.7, edgecolor='black', linewidth=1)\n",
        "ax4.set_title('所有动作的嵌入向量对比', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('嵌入维度')\n",
        "ax4.set_ylabel('嵌入值')\n",
        "ax4.set_xticks(x_pos)\n",
        "ax4.set_xticklabels([f'维度{i+1}' for i in range(embedding_dim)])\n",
        "ax4.legend(fontsize=9, loc='upper right')\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('查找表嵌入可视化：VLA任务的查找表嵌入', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"查找表嵌入可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：查找表结构，显示动作和嵌入维度的矩阵\")\n",
        "print(\"2. 右上：查找表嵌入查询过程，显示从动作索引到嵌入向量的查询过程\")\n",
        "print(\"3. 左下：单个动作的嵌入向量，显示动作的嵌入向量值\")\n",
        "print(\"4. 右下：所有动作的嵌入向量对比，显示不同动作的嵌入向量差异\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. 神经网络嵌入详解\n",
        "\n",
        "### 4.1 什么是神经网络嵌入\n",
        "\n",
        "**直观理解**：想象神经网络嵌入就像一台\"翻译机\"，将动作\"翻译\"成向量。\n",
        "\n",
        "**定义**：神经网络嵌入是指使用神经网络将动作映射到向量的方法，是动作嵌入的高级方法。\n",
        "\n",
        "### 4.2 为什么需要神经网络嵌入\n",
        "\n",
        "神经网络嵌入的必要性在于：\n",
        "\n",
        "1. **灵活表达**：\n",
        "   - 能够表达复杂的动作特征\n",
        "   - 能够学习动作的非线性关系\n",
        "   - 适合复杂的动作表示\n",
        "\n",
        "2. **端到端训练**：\n",
        "   - 能够与VLA模型的其他模块一起端到端训练\n",
        "   - 能够学习最适合任务的动作表示\n",
        "   - 能够优化整体性能\n",
        "\n",
        "3. **适用性广**：\n",
        "   - 能够处理离散动作和连续动作\n",
        "   - 能够处理变长动作序列\n",
        "   - 适合各种动作表示任务\n",
        "\n",
        "### 4.3 神经网络嵌入的数学推导详解\n",
        "\n",
        "#### 4.3.1 从基础数学开始\n",
        "\n",
        "**步骤1：理解神经网络**\n",
        "\n",
        "神经网络是一个函数，将输入映射到输出：\n",
        "\n",
        "$$f: \\mathbb{R}^{d_{in}} \\rightarrow \\mathbb{R}^{d_{out}}$$\n",
        "\n",
        "**步骤2：理解全连接层**\n",
        "\n",
        "全连接层的数学表示为：\n",
        "\n",
        "$$y = \\text{ReLU}(W x + b)$$\n",
        "\n",
        "其中：\n",
        "- $x \\in \\mathbb{R}^{d_{in}}$是输入\n",
        "- $W \\in \\mathbb{R}^{d_{out} \\times d_{in}}$是权重矩阵\n",
        "- $b \\in \\mathbb{R}^{d_{out}}$是偏置向量\n",
        "- $\\text{ReLU}$是激活函数\n",
        "\n",
        "**步骤3：理解动作嵌入网络**\n",
        "\n",
        "动作嵌入网络将动作映射到嵌入向量：\n",
        "\n",
        "$$e_a = f_{\\text{embed}}(a)$$\n",
        "\n",
        "其中$f_{\\text{embed}}$是嵌入网络。\n",
        "\n",
        "#### 4.3.2 神经网络嵌入的具体计算示例\n",
        "\n",
        "**示例：神经网络嵌入计算（连续动作）**\n",
        "\n",
        "假设：\n",
        "- 动作：$a = [x, y, z, f] \\in \\mathbb{R}^4$（位置和力度）\n",
        "- 嵌入网络：两层全连接网络\n",
        "- 第一层：$d_{in} = 4$，$d_{hidden} = 64$，$d_{out} = 64$\n",
        "- 第二层：$d_{in} = 64$，$d_{out} = 32$\n",
        "\n",
        "**步骤1：第一层计算**\n",
        "\n",
        "$$h_1 = \\text{ReLU}(W_1 a + b_1)$$\n",
        "\n",
        "其中$W_1 \\in \\mathbb{R}^{64 \\times 4}$，$b_1 \\in \\mathbb{R}^{64}$。\n",
        "\n",
        "**步骤2：第二层计算**\n",
        "\n",
        "$$e_a = W_2 h_1 + b_2$$\n",
        "\n",
        "其中$W_2 \\in \\mathbb{R}^{32 \\times 64}$，$b_2 \\in \\mathbb{R}^{32}$。\n",
        "\n",
        "**步骤3：最终嵌入**\n",
        "\n",
        "最终的动作嵌入为$e_a \\in \\mathbb{R}^{32}$。\n",
        "\n",
        "### 4.4 神经网络嵌入的可视化\n",
        "\n",
        "下面我们通过代码可视化神经网络嵌入的过程：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 神经网络嵌入可视化（示例：VLA任务的神经网络嵌入）\n",
        "# ============================================\n",
        "np.random.seed(42)\n",
        "\n",
        "# 示例：VLA任务的连续动作空间\n",
        "action_dim = 4  # x, y, z, f\n",
        "embedding_dim = 32\n",
        "hidden_dim = 64\n",
        "\n",
        "# 模拟神经网络嵌入\n",
        "# 生成示例动作\n",
        "num_samples = 20\n",
        "actions = np.random.randn(num_samples, action_dim) * 0.5\n",
        "\n",
        "# 模拟神经网络嵌入（两层全连接网络）\n",
        "W1 = np.random.randn(hidden_dim, action_dim) * 0.1\n",
        "b1 = np.random.randn(hidden_dim) * 0.1\n",
        "W2 = np.random.randn(embedding_dim, hidden_dim) * 0.1\n",
        "b2 = np.random.randn(embedding_dim) * 0.1\n",
        "\n",
        "# 计算嵌入\n",
        "h1 = np.maximum(0, actions @ W1.T + b1)  # ReLU\n",
        "embeddings = h1 @ W2.T + b2\n",
        "\n",
        "# 归一化\n",
        "embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "# 使用PCA降维可视化\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings)\n",
        "actions_2d = pca.fit_transform(actions)\n",
        "\n",
        "# 可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 左上：神经网络嵌入架构\n",
        "ax1 = axes[0, 0]\n",
        "ax1.axis('off')\n",
        "# 绘制神经网络架构\n",
        "layers = [\n",
        "    ('输入动作', 0.1, 0.5, action_dim),\n",
        "    ('隐藏层', 0.5, 0.5, hidden_dim),\n",
        "    ('输出嵌入', 0.9, 0.5, embedding_dim),\n",
        "]\n",
        "\n",
        "for i, (name, x, y, dim) in enumerate(layers):\n",
        "    # 绘制层\n",
        "    rect_height = min(0.3, dim * 0.01)\n",
        "    rect = plt.Rectangle((x - 0.05, y - rect_height/2), 0.1, rect_height,\n",
        "                        facecolor='lightblue', edgecolor='black', linewidth=2)\n",
        "    ax1.add_patch(rect)\n",
        "    ax1.text(x, y, name, ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "    ax1.text(x, y - rect_height/2 - 0.05, f'{dim}维', ha='center', va='top', \n",
        "            fontsize=9)\n",
        "    \n",
        "    # 绘制连接\n",
        "    if i < len(layers) - 1:\n",
        "        next_x = layers[i+1][1]\n",
        "        ax1.arrow(x + 0.05, y, next_x - x - 0.1, 0, head_width=0.02, \n",
        "                 head_length=0.02, fc='black', ec='black')\n",
        "\n",
        "ax1.set_xlim(0, 1)\n",
        "ax1.set_ylim(0, 1)\n",
        "ax1.set_title('神经网络嵌入架构', fontsize=12, fontweight='bold')\n",
        "\n",
        "# 右上：动作空间 vs 嵌入空间（2D投影）\n",
        "ax2 = axes[0, 1]\n",
        "ax2.scatter(actions_2d[:, 0], actions_2d[:, 1], s=100, alpha=0.6, \n",
        "           color='red', edgecolors='black', linewidth=1, label='动作空间')\n",
        "ax2.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100, alpha=0.6, \n",
        "           color='blue', edgecolors='black', linewidth=1, label='嵌入空间')\n",
        "ax2.set_title('动作空间 vs 嵌入空间（2D投影）', fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel('PCA维度1')\n",
        "ax2.set_ylabel('PCA维度2')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 左下：嵌入向量分布\n",
        "ax3 = axes[1, 0]\n",
        "embedding_norms = np.linalg.norm(embeddings, axis=1)\n",
        "ax3.hist(embedding_norms, bins=10, color='steelblue', alpha=0.7, \n",
        "        edgecolor='black', linewidth=2)\n",
        "ax3.set_title('嵌入向量范数分布', fontsize=12, fontweight='bold')\n",
        "ax3.set_xlabel('向量范数')\n",
        "ax3.set_ylabel('频数')\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 右下：嵌入维度重要性\n",
        "ax4 = axes[1, 1]\n",
        "embedding_std = np.std(embeddings, axis=0)\n",
        "x_pos = np.arange(embedding_dim)\n",
        "bars = ax4.bar(x_pos, embedding_std, color='orange', alpha=0.7, \n",
        "              edgecolor='black', linewidth=2)\n",
        "ax4.set_title('嵌入维度重要性（标准差）', fontsize=12, fontweight='bold')\n",
        "ax4.set_xlabel('嵌入维度')\n",
        "ax4.set_ylabel('标准差')\n",
        "ax4.set_xticks(x_pos[::4])\n",
        "ax4.set_xticklabels([f'维度{i+1}' for i in x_pos[::4]])\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('神经网络嵌入可视化：VLA任务的神经网络嵌入', fontsize=14, fontweight='bold', y=1.0)\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"神经网络嵌入可视化说明：\")\n",
        "print(\"=\" * 60)\n",
        "print(\"1. 左上：神经网络嵌入架构，显示从动作到嵌入的网络结构\")\n",
        "print(\"2. 右上：动作空间 vs 嵌入空间（2D投影），显示动作和嵌入在空间中的分布\")\n",
        "print(\"3. 左下：嵌入向量范数分布，显示嵌入向量的范数分布\")\n",
        "print(\"4. 右下：嵌入维度重要性，显示不同嵌入维度的重要性（标准差）\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. 动作嵌入在VLA中的应用\n",
        "\n",
        "### 5.1 动作嵌入在VLA中的角色\n",
        "\n",
        "在VLA中，动作嵌入用于将动作转换为向量表示，便于模型处理和预测。VLA模型使用动作嵌入理解动作的语义，从而更好地预测和执行动作。\n",
        "\n",
        "### 5.2 动作嵌入在VLA中的优势\n",
        "\n",
        "动作嵌入在VLA中的优势包括：\n",
        "\n",
        "1. **语义理解**：能够理解动作的语义，捕获动作之间的语义关系\n",
        "2. **泛化能力**：能够泛化到未见过的动作，提高模型的泛化能力\n",
        "3. **特征学习**：能够学习动作的特征表示，提高模型的表达能力\n",
        "4. **统一表示**：能够将不同类型的动作统一表示为向量，便于模型处理\n",
        "\n",
        "### 5.3 动作嵌入在VLA中的使用流程\n",
        "\n",
        "**步骤1：定义动作空间**\n",
        "\n",
        "定义动作空间，包括动作类型和动作数量：\n",
        "\n",
        "```python\n",
        "action_space = {\n",
        "    'discrete': ['抓取', '放置', '移动', '旋转', '停止'],\n",
        "    'continuous': {'dim': 4, 'ranges': {...}},\n",
        "}\n",
        "```\n",
        "\n",
        "**步骤2：创建动作嵌入**\n",
        "\n",
        "创建动作嵌入，使用查找表嵌入或神经网络嵌入：\n",
        "\n",
        "```python\n",
        "# 查找表嵌入（离散动作）\n",
        "action_embedding = nn.Embedding(num_actions, embedding_dim)\n",
        "\n",
        "# 神经网络嵌入（连续动作）\n",
        "action_embedding = nn.Sequential(\n",
        "    nn.Linear(action_dim, hidden_dim),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(hidden_dim, embedding_dim),\n",
        ")\n",
        "```\n",
        "\n",
        "**步骤3：动作嵌入学习**\n",
        "\n",
        "在训练过程中，动作嵌入会通过端到端训练学习：\n",
        "\n",
        "```python\n",
        "# 获取动作嵌入\n",
        "action_emb = action_embedding(action)\n",
        "\n",
        "# 使用动作嵌入进行预测\n",
        "prediction = model(multimodal_features, action_emb)\n",
        "```\n",
        "\n",
        "**步骤4：动作相似性计算**\n",
        "\n",
        "使用动作嵌入计算动作相似性：\n",
        "\n",
        "```python\n",
        "# 计算动作相似性\n",
        "similarity = cosine_similarity(action_emb1, action_emb2)\n",
        "```\n",
        "\n",
        "### 5.4 动作嵌入在VLA中的典型应用\n",
        "\n",
        "#### 5.4.1 离散动作空间\n",
        "\n",
        "**应用场景**：VLA任务的离散动作空间\n",
        "\n",
        "**动作嵌入示例**：\n",
        "```python\n",
        "# 使用查找表嵌入\n",
        "action_embedding = nn.Embedding(num_actions=10, embedding_dim=64)\n",
        "```\n",
        "\n",
        "**优势**：\n",
        "- 实现简单，计算效率高\n",
        "- 能够捕获动作的语义相似性\n",
        "- 适合大规模VLA任务\n",
        "\n",
        "#### 5.4.2 连续动作空间\n",
        "\n",
        "**应用场景**：VLA任务的连续动作空间\n",
        "\n",
        "**动作嵌入示例**：\n",
        "```python\n",
        "# 使用神经网络嵌入\n",
        "action_embedding = nn.Sequential(\n",
        "    nn.Linear(action_dim=4, hidden_dim=64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, embedding_dim=32),\n",
        ")\n",
        "```\n",
        "\n",
        "**优势**：\n",
        "- 能够表达复杂的动作特征\n",
        "- 能够学习动作的非线性关系\n",
        "- 适合复杂的动作表示\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 总结\n",
        "\n",
        "### 6.1 动作嵌入的核心思想\n",
        "\n",
        "动作嵌入的核心思想包括：\n",
        "\n",
        "1. **向量表示**：将动作表示为向量，捕获动作的语义信息\n",
        "2. **语义相似性**：语义相似的动作在向量空间中距离较近\n",
        "3. **嵌入学习**：使用查找表嵌入或神经网络嵌入学习动作嵌入\n",
        "4. **统一表示**：将不同类型的动作统一表示为向量\n",
        "\n",
        "### 6.2 动作嵌入的优势\n",
        "\n",
        "动作嵌入的优势包括：\n",
        "\n",
        "1. **语义相似性**：语义相似的动作在向量空间中距离较近\n",
        "2. **泛化能力**：能够泛化到未见过的动作\n",
        "3. **特征学习**：能够学习动作的特征表示\n",
        "4. **统一表示**：能够将不同类型的动作统一表示为向量\n",
        "\n",
        "### 6.3 动作嵌入在VLA中的重要性\n",
        "\n",
        "动作嵌入在VLA中的重要性体现在：\n",
        "\n",
        "1. **语义理解的基础**：动作嵌入是理解动作语义的基础，是VLA动作模块的重要方法\n",
        "2. **泛化能力**：能够泛化到未见过的动作，提高模型的泛化能力\n",
        "3. **特征学习**：能够学习动作的特征表示，提高模型的表达能力\n",
        "4. **应用广泛**：在VLA中应用广泛，是VLA动作表示的重要方法\n",
        "\n",
        "### 6.4 学习建议\n",
        "\n",
        "1. **理解基础概念**：深入理解动作嵌入、向量空间、语义相似性等基础概念\n",
        "2. **掌握嵌入方法**：掌握查找表嵌入和神经网络嵌入的原理和应用\n",
        "3. **实践设计**：通过实践设计不同任务的动作嵌入，理解设计原则\n",
        "4. **对比学习**：对比动作嵌入和One-Hot编码，理解各自的适用场景\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 文档信息\n",
        "\n",
        "- **创建时间**：2024年\n",
        "- **文档版本**：v1.0\n",
        "- **维护者**：VLA学习团队\n",
        "- **相关文档**：\n",
        "  - [动作执行基础详解](../../理论笔记/动作执行基础详解.ipynb)\n",
        "  - [词向量详解](../../../02_语言理解基础/01_文本特征提取/01_词向量/理论笔记/词向量详解.ipynb)\n",
        "  - [离散动作空间详解](../01_离散动作空间/理论笔记/离散动作空间详解.ipynb)\n",
        "  - [连续动作空间详解](../02_连续动作空间/理论笔记/连续动作空间详解.ipynb)\n",
        "  - [动作序列详解](../03_动作序列/理论笔记/动作序列详解.ipynb)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
